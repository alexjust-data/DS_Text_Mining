{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1894f082",
   "metadata": {
    "id": "1894f082"
   },
   "source": [
    "<div style=\"width: 100%; clear: both;\">\n",
    "<div style=\"float: left; width: 50%;\">\n",
    "<img src=\"https://www.uoc.edu/portal/_resources/common/imatges/sala_de_premsa/noticies/2016/202-nova-marca-uoc.jpg\", align=\"left\" width=\"380\" height=\"120\">\n",
    "</div>\n",
    "</div>\n",
    "<div style=\"float: right; width: 50%;\">\n",
    "<p style=\"margin: 0; padding-top: 22px; text-align:right;\">M2.893 - Análisis de textos</p>\n",
    "<p style=\"margin: 0; text-align:right;\">Máster en Ciencia de Datos</p>\n",
    "<p style=\"margin: 0; text-align:right; padding-button: 100px;\">Estudios de Informática, Multimedia y Telecomunicaciones</p>\n",
    "</div>\n",
    "</div>\n",
    "<div style=\"width: 100%; clear: both;\">\n",
    "<div style=\"width:100%;\">&nbsp;</div>\n",
    "\n",
    "\n",
    "# PAC 1: Procesamiento y análisis de información textual\n",
    "\n",
    "En esta práctica revisaremos y aplicaremos los conocimientos aprendidos en los módulos 1, 2 y 3. Concretamente trataremos 5 temas.\n",
    "\n",
    "<ul>\n",
    "<li>1. Preparación del dataset: pre-procesamiento de texto.\n",
    "<li>2. Obtención de datos a partir de información textual.\n",
    "<li>3. Detección de tópicos.\n",
    "<li>4. Clasificación de textos.\n",
    "<li>5. Evaluación: comparación de modelos y discusión de resultados.\n",
    "</ul>\n",
    "    \n",
    "El <b>propósito</b> de la práctica es descubrir rasgos característicos de un conjunto de reseñas de productos de software de <i>Amazon</i>, utilizando las técnicas explicadas y ver si es posible clasificar automáticamente una opinión como positiva o negativa con métodos de machine learning."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb0bf012",
   "metadata": {
    "id": "bb0bf012"
   },
   "source": [
    "<b> Descripción del Dataset</b>\n",
    "\n",
    "- Título: Amazon Review Data\n",
    "\n",
    "- Fuente: https://cseweb.ucsd.edu/~jmcauley/datasets/amazon_v2/#complete-data\n",
    "\n",
    " Utilizaremos un subconjunto de las reseñas disponibles en el dataset <i>Software</i>, el cual contiene opiniones realizadas por los clientes a diferentes productos de software disponibles en Amazon. El dataset original tiene 459.436 instancias, aunque en esta práctica vamos a trabajar con menos del 5% de ellas.\n",
    "\n",
    "En cuanto a la estructura del dataset, éste tiene 12 atributos:\n",
    "\n",
    "- <b>overall</b>: rating o calificación del producto; el valor va desde 1 (insatisfecho), hasta 5 (satisfecho).<br>\n",
    "- <b>verified</b>: indica si el mensaje ha sido verificado.<br>\n",
    "- <b>reviewTime</b>: fecha de la reseña (sin procesar).<br>\n",
    "- <b>reviewerID</b>: ID del revisor, por ejemplo A2SUAM1J3GNN3B.<br>\n",
    "- <b>asin</b>: ID del producto, p. 0000013714.<br>\n",
    "- <b>style</b>: diccionario de los metadatos del producto; por ejemplo, \"Platform\": \"Mac\".<br>\n",
    "- <b>reviewerName</b>: nombre del revisor.<br>\n",
    "- <b>reviewText</b>: texto de la reseña.<br>\n",
    "- <b>summary</b>: resumen de la reseña.<br>\n",
    "- <b>unixReviewTime</b>: fecha de la reseña (en formato Unix).<br>\n",
    "- <b>vote</b>:votos útiles de la revisión <br>\n",
    "- <b>image</b>: imágenes que los usuarios publican después de haber recibido el producto.<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d1333f6b",
   "metadata": {
    "id": "d1333f6b"
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore', category=DeprecationWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d8d20de",
   "metadata": {
    "id": "3d8d20de"
   },
   "source": [
    "# 1. Preparación del dataset: pre-procesamiento de texto (0.5 puntos)\n",
    "\n",
    "\n",
    "En este primer apartado realizaremos la carga del dataset original, seleccionaremos un subconjunto de las instancias y prepararemos (limpieza) el texto de las reseñas antes de realizar el análisis.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "hqRgiWGkHfVL",
   "metadata": {
    "id": "hqRgiWGkHfVL"
   },
   "source": [
    "## 1.1 Carga y creación del dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bbf74bac",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 539
    },
    "id": "bbf74bac",
    "outputId": "d5f1f3ee-8b0a-46f1-dbfc-fc5181ee7c52"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tamaño del dataset (15000, 12)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>overall</th>\n",
       "      <th>verified</th>\n",
       "      <th>reviewTime</th>\n",
       "      <th>reviewerID</th>\n",
       "      <th>asin</th>\n",
       "      <th>style</th>\n",
       "      <th>reviewerName</th>\n",
       "      <th>reviewText</th>\n",
       "      <th>summary</th>\n",
       "      <th>unixReviewTime</th>\n",
       "      <th>vote</th>\n",
       "      <th>image</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>11499</th>\n",
       "      <td>5.0</td>\n",
       "      <td>False</td>\n",
       "      <td>04 8, 2009</td>\n",
       "      <td>A2CNXL7UGZYFG4</td>\n",
       "      <td>B000QO76HU</td>\n",
       "      <td>NaN</td>\n",
       "      <td>E. HOFFMAN</td>\n",
       "      <td>STOP RIGHT THERE ! This is a real review that ...</td>\n",
       "      <td>YNAB - WHY IT CHANGED MY LIFE - APRIL 2009</td>\n",
       "      <td>1239148800</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6475</th>\n",
       "      <td>5.0</td>\n",
       "      <td>False</td>\n",
       "      <td>09 4, 2008</td>\n",
       "      <td>A3EZD11AFUX23K</td>\n",
       "      <td>B0017I8NQM</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Jason P. Gold</td>\n",
       "      <td>Please see [...] for a comparison of the featu...</td>\n",
       "      <td>The Better Wordprocessor</td>\n",
       "      <td>1220486400</td>\n",
       "      <td>12.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13167</th>\n",
       "      <td>2.0</td>\n",
       "      <td>True</td>\n",
       "      <td>10 2, 2013</td>\n",
       "      <td>A2H7NSYY9Q1UJZ</td>\n",
       "      <td>B000GD5DS0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Wallace Pierce</td>\n",
       "      <td>Just did not fit my needs.  My computer crashe...</td>\n",
       "      <td>My opinion of the Money 2007 Deluxe version.</td>\n",
       "      <td>1380672000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>862</th>\n",
       "      <td>4.0</td>\n",
       "      <td>True</td>\n",
       "      <td>06 28, 2015</td>\n",
       "      <td>A1XJ7XUR2W0J8V</td>\n",
       "      <td>B00RKZKFUI</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Jerry De La Cruz</td>\n",
       "      <td>Everything this little program does can be don...</td>\n",
       "      <td>The optional little graphics are a nice touch....</td>\n",
       "      <td>1435449600</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5970</th>\n",
       "      <td>5.0</td>\n",
       "      <td>False</td>\n",
       "      <td>08 13, 2018</td>\n",
       "      <td>A6OUFMC6D07OF</td>\n",
       "      <td>B0144NYGJY</td>\n",
       "      <td>{'Platform:': ' Key Card [12 month]'}</td>\n",
       "      <td>Barry</td>\n",
       "      <td>worked and useful as described</td>\n",
       "      <td>worked and useful as described</td>\n",
       "      <td>1534118400</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       overall  verified   reviewTime      reviewerID        asin  \\\n",
       "11499      5.0     False   04 8, 2009  A2CNXL7UGZYFG4  B000QO76HU   \n",
       "6475       5.0     False   09 4, 2008  A3EZD11AFUX23K  B0017I8NQM   \n",
       "13167      2.0      True   10 2, 2013  A2H7NSYY9Q1UJZ  B000GD5DS0   \n",
       "862        4.0      True  06 28, 2015  A1XJ7XUR2W0J8V  B00RKZKFUI   \n",
       "5970       5.0     False  08 13, 2018   A6OUFMC6D07OF  B0144NYGJY   \n",
       "\n",
       "                                       style      reviewerName  \\\n",
       "11499                                    NaN        E. HOFFMAN   \n",
       "6475                                     NaN     Jason P. Gold   \n",
       "13167                                    NaN    Wallace Pierce   \n",
       "862                                      NaN  Jerry De La Cruz   \n",
       "5970   {'Platform:': ' Key Card [12 month]'}             Barry   \n",
       "\n",
       "                                              reviewText  \\\n",
       "11499  STOP RIGHT THERE ! This is a real review that ...   \n",
       "6475   Please see [...] for a comparison of the featu...   \n",
       "13167  Just did not fit my needs.  My computer crashe...   \n",
       "862    Everything this little program does can be don...   \n",
       "5970                      worked and useful as described   \n",
       "\n",
       "                                                 summary  unixReviewTime  \\\n",
       "11499         YNAB - WHY IT CHANGED MY LIFE - APRIL 2009      1239148800   \n",
       "6475                            The Better Wordprocessor      1220486400   \n",
       "13167       My opinion of the Money 2007 Deluxe version.      1380672000   \n",
       "862    The optional little graphics are a nice touch....      1435449600   \n",
       "5970                      worked and useful as described      1534118400   \n",
       "\n",
       "       vote image  \n",
       "11499   2.0   NaN  \n",
       "6475   12.0   NaN  \n",
       "13167   NaN   NaN  \n",
       "862     NaN   NaN  \n",
       "5970    NaN   NaN  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Cargamos el archivo de reseñas:\n",
    "df = pd.read_csv('Amazon_software.csv', encoding = \"ISO-8859-1\")\n",
    "\n",
    "df = pd.DataFrame(df)\n",
    "print('Tamaño del dataset', df.shape)\n",
    "\n",
    "df.sample(5, random_state=42)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "VVM24VzSQFWJ",
   "metadata": {
    "id": "VVM24VzSQFWJ"
   },
   "source": [
    "Para realizar la práctica, sólo necesitaremos los textos de las reseñas y las calificaciones. Por tanto, eliminaremos las columnas innecesarias y nos quedaremos solo con las columnas <b>overall</b> y <b>reviewText</b>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "99646f8f-4bfb-4c5b-942e-48b550ee5aeb",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 275
    },
    "id": "99646f8f-4bfb-4c5b-942e-48b550ee5aeb",
    "outputId": "02e35a49-b018-48fa-8414-4de312ab7aa3"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>overall</th>\n",
       "      <th>reviewText</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>11499</th>\n",
       "      <td>5.0</td>\n",
       "      <td>STOP RIGHT THERE ! This is a real review that is not motivated by deception.\\nThe simple four (4) rules that YNAB software helps you follow is the combination that ha...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6475</th>\n",
       "      <td>5.0</td>\n",
       "      <td>Please see [...] for a comparison of the features in pre-ribbon versions of Word to WordPerfect.  It is enlightening!\\n\\nIt is hard to believe it is two years since C...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13167</th>\n",
       "      <td>2.0</td>\n",
       "      <td>Just did not fit my needs.  My computer crashed &amp; I had to replace my money program, so I ordered the 2007 version thinking it might be an improvement.  It was an imp...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>862</th>\n",
       "      <td>4.0</td>\n",
       "      <td>Everything this little program does can be done yourself with some programming in your word processor.  But why bother; this thing does it simply and intuitively.  Th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5970</th>\n",
       "      <td>5.0</td>\n",
       "      <td>worked and useful as described</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       overall  \\\n",
       "11499      5.0   \n",
       "6475       5.0   \n",
       "13167      2.0   \n",
       "862        4.0   \n",
       "5970       5.0   \n",
       "\n",
       "                                                                                                                                                                      reviewText  \n",
       "11499  STOP RIGHT THERE ! This is a real review that is not motivated by deception.\\nThe simple four (4) rules that YNAB software helps you follow is the combination that ha...  \n",
       "6475   Please see [...] for a comparison of the features in pre-ribbon versions of Word to WordPerfect.  It is enlightening!\\n\\nIt is hard to believe it is two years since C...  \n",
       "13167  Just did not fit my needs.  My computer crashed & I had to replace my money program, so I ordered the 2007 version thinking it might be an improvement.  It was an imp...  \n",
       "862    Everything this little program does can be done yourself with some programming in your word processor.  But why bother; this thing does it simply and intuitively.  Th...  \n",
       "5970                                                                                                                                              worked and useful as described  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Expandir la visualización de la columna de reseñas:\n",
    "pd.set_option('display.max_colwidth', 170)\n",
    "\n",
    "#Seleccionamos las columnas con las que trabajaremos:\n",
    "df = df[['overall', 'reviewText']] # calificación de la reseña y texto de la reseña.\n",
    "\n",
    "#Presentar 5 elementos de datos:\n",
    "df.sample(5, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ecdf4211-88d4-4cf7-8cfc-e9f3593e8b2e",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 448
    },
    "id": "ecdf4211-88d4-4cf7-8cfc-e9f3593e8b2e",
    "outputId": "ccb2a944-ea99-43f0-9275-871fa7a133bd"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: >"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Graficamos un histograma para tener una idea de la distribución de las reseñas numéricas:\n",
    "df.overall.hist(bins=[1.0, 2.0, 3.0, 4.0, 5.0], grid=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5864a2ae-4515-4e33-a0d1-18f02740b307",
   "metadata": {
    "id": "5864a2ae-4515-4e33-a0d1-18f02740b307"
   },
   "source": [
    "Como observamos en el histograma, hay más calificaciones positivas (de 4 puntos o más), que negativas (de 1 y 2 puntos). En la siguiente tabla veamos cuál es la tasa de votaciones por cada nivel de rating."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b1371761-c6c5-4bba-8057-93d6f3a0b222",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "b1371761-c6c5-4bba-8057-93d6f3a0b222",
    "outputId": "2ef3151d-8c56-4962-849f-94763c370444"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "overall\n",
       "5.0    46.226667\n",
       "1.0    22.606667\n",
       "4.0    15.546667\n",
       "3.0     8.766667\n",
       "2.0     6.853333\n",
       "Name: proportion, dtype: float64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Distribución de calificaciones por ubicación:\n",
    "df['overall'].value_counts(normalize=True) * 100 # valor porcentual"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16c5f881-45d7-45e2-804a-ebb93ca8773c",
   "metadata": {
    "id": "16c5f881-45d7-45e2-804a-ebb93ca8773c"
   },
   "source": [
    "La tabla anterior indica que, aproximadamente 1 de cada 2 clientes de Amazon han asignado la máxima puntuación (5.0) a los productos de software o tecnología. Mientras que 1 de cada 4 clientes han asignado la peor calificación posible (1.0).\n",
    "\n",
    "Para la clasificación de textos, necesitaremos sólo las opiniones que tienen las calificaciones más altas y las más bajas, por ello, vamos a seleccionar las filas que cumplan con estas características.\n",
    "\n",
    "Las opiniones cuya calificación sea mayor que 3 serán etiquetadas con '1'; mientras que, etiquetaremos con '0' las opiniones que tengan una calificación menor a 3. Las etiquetas se asignan a la columna <b>sentiment</b>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "16d52608",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "16d52608",
    "outputId": "bef5532b-2466-4a52-ba0a-7b5be2e350ec"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NÚMERO DE CALIFICACIONES POR CLASE:\n",
      " sentiment\n",
      "1    9266\n",
      "0    4419\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Tamaño total del dataset (13685, 3) \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Descartar reseñas neutrales (calificación = 3)\n",
    "cond = df['overall'] != 3\n",
    "df = df.loc[cond] # Filtrar\n",
    "\n",
    "# Creación de una nueva columna: sentiment\n",
    "df.loc[:,('sentiment')] = df['overall'].apply(lambda x : 1 if x > 3 else 0).copy()\n",
    "\n",
    "# Imprimir número de calificaciones por clase.\n",
    "print('NÚMERO DE CALIFICACIONES POR CLASE:\\n', df.sentiment.value_counts())\n",
    "print(\"\\nTamaño total del dataset\", df.shape, \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "wDoKtCxIbT5y",
   "metadata": {
    "id": "wDoKtCxIbT5y"
   },
   "source": [
    "Como observamos en el output anterior, luego de aplicar el filtro queddan 13685 instancias, de las cuales, aprox. el 32% de reseñas tienden a tener una connotación o sentimiento negativo, y el 68% son positivas.\n",
    "\n",
    "Para la clasificación de textos (Parte 4) vamos a trabajar con el dataset desbalanceado, pero, para la parte final de la práctica, haremos un ajuste para crear un modelo predictivo con una versión del dataset balanceado y veremos qué ocurre con las predicciones.\n",
    "\n",
    "Ahora continuemos con la exploración de las reseñas para ver qué otras tareas de preparación tenemos que realizar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c8fad82c-97fc-4273-bf24-df02492018a2",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 241
    },
    "id": "c8fad82c-97fc-4273-bf24-df02492018a2",
    "outputId": "fa4d00ad-0d1c-4113-8688-9318d868639b"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>overall</th>\n",
       "      <th>reviewText</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>11725</th>\n",
       "      <td>5.0</td>\n",
       "      <td>Just got to say the seller sold this to me at an amazing price.  I used the license serial number to renew my 3 PC's for a 1/3 of the cost of doing it online.  Woo Hoo!</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4532</th>\n",
       "      <td>4.0</td>\n",
       "      <td>The download of a)the Amazon required downloader and then b) the actual program in multiple steps went OK but for another $[...] bucks or so you can get the actual pa...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6339</th>\n",
       "      <td>5.0</td>\n",
       "      <td>Was recommended by my graphic designer so I could view and make small changes without going over my graphic design budget!</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6520</th>\n",
       "      <td>2.0</td>\n",
       "      <td>Slow.  Get lots of \"flashing\" hourglass cursors when making entries.  Same as older products, but only have to by to keep download function.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>628</th>\n",
       "      <td>1.0</td>\n",
       "      <td>Not to gd</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       overall  \\\n",
       "11725      5.0   \n",
       "4532       4.0   \n",
       "6339       5.0   \n",
       "6520       2.0   \n",
       "628        1.0   \n",
       "\n",
       "                                                                                                                                                                      reviewText  \\\n",
       "11725   Just got to say the seller sold this to me at an amazing price.  I used the license serial number to renew my 3 PC's for a 1/3 of the cost of doing it online.  Woo Hoo!   \n",
       "4532   The download of a)the Amazon required downloader and then b) the actual program in multiple steps went OK but for another $[...] bucks or so you can get the actual pa...   \n",
       "6339                                                  Was recommended by my graphic designer so I could view and make small changes without going over my graphic design budget!   \n",
       "6520                                Slow.  Get lots of \"flashing\" hourglass cursors when making entries.  Same as older products, but only have to by to keep download function.   \n",
       "628                                                                                                                                                                    Not to gd   \n",
       "\n",
       "       sentiment  \n",
       "11725          1  \n",
       "4532           1  \n",
       "6339           1  \n",
       "6520           0  \n",
       "628            0  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Muestra de clalificaciones: (1, sentimiento positivo) y (0, sentimiento negativo)\n",
    "df.sample(5, random_state = 8)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "903f1f58-ac1b-43bd-af43-3e992a51c909",
   "metadata": {
    "id": "903f1f58-ac1b-43bd-af43-3e992a51c909"
   },
   "source": [
    "Como observamos en el dataset creado, algunas reseñas son muy poco comunicativas (como \"Not to gd\"), por lo tanto, vamos a filtrar aquellas con menos de 5 palabras."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "aHP4wM-zxFfU",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "aHP4wM-zxFfU",
    "outputId": "c5ec0483-648f-45b9-efaf-8e66f9c988c1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CANTIDAD TOTAL DE REVIEWS ANTES DEL FILTRADO: 13685 \n",
      "\n",
      "CANTIDAD TOTAL DE REVIEWS DESPUÉS DEL FILTRADO: 12314\n",
      "NÚMERO DE CALIFICACIONES POR CLASE:\n",
      " sentiment\n",
      "1    8037\n",
      "0    4277\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Tamaño total del dataset (12314, 3) \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"CANTIDAD TOTAL DE REVIEWS ANTES DEL FILTRADO:\", df.shape[0], \"\\n\")\n",
    "\n",
    "def words_counter(text):\n",
    "    if type(text) != float:\n",
    "      return len(text.split()) # contar palabras de cada reseña\n",
    "    else:\n",
    "      return None\n",
    "\n",
    "#Descartar reseñas muy cortas: inferior a 5 palabras:\n",
    "df = df[df['reviewText'].apply(words_counter) >= 5]\n",
    "print(\"CANTIDAD TOTAL DE REVIEWS DESPUÉS DEL FILTRADO:\", df.shape[0])\n",
    "\n",
    "\n",
    "# Imprimir número de calificaciones por clase.\n",
    "print('NÚMERO DE CALIFICACIONES POR CLASE:\\n', df.sentiment.value_counts())\n",
    "print(\"\\nTamaño total del dataset\", df.shape, \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "zFYWBAr0XZua",
   "metadata": {
    "id": "zFYWBAr0XZua"
   },
   "source": [
    "Como observamos en el output anterior, de las 13.685 reseñas etiquetadas, luego del filtrado quedan 12.314 reseñas."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "gmUCKPB5xGjC",
   "metadata": {
    "id": "gmUCKPB5xGjC"
   },
   "source": [
    "## 1.2 Limpieza de texto (0.5 puntos):\n",
    "Antes de trabajar con los textos de las reseñas, hay que limpiarlos. Exploremos el tercer comentario para identificar qué tareas de limpieza necesitamos aplicar:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a9e67fb6-3534-4b36-9984-644fb806a154",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 127
    },
    "id": "a9e67fb6-3534-4b36-9984-644fb806a154",
    "outputId": "5627a080-8b9b-43e6-a2d1-6a57faaff534"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'I\\'ve used TurboTax since 1994.  This year they\\'ve clearly demonstrated their elitest attitude and how they really feel about their suckers, er customers.  I only do a couple stock trades a year and for that I\\'m forced to buy the Premier version ?!?!?  I decided to go with the <a data-hook=\"product-link-linked\" class=\"a-link-normal\" href=\"/Deluxe-package-from-H-R-Block/dp/B00PJPI6G6/ref=cm_cr_arp_d_rvw_txt?ie=UTF8\">Deluxe package from H&R Block</a> and it truly is Deluxe.  All the federal forms, 5 fed efiles (lets you prepare unlimited returns for family and friends), and state return on CD all for $25.  It imported last year\\'s TurboTax file quickly and accurately and worked great.  I\\'m switched for life.'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.iloc[12][1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f963f2c-a3d7-4427-b07b-59b171e096bb",
   "metadata": {
    "id": "7f963f2c-a3d7-4427-b07b-59b171e096bb"
   },
   "source": [
    "El ejemplo presentado, nos permite observar que necesitamos quitar algunos signos de puntuación y limpiar código HTML. Por ahora, dejaremos pendiente a estas tareas para realizarlo más adelante.\n",
    "\n",
    "Además, si continuamos con la exploración un del dataset, observamos que algunos textos contienen direcciones web.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "79c6f61f-2f43-48a9-a483-7bd7388b0a02",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 36
    },
    "id": "79c6f61f-2f43-48a9-a483-7bd7388b0a02",
    "outputId": "2d4afe3f-7829-47f7-8f94-48107bdd4d4c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'https://www.amazon.com help me a lot with my collection in my diary of my listening to music'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Presentar la primera reseña que incluye una dirección web:\n",
    "df[df['reviewText'].str.contains('http', case=False, na=False)].iloc[0][1]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d7299af-9745-4247-bdb6-e91843253d74",
   "metadata": {
    "id": "4d7299af-9745-4247-bdb6-e91843253d74"
   },
   "source": [
    "<div style=\"background-color: #F8F7FF; border-color: #7C9DBF; border-left: 5px solid #7C9DBF; padding: 0.5em;\">\n",
    "\n",
    "<strong>Ejercicio:</strong>  Filtraje de direcciones web: Agrega una columna al dataframe que se denomine <i>text</i> e implementa una función que a partir del contenido de <i>reviewText</i>, quite las direcciones web de los textos.\n",
    "<br>\n",
    "<b>Salida esperada:</b> Enlista al menos una reseña que muestre que la función implementada funciona.\n",
    "\n",
    "</div>\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "287fc6e2-586b-44ed-84bd-cf338196cd1a",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 36
    },
    "id": "287fc6e2-586b-44ed-84bd-cf338196cd1a",
    "outputId": "87525cd3-0e7e-4c9d-9173-629253f6ed8d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ANTES DEL FILTRADO:\n",
      " https://www.amazon.com help me a lot with my collection in my diary of my listening to music \n",
      "\n",
      "DESPUÉS DEL FILTRADO:\n",
      "  help me a lot with my collection in my diary of my listening to music \n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "\n",
    "# Función para remover URLs usando expresiones regulares\n",
    "def remove_urls(text):\n",
    "    # Definición de una expresión regular para encontrar URLs\n",
    "    url_pattern = re.compile(r'https?://\\S+|www\\.\\S+')\n",
    "    # Reemplazar las URLs encontradas por un espacio vacío\n",
    "    return url_pattern.sub(r'', text)\n",
    "\n",
    "# Crear una nueva columna 'text' aplicando la función para eliminar URLs\n",
    "df['text'] = df['reviewText'].apply(lambda x: remove_urls(x) if x is not None else x)\n",
    "\n",
    "# Ahora, para demostrar que la función ha funcionado, vamos a comparar el texto antes y después del filtrado en una instancia específica.\n",
    "# Para ello, seleccionaremos una reseña que sabemos que contiene una URL.\n",
    "\n",
    "# Ejemplo antes del filtrado\n",
    "print(\"ANTES DEL FILTRADO:\\n\", df.loc[df['reviewText'].str.contains('http', case=False, na=False)].iloc[0]['reviewText'], \"\\n\")\n",
    "\n",
    "# Ejemplo después del filtrado\n",
    "print(\"DESPUÉS DEL FILTRADO:\\n\", df.loc[df['reviewText'].str.contains('http', case=False, na=False)].iloc[0]['text'], \"\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "tR7h0D2L7R1J",
   "metadata": {
    "id": "tR7h0D2L7R1J"
   },
   "source": [
    "<div style=\"background-color: #EDF7FF; border-color: #7C9DBF; border-left: 5px solid #7C9DBF; padding: 1em;\">\n",
    "\n",
    "<strong>Ejercicio:</strong>  En este segundo paso de la limpieza de datos, construye una función que convierta el texto que contiene contracciones (una contracción es la forma abreviada de una palabra, como \"don't\") a su forma completa (como, \"do not\"). La expansión de las contracciones puede ser útil para mejorar la identificación de stopwords.\n",
    "<br>\n",
    "<br>\n",
    "<b>Salida esperada:</b> Enlista la siguiente reseña, evidenciando que las contracciones han sido extendidas. *Ejemplo de la salida esperada*:\n",
    "<br>\n",
    "<i>\"I do not really know why there were so many complaints about Windows 8. I got this in 2013 and had no problem since them. All you have to do is add on a free start button utility and it works pretty much like windows has always worked. Of course now that Windows 10 is out, maybe that is a moot point.\"</i>\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fsJG5c6G6NjU",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 73
    },
    "id": "fsJG5c6G6NjU",
    "outputId": "1cd07acf-5716-4cbf-d419-a89b45effcaa"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"I don't really know why there were so many complaints about Windows 8. I got this in 2013 and had no problem since them. All you have to do is add on a free start button utility and it works pretty much like windows has always worked. Of course now that Windows 10 is out, maybe that's a moot point\""
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Observemos el texto con contracciones (\"don't\", \"that's\"). Luego evidencia cómo éste cambia luego de la transformación:\n",
    "df.iloc[1][3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "gwiwCHtE54bN",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 73
    },
    "id": "gwiwCHtE54bN",
    "outputId": "26acf2dc-4637-4b1e-8425-1b89c8cc4c20"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I do not really know why there were so many complaints about Windows 8. I got this in 2013 and had not had any problem since then. All you have to do is add on a free start button utility and it works pretty much like windows has always worked. Of course now that Windows 10 is out, maybe that's a moot point.\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "# Mapeo de contracciones a sus formas expandidas\n",
    "contractions_mapping = {\n",
    "    \"don't\": \"do not\",\n",
    "    \"doesn't\": \"does not\",\n",
    "    \"didn't\": \"did not\",\n",
    "    \"hasn't\": \"has not\",\n",
    "    \"haven't\": \"have not\",\n",
    "    \"hadn't\": \"had not\",\n",
    "    \"won't\": \"will not\",\n",
    "    \"wouldn't\": \"would not\",\n",
    "    \"can't\": \"cannot\",\n",
    "    \"couldn't\": \"could not\",\n",
    "    \"shouldn't\": \"should not\",\n",
    "    \"mightn't\": \"might not\",\n",
    "    \"mustn't\": \"must not\",\n",
    "    \"I'm\": \"I am\",\n",
    "    \"you're\": \"you are\",\n",
    "    \"he's\": \"he is\",\n",
    "    \"she's\": \"she is\",\n",
    "    \"it's\": \"it is\",\n",
    "    \"we're\": \"we are\",\n",
    "    \"they're\": \"they are\",\n",
    "    \"I've\": \"I have\",\n",
    "    \"you've\": \"you have\",\n",
    "    \"we've\": \"we have\",\n",
    "    \"they've\": \"they have\",\n",
    "    \"I'd\": \"I would\",\n",
    "    \"you'd\": \"you had\",\n",
    "    \"he'd\": \"he had\",\n",
    "    \"she'd\": \"she had\",\n",
    "    \"we'd\": \"we had\",\n",
    "    \"they'd\": \"they had\",\n",
    "    \"I'll\": \"I will\",\n",
    "    \"you'll\": \"you will\",\n",
    "    \"he'll\": \"he will\",\n",
    "    \"she'll\": \"she will\",\n",
    "    \"we'll\": \"we will\",\n",
    "    \"they'll\": \"they will\",\n",
    "}\n",
    "\n",
    "# Función para expandir contracciones en el texto\n",
    "def expand_contractions(text, contractions_dict=contractions_mapping):\n",
    "    # Para cada contracción y su expansión en el diccionario\n",
    "    for contraction, expansion in contractions_dict.items():\n",
    "        # Usar expresiones regulares para reemplazar la contracción con su expansión\n",
    "        text = re.sub(r\"\\b{}\\b\".format(contraction), expansion, text, flags=re.IGNORECASE)\n",
    "    return text\n",
    "\n",
    "# Simulando un ejemplo de texto con contracciones\n",
    "example_text = \"I don't really know why there were so many complaints about Windows 8. I got this in 2013 and hadn't had any problem since then. All you have to do is add on a free start button utility and it works pretty much like windows has always worked. Of course now that Windows 10 is out, maybe that's a moot point.\"\n",
    "\n",
    "# Aplicando la función al ejemplo de texto\n",
    "expanded_text = expand_contractions(example_text)\n",
    "\n",
    "print(expanded_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "BDMUKkFFPhmy",
   "metadata": {
    "id": "BDMUKkFFPhmy"
   },
   "source": [
    "Como ya lo comprobamos, otra tarea de limpieza que el dataset necesita es la limpieza de código HTML de los textos. Veamos el siguiente ejemplo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "sgl_-fKiP2Xq",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "id": "sgl_-fKiP2Xq",
    "outputId": "4e360bbd-8c14-4357-e684-84d8e8476d09"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'This was FRAUD.  CD already registered per intuit<a data-hook=\"product-link-linked\" class=\"a-link-normal\" href=\"/QuickBooks-Pro-2009-OLD-VERSION/dp/B001ECGT8A/ref=cm_cr_arp_d_rvw_txt?ie=UTF8\">QuickBooks Pro 2009 [OLD VERSION</a>]'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.iloc[140][3] #A7D4E7F9EKSI9\n",
    "\n",
    "#Presentar la tercera reseña que incluye una dirección web, luego de la limpieza:\n",
    "df[df['text'].str.contains('This was FRAUD.', case=False, na=False)].iloc[0][3]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "XAUTu9VdUGCz",
   "metadata": {
    "id": "XAUTu9VdUGCz"
   },
   "source": [
    "Como observamos en el ejemplo, el texto de la reseña contiene la etiqueta de enlace. A través de la siguiente función vamos a quitar cualquier fragmento de código HTML de las reseñas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "vU9VwGbtP0j-",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 93
    },
    "id": "vU9VwGbtP0j-",
    "outputId": "15a71ac5-f69a-4890-f98b-642e335def61"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/p5/jp6dx55n0tl16f0fwb0jj6t00000gn/T/ipykernel_11694/160081010.py:4: MarkupResemblesLocatorWarning: The input looks more like a filename than markup. You may want to open this file and pass the filehandle into Beautiful Soup.\n",
      "  soup = BeautifulSoup(text, 'html.parser')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'This was FRAUD.  CD already registered per intuitQuickBooks Pro 2009 [OLD VERSION]'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "\n",
    "def html_links_remove(text):\n",
    "    soup = BeautifulSoup(text, 'html.parser')\n",
    "    text = soup.get_text()\n",
    "    return text\n",
    "\n",
    "# Aplicar la función.\n",
    "df['text']=df['text'].apply(lambda x:html_links_remove(x))\n",
    "\n",
    "#Presentar la tercera reseña que tenía una dirección web. Luego de la limpieza queda:\n",
    "df[df['text'].str.contains('This was FRAUD.', case=False, na=False)].iloc[0][3]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72067352-5141-4e85-9e06-13bcf9e05cd8",
   "metadata": {
    "id": "72067352-5141-4e85-9e06-13bcf9e05cd8"
   },
   "source": [
    "Ahora completaremos una tarea que la dejamos pendiente: quitar ciertos signos de puntuación."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b890c968",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 109
    },
    "id": "b890c968",
    "outputId": "558bcb15-7cd9-41bd-8199-34b246dbd54f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"I've used TurboTax since 1994.  This year they've clearly demonstrated their elitest attitude and how they really feel about their suckers  er customers.  I only do a couple stock trades a year and for that I'm forced to buy the Premier version        I decided to go with the Deluxe package from H R Block and it truly is Deluxe.  All the federal forms  5 fed efiles  lets you prepare unlimited returns for family and friends   and state return on CD all for  25.  It imported last year's TurboTax file quickly and accurately and worked great.  I'm switched for life.\""
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import string\n",
    "\n",
    "punctuation = ';,!\"#$%&\\()*+-<>@[\\\\]^_`{|}~?'\n",
    "\n",
    "# Función para reemplazar ciertos signos de puntuación:\n",
    "def clean_signs(text):\n",
    "    text = re.sub('[%s]' % re.escape(punctuation), ' ', text)\n",
    "    return text\n",
    "\n",
    "# Aplicar la función a la columna 'Review_Text'\n",
    "df['text'] = df['text'].apply(clean_signs)\n",
    "\n",
    "df.iloc[12].text # Presentamos una reseña para ver cómo va quedando el texto preprocesado."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d19a62b-8815-4e5f-97f2-be94612663e8",
   "metadata": {
    "id": "8d19a62b-8815-4e5f-97f2-be94612663e8"
   },
   "source": [
    "Finalmente, observamos en el ejemplo que hay espacios doble, así que vamos a crear una función para eliminarlos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f4e0e064-42c7-4836-8836-c28f31463aa4",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 109
    },
    "id": "f4e0e064-42c7-4836-8836-c28f31463aa4",
    "outputId": "6e18d12c-f76b-4369-b62f-42872d3c6993"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"I've used TurboTax since 1994. This year they've clearly demonstrated their elitest attitude and how they really feel about their suckers er customers. I only do a couple stock trades a year and for that I'm forced to buy the Premier version I decided to go with the Deluxe package from H R Block and it truly is Deluxe. All the federal forms 5 fed efiles lets you prepare unlimited returns for family and friends and state return on CD all for 25. It imported last year's TurboTax file quickly and accurately and worked great. I'm switched for life.\""
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "class ExtraSpacesReplacer(object):\n",
    "    \"\"\" Replaces extra spaces in a text.\n",
    "    >>> replacer = ExtraSpacesReplacer()\n",
    "    \"\"\"\n",
    "\n",
    "    def replace(self, text):\n",
    "        s = text\n",
    "        s = re.sub('\\s\\s+', ' ', s)\n",
    "        return s.strip()\n",
    "\n",
    "spaces_replacer = ExtraSpacesReplacer()\n",
    "\n",
    "df['text'] = df['text'].apply(spaces_replacer.replace)\n",
    "\n",
    "df.iloc[12][3] # Reseña luego de la limpieza"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dd14cd0",
   "metadata": {
    "id": "9dd14cd0"
   },
   "source": [
    "# 2. Obtención de datos a partir de información textual (3.25 puntos)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "312b68be",
   "metadata": {
    "id": "312b68be"
   },
   "source": [
    "## 2.1 Encontrar colocaciones (2 puntos)\n",
    "\n",
    "Recordemos que las colocaciones son términos multipalabra, es decir, secuencias de palabras que, en conjunto, tienen un significado que difiere significativamente del significado de cada palabra individual (e.g.\"Internet Security\")."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de41ffd0",
   "metadata": {
    "id": "de41ffd0"
   },
   "source": [
    "\n",
    "<strong>Ejercicio:</strong>  Calcula los mejores bigramas y trigramas de las opiniones (1 punto).\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "lk582wJzf5UM",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "lk582wJzf5UM",
    "outputId": "38ebad0c-ba11-4c30-ae5a-f08a04d5141e"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading collection 'all'\n",
      "[nltk_data]    | \n",
      "[nltk_data]    | Downloading package abc to /Users/alex/nltk_data...\n",
      "[nltk_data]    |   Package abc is already up-to-date!\n",
      "[nltk_data]    | Downloading package alpino to\n",
      "[nltk_data]    |     /Users/alex/nltk_data...\n",
      "[nltk_data]    |   Package alpino is already up-to-date!\n",
      "[nltk_data]    | Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]    |     /Users/alex/nltk_data...\n",
      "[nltk_data]    |   Package averaged_perceptron_tagger is already up-\n",
      "[nltk_data]    |       to-date!\n",
      "[nltk_data]    | Downloading package averaged_perceptron_tagger_ru to\n",
      "[nltk_data]    |     /Users/alex/nltk_data...\n",
      "[nltk_data]    |   Package averaged_perceptron_tagger_ru is already\n",
      "[nltk_data]    |       up-to-date!\n",
      "[nltk_data]    | Downloading package basque_grammars to\n",
      "[nltk_data]    |     /Users/alex/nltk_data...\n",
      "[nltk_data]    |   Package basque_grammars is already up-to-date!\n",
      "[nltk_data]    | Downloading package bcp47 to /Users/alex/nltk_data...\n",
      "[nltk_data]    |   Package bcp47 is already up-to-date!\n",
      "[nltk_data]    | Downloading package biocreative_ppi to\n",
      "[nltk_data]    |     /Users/alex/nltk_data...\n",
      "[nltk_data]    |   Package biocreative_ppi is already up-to-date!\n",
      "[nltk_data]    | Downloading package bllip_wsj_no_aux to\n",
      "[nltk_data]    |     /Users/alex/nltk_data...\n",
      "[nltk_data]    |   Package bllip_wsj_no_aux is already up-to-date!\n",
      "[nltk_data]    | Downloading package book_grammars to\n",
      "[nltk_data]    |     /Users/alex/nltk_data...\n",
      "[nltk_data]    |   Package book_grammars is already up-to-date!\n",
      "[nltk_data]    | Downloading package brown to /Users/alex/nltk_data...\n",
      "[nltk_data]    |   Package brown is already up-to-date!\n",
      "[nltk_data]    | Downloading package brown_tei to\n",
      "[nltk_data]    |     /Users/alex/nltk_data...\n",
      "[nltk_data]    |   Package brown_tei is already up-to-date!\n",
      "[nltk_data]    | Downloading package cess_cat to\n",
      "[nltk_data]    |     /Users/alex/nltk_data...\n",
      "[nltk_data]    |   Package cess_cat is already up-to-date!\n",
      "[nltk_data]    | Downloading package cess_esp to\n",
      "[nltk_data]    |     /Users/alex/nltk_data...\n",
      "[nltk_data]    |   Package cess_esp is already up-to-date!\n",
      "[nltk_data]    | Downloading package chat80 to\n",
      "[nltk_data]    |     /Users/alex/nltk_data...\n",
      "[nltk_data]    |   Package chat80 is already up-to-date!\n",
      "[nltk_data]    | Downloading package city_database to\n",
      "[nltk_data]    |     /Users/alex/nltk_data...\n",
      "[nltk_data]    |   Package city_database is already up-to-date!\n",
      "[nltk_data]    | Downloading package cmudict to\n",
      "[nltk_data]    |     /Users/alex/nltk_data...\n",
      "[nltk_data]    |   Package cmudict is already up-to-date!\n",
      "[nltk_data]    | Downloading package comparative_sentences to\n",
      "[nltk_data]    |     /Users/alex/nltk_data...\n",
      "[nltk_data]    |   Package comparative_sentences is already up-to-\n",
      "[nltk_data]    |       date!\n",
      "[nltk_data]    | Downloading package comtrans to\n",
      "[nltk_data]    |     /Users/alex/nltk_data...\n",
      "[nltk_data]    |   Package comtrans is already up-to-date!\n",
      "[nltk_data]    | Downloading package conll2000 to\n",
      "[nltk_data]    |     /Users/alex/nltk_data...\n",
      "[nltk_data]    |   Package conll2000 is already up-to-date!\n",
      "[nltk_data]    | Downloading package conll2002 to\n",
      "[nltk_data]    |     /Users/alex/nltk_data...\n",
      "[nltk_data]    |   Package conll2002 is already up-to-date!\n",
      "[nltk_data]    | Downloading package conll2007 to\n",
      "[nltk_data]    |     /Users/alex/nltk_data...\n",
      "[nltk_data]    |   Package conll2007 is already up-to-date!\n",
      "[nltk_data]    | Downloading package crubadan to\n",
      "[nltk_data]    |     /Users/alex/nltk_data...\n",
      "[nltk_data]    |   Package crubadan is already up-to-date!\n",
      "[nltk_data]    | Downloading package dependency_treebank to\n",
      "[nltk_data]    |     /Users/alex/nltk_data...\n",
      "[nltk_data]    |   Package dependency_treebank is already up-to-date!\n",
      "[nltk_data]    | Downloading package dolch to /Users/alex/nltk_data...\n",
      "[nltk_data]    |   Package dolch is already up-to-date!\n",
      "[nltk_data]    | Downloading package europarl_raw to\n",
      "[nltk_data]    |     /Users/alex/nltk_data...\n",
      "[nltk_data]    |   Package europarl_raw is already up-to-date!\n",
      "[nltk_data]    | Downloading package extended_omw to\n",
      "[nltk_data]    |     /Users/alex/nltk_data...\n",
      "[nltk_data]    |   Package extended_omw is already up-to-date!\n",
      "[nltk_data]    | Downloading package floresta to\n",
      "[nltk_data]    |     /Users/alex/nltk_data...\n",
      "[nltk_data]    |   Package floresta is already up-to-date!\n",
      "[nltk_data]    | Downloading package framenet_v15 to\n",
      "[nltk_data]    |     /Users/alex/nltk_data...\n",
      "[nltk_data]    |   Package framenet_v15 is already up-to-date!\n",
      "[nltk_data]    | Downloading package framenet_v17 to\n",
      "[nltk_data]    |     /Users/alex/nltk_data...\n",
      "[nltk_data]    |   Package framenet_v17 is already up-to-date!\n",
      "[nltk_data]    | Downloading package gazetteers to\n",
      "[nltk_data]    |     /Users/alex/nltk_data...\n",
      "[nltk_data]    |   Package gazetteers is already up-to-date!\n",
      "[nltk_data]    | Downloading package genesis to\n",
      "[nltk_data]    |     /Users/alex/nltk_data...\n",
      "[nltk_data]    |   Package genesis is already up-to-date!\n",
      "[nltk_data]    | Downloading package gutenberg to\n",
      "[nltk_data]    |     /Users/alex/nltk_data...\n",
      "[nltk_data]    |   Package gutenberg is already up-to-date!\n",
      "[nltk_data]    | Downloading package ieer to /Users/alex/nltk_data...\n",
      "[nltk_data]    |   Package ieer is already up-to-date!\n",
      "[nltk_data]    | Downloading package inaugural to\n",
      "[nltk_data]    |     /Users/alex/nltk_data...\n",
      "[nltk_data]    |   Package inaugural is already up-to-date!\n",
      "[nltk_data]    | Downloading package indian to\n",
      "[nltk_data]    |     /Users/alex/nltk_data...\n",
      "[nltk_data]    |   Package indian is already up-to-date!\n",
      "[nltk_data]    | Downloading package jeita to /Users/alex/nltk_data...\n",
      "[nltk_data]    |   Package jeita is already up-to-date!\n",
      "[nltk_data]    | Downloading package kimmo to /Users/alex/nltk_data...\n",
      "[nltk_data]    |   Package kimmo is already up-to-date!\n",
      "[nltk_data]    | Downloading package knbc to /Users/alex/nltk_data...\n",
      "[nltk_data]    |   Package knbc is already up-to-date!\n",
      "[nltk_data]    | Downloading package large_grammars to\n",
      "[nltk_data]    |     /Users/alex/nltk_data...\n",
      "[nltk_data]    |   Package large_grammars is already up-to-date!\n",
      "[nltk_data]    | Downloading package lin_thesaurus to\n",
      "[nltk_data]    |     /Users/alex/nltk_data...\n",
      "[nltk_data]    |   Package lin_thesaurus is already up-to-date!\n",
      "[nltk_data]    | Downloading package mac_morpho to\n",
      "[nltk_data]    |     /Users/alex/nltk_data...\n",
      "[nltk_data]    |   Package mac_morpho is already up-to-date!\n",
      "[nltk_data]    | Downloading package machado to\n",
      "[nltk_data]    |     /Users/alex/nltk_data...\n",
      "[nltk_data]    |   Package machado is already up-to-date!\n",
      "[nltk_data]    | Downloading package masc_tagged to\n",
      "[nltk_data]    |     /Users/alex/nltk_data...\n",
      "[nltk_data]    |   Package masc_tagged is already up-to-date!\n",
      "[nltk_data]    | Downloading package maxent_ne_chunker to\n",
      "[nltk_data]    |     /Users/alex/nltk_data...\n",
      "[nltk_data]    |   Package maxent_ne_chunker is already up-to-date!\n",
      "[nltk_data]    | Downloading package maxent_treebank_pos_tagger to\n",
      "[nltk_data]    |     /Users/alex/nltk_data...\n",
      "[nltk_data]    |   Package maxent_treebank_pos_tagger is already up-\n",
      "[nltk_data]    |       to-date!\n",
      "[nltk_data]    | Downloading package moses_sample to\n",
      "[nltk_data]    |     /Users/alex/nltk_data...\n",
      "[nltk_data]    |   Package moses_sample is already up-to-date!\n",
      "[nltk_data]    | Downloading package movie_reviews to\n",
      "[nltk_data]    |     /Users/alex/nltk_data...\n",
      "[nltk_data]    |   Package movie_reviews is already up-to-date!\n",
      "[nltk_data]    | Downloading package mte_teip5 to\n",
      "[nltk_data]    |     /Users/alex/nltk_data...\n",
      "[nltk_data]    |   Package mte_teip5 is already up-to-date!\n",
      "[nltk_data]    | Downloading package mwa_ppdb to\n",
      "[nltk_data]    |     /Users/alex/nltk_data...\n",
      "[nltk_data]    |   Package mwa_ppdb is already up-to-date!\n",
      "[nltk_data]    | Downloading package names to /Users/alex/nltk_data...\n",
      "[nltk_data]    |   Package names is already up-to-date!\n",
      "[nltk_data]    | Downloading package nombank.1.0 to\n",
      "[nltk_data]    |     /Users/alex/nltk_data...\n",
      "[nltk_data]    |   Package nombank.1.0 is already up-to-date!\n",
      "[nltk_data]    | Downloading package nonbreaking_prefixes to\n",
      "[nltk_data]    |     /Users/alex/nltk_data...\n",
      "[nltk_data]    |   Package nonbreaking_prefixes is already up-to-date!\n",
      "[nltk_data]    | Downloading package nps_chat to\n",
      "[nltk_data]    |     /Users/alex/nltk_data...\n",
      "[nltk_data]    |   Package nps_chat is already up-to-date!\n",
      "[nltk_data]    | Downloading package omw to /Users/alex/nltk_data...\n",
      "[nltk_data]    |   Package omw is already up-to-date!\n",
      "[nltk_data]    | Downloading package omw-1.4 to\n",
      "[nltk_data]    |     /Users/alex/nltk_data...\n",
      "[nltk_data]    |   Package omw-1.4 is already up-to-date!\n",
      "[nltk_data]    | Downloading package opinion_lexicon to\n",
      "[nltk_data]    |     /Users/alex/nltk_data...\n",
      "[nltk_data]    |   Package opinion_lexicon is already up-to-date!\n",
      "[nltk_data]    | Downloading package panlex_swadesh to\n",
      "[nltk_data]    |     /Users/alex/nltk_data...\n",
      "[nltk_data]    |   Package panlex_swadesh is already up-to-date!\n",
      "[nltk_data]    | Downloading package paradigms to\n",
      "[nltk_data]    |     /Users/alex/nltk_data...\n",
      "[nltk_data]    |   Package paradigms is already up-to-date!\n",
      "[nltk_data]    | Downloading package pe08 to /Users/alex/nltk_data...\n",
      "[nltk_data]    |   Package pe08 is already up-to-date!\n",
      "[nltk_data]    | Downloading package perluniprops to\n",
      "[nltk_data]    |     /Users/alex/nltk_data...\n",
      "[nltk_data]    |   Package perluniprops is already up-to-date!\n",
      "[nltk_data]    | Downloading package pil to /Users/alex/nltk_data...\n",
      "[nltk_data]    |   Package pil is already up-to-date!\n",
      "[nltk_data]    | Downloading package pl196x to\n",
      "[nltk_data]    |     /Users/alex/nltk_data...\n",
      "[nltk_data]    |   Package pl196x is already up-to-date!\n",
      "[nltk_data]    | Downloading package porter_test to\n",
      "[nltk_data]    |     /Users/alex/nltk_data...\n",
      "[nltk_data]    |   Package porter_test is already up-to-date!\n",
      "[nltk_data]    | Downloading package ppattach to\n",
      "[nltk_data]    |     /Users/alex/nltk_data...\n",
      "[nltk_data]    |   Package ppattach is already up-to-date!\n",
      "[nltk_data]    | Downloading package problem_reports to\n",
      "[nltk_data]    |     /Users/alex/nltk_data...\n",
      "[nltk_data]    |   Package problem_reports is already up-to-date!\n",
      "[nltk_data]    | Downloading package product_reviews_1 to\n",
      "[nltk_data]    |     /Users/alex/nltk_data...\n",
      "[nltk_data]    |   Package product_reviews_1 is already up-to-date!\n",
      "[nltk_data]    | Downloading package product_reviews_2 to\n",
      "[nltk_data]    |     /Users/alex/nltk_data...\n",
      "[nltk_data]    |   Package product_reviews_2 is already up-to-date!\n",
      "[nltk_data]    | Downloading package propbank to\n",
      "[nltk_data]    |     /Users/alex/nltk_data...\n",
      "[nltk_data]    |   Package propbank is already up-to-date!\n",
      "[nltk_data]    | Downloading package pros_cons to\n",
      "[nltk_data]    |     /Users/alex/nltk_data...\n",
      "[nltk_data]    |   Package pros_cons is already up-to-date!\n",
      "[nltk_data]    | Downloading package ptb to /Users/alex/nltk_data...\n",
      "[nltk_data]    |   Package ptb is already up-to-date!\n",
      "[nltk_data]    | Downloading package punkt to /Users/alex/nltk_data...\n",
      "[nltk_data]    |   Package punkt is already up-to-date!\n",
      "[nltk_data]    | Downloading package qc to /Users/alex/nltk_data...\n",
      "[nltk_data]    |   Package qc is already up-to-date!\n",
      "[nltk_data]    | Downloading package reuters to\n",
      "[nltk_data]    |     /Users/alex/nltk_data...\n",
      "[nltk_data]    |   Package reuters is already up-to-date!\n",
      "[nltk_data]    | Downloading package rslp to /Users/alex/nltk_data...\n",
      "[nltk_data]    |   Package rslp is already up-to-date!\n",
      "[nltk_data]    | Downloading package rte to /Users/alex/nltk_data...\n",
      "[nltk_data]    |   Package rte is already up-to-date!\n",
      "[nltk_data]    | Downloading package sample_grammars to\n",
      "[nltk_data]    |     /Users/alex/nltk_data...\n",
      "[nltk_data]    |   Package sample_grammars is already up-to-date!\n",
      "[nltk_data]    | Downloading package semcor to\n",
      "[nltk_data]    |     /Users/alex/nltk_data...\n",
      "[nltk_data]    |   Package semcor is already up-to-date!\n",
      "[nltk_data]    | Downloading package senseval to\n",
      "[nltk_data]    |     /Users/alex/nltk_data...\n",
      "[nltk_data]    |   Package senseval is already up-to-date!\n",
      "[nltk_data]    | Downloading package sentence_polarity to\n",
      "[nltk_data]    |     /Users/alex/nltk_data...\n",
      "[nltk_data]    |   Package sentence_polarity is already up-to-date!\n",
      "[nltk_data]    | Downloading package sentiwordnet to\n",
      "[nltk_data]    |     /Users/alex/nltk_data...\n",
      "[nltk_data]    |   Package sentiwordnet is already up-to-date!\n",
      "[nltk_data]    | Downloading package shakespeare to\n",
      "[nltk_data]    |     /Users/alex/nltk_data...\n",
      "[nltk_data]    |   Package shakespeare is already up-to-date!\n",
      "[nltk_data]    | Downloading package sinica_treebank to\n",
      "[nltk_data]    |     /Users/alex/nltk_data...\n",
      "[nltk_data]    |   Package sinica_treebank is already up-to-date!\n",
      "[nltk_data]    | Downloading package smultron to\n",
      "[nltk_data]    |     /Users/alex/nltk_data...\n",
      "[nltk_data]    |   Package smultron is already up-to-date!\n",
      "[nltk_data]    | Downloading package snowball_data to\n",
      "[nltk_data]    |     /Users/alex/nltk_data...\n",
      "[nltk_data]    |   Package snowball_data is already up-to-date!\n",
      "[nltk_data]    | Downloading package spanish_grammars to\n",
      "[nltk_data]    |     /Users/alex/nltk_data...\n",
      "[nltk_data]    |   Package spanish_grammars is already up-to-date!\n",
      "[nltk_data]    | Downloading package state_union to\n",
      "[nltk_data]    |     /Users/alex/nltk_data...\n",
      "[nltk_data]    |   Package state_union is already up-to-date!\n",
      "[nltk_data]    | Downloading package stopwords to\n",
      "[nltk_data]    |     /Users/alex/nltk_data...\n",
      "[nltk_data]    |   Package stopwords is already up-to-date!\n",
      "[nltk_data]    | Downloading package subjectivity to\n",
      "[nltk_data]    |     /Users/alex/nltk_data...\n",
      "[nltk_data]    |   Package subjectivity is already up-to-date!\n",
      "[nltk_data]    | Downloading package swadesh to\n",
      "[nltk_data]    |     /Users/alex/nltk_data...\n",
      "[nltk_data]    |   Package swadesh is already up-to-date!\n",
      "[nltk_data]    | Downloading package switchboard to\n",
      "[nltk_data]    |     /Users/alex/nltk_data...\n",
      "[nltk_data]    |   Package switchboard is already up-to-date!\n",
      "[nltk_data]    | Downloading package tagsets to\n",
      "[nltk_data]    |     /Users/alex/nltk_data...\n",
      "[nltk_data]    |   Package tagsets is already up-to-date!\n",
      "[nltk_data]    | Downloading package timit to /Users/alex/nltk_data...\n",
      "[nltk_data]    |   Package timit is already up-to-date!\n",
      "[nltk_data]    | Downloading package toolbox to\n",
      "[nltk_data]    |     /Users/alex/nltk_data...\n",
      "[nltk_data]    |   Package toolbox is already up-to-date!\n",
      "[nltk_data]    | Downloading package treebank to\n",
      "[nltk_data]    |     /Users/alex/nltk_data...\n",
      "[nltk_data]    |   Package treebank is already up-to-date!\n",
      "[nltk_data]    | Downloading package twitter_samples to\n",
      "[nltk_data]    |     /Users/alex/nltk_data...\n",
      "[nltk_data]    |   Package twitter_samples is already up-to-date!\n",
      "[nltk_data]    | Downloading package udhr to /Users/alex/nltk_data...\n",
      "[nltk_data]    |   Package udhr is already up-to-date!\n",
      "[nltk_data]    | Downloading package udhr2 to /Users/alex/nltk_data...\n",
      "[nltk_data]    |   Package udhr2 is already up-to-date!\n",
      "[nltk_data]    | Downloading package unicode_samples to\n",
      "[nltk_data]    |     /Users/alex/nltk_data...\n",
      "[nltk_data]    |   Package unicode_samples is already up-to-date!\n",
      "[nltk_data]    | Downloading package universal_tagset to\n",
      "[nltk_data]    |     /Users/alex/nltk_data...\n",
      "[nltk_data]    |   Package universal_tagset is already up-to-date!\n",
      "[nltk_data]    | Downloading package universal_treebanks_v20 to\n",
      "[nltk_data]    |     /Users/alex/nltk_data...\n",
      "[nltk_data]    |   Package universal_treebanks_v20 is already up-to-\n",
      "[nltk_data]    |       date!\n",
      "[nltk_data]    | Downloading package vader_lexicon to\n",
      "[nltk_data]    |     /Users/alex/nltk_data...\n",
      "[nltk_data]    |   Package vader_lexicon is already up-to-date!\n",
      "[nltk_data]    | Downloading package verbnet to\n",
      "[nltk_data]    |     /Users/alex/nltk_data...\n",
      "[nltk_data]    |   Package verbnet is already up-to-date!\n",
      "[nltk_data]    | Downloading package verbnet3 to\n",
      "[nltk_data]    |     /Users/alex/nltk_data...\n",
      "[nltk_data]    |   Package verbnet3 is already up-to-date!\n",
      "[nltk_data]    | Downloading package webtext to\n",
      "[nltk_data]    |     /Users/alex/nltk_data...\n",
      "[nltk_data]    |   Package webtext is already up-to-date!\n",
      "[nltk_data]    | Downloading package wmt15_eval to\n",
      "[nltk_data]    |     /Users/alex/nltk_data...\n",
      "[nltk_data]    |   Package wmt15_eval is already up-to-date!\n",
      "[nltk_data]    | Downloading package word2vec_sample to\n",
      "[nltk_data]    |     /Users/alex/nltk_data...\n",
      "[nltk_data]    |   Package word2vec_sample is already up-to-date!\n",
      "[nltk_data]    | Downloading package wordnet to\n",
      "[nltk_data]    |     /Users/alex/nltk_data...\n",
      "[nltk_data]    |   Package wordnet is already up-to-date!\n",
      "[nltk_data]    | Downloading package wordnet2021 to\n",
      "[nltk_data]    |     /Users/alex/nltk_data...\n",
      "[nltk_data]    |   Package wordnet2021 is already up-to-date!\n",
      "[nltk_data]    | Downloading package wordnet2022 to\n",
      "[nltk_data]    |     /Users/alex/nltk_data...\n",
      "[nltk_data]    |   Package wordnet2022 is already up-to-date!\n",
      "[nltk_data]    | Downloading package wordnet31 to\n",
      "[nltk_data]    |     /Users/alex/nltk_data...\n",
      "[nltk_data]    |   Package wordnet31 is already up-to-date!\n",
      "[nltk_data]    | Downloading package wordnet_ic to\n",
      "[nltk_data]    |     /Users/alex/nltk_data...\n",
      "[nltk_data]    |   Package wordnet_ic is already up-to-date!\n",
      "[nltk_data]    | Downloading package words to /Users/alex/nltk_data...\n",
      "[nltk_data]    |   Package words is already up-to-date!\n",
      "[nltk_data]    | Downloading package ycoe to /Users/alex/nltk_data...\n",
      "[nltk_data]    |   Package ycoe is already up-to-date!\n",
      "[nltk_data]    | \n",
      "[nltk_data]  Done downloading collection all\n"
     ]
    }
   ],
   "source": [
    "# Para este apartado es necesario cargar las siguientes librerías:\n",
    "import nltk\n",
    "nltk.download('all')\n",
    "from nltk import pos_tag, word_tokenize\n",
    "from nltk.collocations import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f6bfa1a6",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "f6bfa1a6",
    "outputId": "0ca2ab02-d3ac-4ed1-83f9-0cf2cd9e7f37"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['could',\n",
       " 'cup',\n",
       " 'i',\n",
       " 'me',\n",
       " 'my',\n",
       " 'myself',\n",
       " 'we',\n",
       " 'our',\n",
       " 'ours',\n",
       " 'ourselves',\n",
       " 'you',\n",
       " \"you're\",\n",
       " \"you've\",\n",
       " \"you'll\",\n",
       " \"you'd\",\n",
       " 'your',\n",
       " 'yours',\n",
       " 'yourself',\n",
       " 'yourselves',\n",
       " 'he']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Importar la lista de stopwords en inglés de la libreria NLTK y agregamos algunas adicionales:\n",
    "stopwords =  [\"could\", \"cup\"]#\n",
    "stopwords = stopwords + nltk.corpus.stopwords.words('english')\n",
    "# extracto de stopwords.\n",
    "[ x for x in stopwords[:20]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f79d8030",
   "metadata": {
    "id": "f79d8030"
   },
   "source": [
    "A partir del comando help(nltk.collocations.BigramAssocMeasures) explora la clase BigramAssocMeasures del módulo nltk.metrics.association y revisa las definiciones de las métricas de Likelihood Ratio (likelihood_ratio) y de Pointwise Mutual Information (pmi) se explica en el capítulo 5 del libro Foundations of Statistical Natural Language Processing (Manning & Schutze)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "35defbdd",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "35defbdd",
    "outputId": "6ea7f9c3-b50f-4e19-cdfa-28101fe6e2ee"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on class BigramAssocMeasures in module nltk.metrics.association:\n",
      "\n",
      "class BigramAssocMeasures(NgramAssocMeasures)\n",
      " |  A collection of bigram association measures. Each association measure\n",
      " |  is provided as a function with three arguments::\n",
      " |  \n",
      " |      bigram_score_fn(n_ii, (n_ix, n_xi), n_xx)\n",
      " |  \n",
      " |  The arguments constitute the marginals of a contingency table, counting\n",
      " |  the occurrences of particular events in a corpus. The letter i in the\n",
      " |  suffix refers to the appearance of the word in question, while x indicates\n",
      " |  the appearance of any word. Thus, for example:\n",
      " |  \n",
      " |  - n_ii counts ``(w1, w2)``, i.e. the bigram being scored\n",
      " |  - n_ix counts ``(w1, *)``\n",
      " |  - n_xi counts ``(*, w2)``\n",
      " |  - n_xx counts ``(*, *)``, i.e. any bigram\n",
      " |  \n",
      " |  This may be shown with respect to a contingency table::\n",
      " |  \n",
      " |              w1    ~w1\n",
      " |           ------ ------\n",
      " |       w2 | n_ii | n_oi | = n_xi\n",
      " |           ------ ------\n",
      " |      ~w2 | n_io | n_oo |\n",
      " |           ------ ------\n",
      " |           = n_ix        TOTAL = n_xx\n",
      " |  \n",
      " |  Method resolution order:\n",
      " |      BigramAssocMeasures\n",
      " |      NgramAssocMeasures\n",
      " |      builtins.object\n",
      " |  \n",
      " |  Class methods defined here:\n",
      " |  \n",
      " |  chi_sq(n_ii, n_ix_xi_tuple, n_xx) from abc.ABCMeta\n",
      " |      Scores bigrams using chi-square, i.e. phi-sq multiplied by the number\n",
      " |      of bigrams, as in Manning and Schutze 5.3.3.\n",
      " |  \n",
      " |  fisher(*marginals) from abc.ABCMeta\n",
      " |      Scores bigrams using Fisher's Exact Test (Pedersen 1996).  Less\n",
      " |      sensitive to small counts than PMI or Chi Sq, but also more expensive\n",
      " |      to compute. Requires scipy.\n",
      " |  \n",
      " |  phi_sq(*marginals) from abc.ABCMeta\n",
      " |      Scores bigrams using phi-square, the square of the Pearson correlation\n",
      " |      coefficient.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Static methods defined here:\n",
      " |  \n",
      " |  dice(n_ii, n_ix_xi_tuple, n_xx)\n",
      " |      Scores bigrams using Dice's coefficient.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data and other attributes defined here:\n",
      " |  \n",
      " |  __abstractmethods__ = frozenset()\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Class methods inherited from NgramAssocMeasures:\n",
      " |  \n",
      " |  jaccard(*marginals) from abc.ABCMeta\n",
      " |      Scores ngrams using the Jaccard index.\n",
      " |  \n",
      " |  likelihood_ratio(*marginals) from abc.ABCMeta\n",
      " |      Scores ngrams using likelihood ratios as in Manning and Schutze 5.3.4.\n",
      " |  \n",
      " |  pmi(*marginals) from abc.ABCMeta\n",
      " |      Scores ngrams by pointwise mutual information, as in Manning and\n",
      " |      Schutze 5.4.\n",
      " |  \n",
      " |  poisson_stirling(*marginals) from abc.ABCMeta\n",
      " |      Scores ngrams using the Poisson-Stirling measure.\n",
      " |  \n",
      " |  student_t(*marginals) from abc.ABCMeta\n",
      " |      Scores ngrams using Student's t test with independence hypothesis\n",
      " |      for unigrams, as in Manning and Schutze 5.3.1.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Static methods inherited from NgramAssocMeasures:\n",
      " |  \n",
      " |  mi_like(*marginals, **kwargs)\n",
      " |      Scores ngrams using a variant of mutual information. The keyword\n",
      " |      argument power sets an exponent (default 3) for the numerator. No\n",
      " |      logarithm of the result is calculated.\n",
      " |  \n",
      " |  raw_freq(*marginals)\n",
      " |      Scores ngrams by their frequency\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from NgramAssocMeasures:\n",
      " |  \n",
      " |  __dict__\n",
      " |      dictionary for instance variables (if defined)\n",
      " |  \n",
      " |  __weakref__\n",
      " |      list of weak references to the object (if defined)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(nltk.collocations.BigramAssocMeasures)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "837f7371",
   "metadata": {
    "id": "837f7371"
   },
   "source": [
    "Para categorizar a los tokens por su tag POS, primero vamos a convertir el texto a minúsculas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "314750c1",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "id": "314750c1",
    "outputId": "3d982944-89a3-4319-c732-98a2ed619052"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'we run a top of the line system utilizing windows 10 pro. i personally tried to get this to work. when you click the application file as per the directions on the back of the case our entire system would bog down and have to be reset. i let it just s'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Creamos texto en minúscula que recoja todas las reseñas:\n",
    "\n",
    "opinions = \" \".join(df['text']).lower()\n",
    "opinions[:250]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "Jtmvp_5FB1xY",
   "metadata": {
    "id": "Jtmvp_5FB1xY"
   },
   "source": [
    "<div style=\"background-color: #F8F7FF; border-color: #7C9DBF; border-left: 5px solid #7C9DBF; padding: 0.5em;\">\n",
    "    \n",
    "<i>Primer paso</i>: \n",
    "<br>\n",
    "Obtener los tokens del texto de las reseñas. Etiqueta estos tokens por su PoS.\n",
    "<br>\n",
    "Utiliza los métodos *word_tokenize* para tokenizar el texto de las reseñas y  *pos_tag* para determinar la etiqueta de cada token.\n",
    "\n",
    "<br>\n",
    "<b>Salida esperada:</b> Imprime los diez primeros tokens, con su respectiva etiqueta:\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2c27f9b8",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2c27f9b8",
    "outputId": "5859ed91-99f9-4b4e-cfb6-4c223ba65a26"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('we', 'PRP'), ('run', 'VBP'), ('a', 'DT'), ('top', 'NN'), ('of', 'IN'), ('the', 'DT'), ('line', 'NN'), ('system', 'NN'), ('utilizing', 'JJ'), ('windows', 'VBZ')]\n"
     ]
    }
   ],
   "source": [
    "# Tokenizar el texto\n",
    "tokens = word_tokenize(opinions)\n",
    "\n",
    "# Etiquetar los tokens con su PoS\n",
    "pos_tokens = pos_tag(tokens)\n",
    "\n",
    "# Imprimir los diez primeros tokens con su respectiva etiqueta PoS\n",
    "print(pos_tokens[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7287ecb",
   "metadata": {
    "id": "c7287ecb"
   },
   "source": [
    "\n",
    "<div style=\"background-color: #F8F7FF; border-color: #7C9DBF; border-left: 5px solid #7C9DBF; padding: 0.5em;\">\n",
    "    \n",
    "<i>Segundo paso</i>: Calcula los 500 mejores bigramas y los 500 mejores trigramas a partir de los tokens etiquetados (e.g. [(we, PRP), ...]) del texto. Utiliza las métricas PMI y Likehood Ratio.\n",
    "\n",
    "\n",
    "<b>Condición</b>: De los 500 bigramas y trigramas, elige a los que no comienzan ni terminen con una stopword. Para el filtrado de stopwords considera:\n",
    "- La lista previamente cargada (desde el paquete NLTK), y\n",
    "- Las categorías POS que representan a palabras vacías como determinantes, preposiciones, entre otras.\n",
    "\n",
    "<br>\n",
    "<b>Salida esperada:</b> Imprime los primeros 20 n-grams obtenidos con cada métrica.\n",
    "</div>\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de2fe029",
   "metadata": {
    "id": "de2fe029"
   },
   "source": [
    "Recordemos la clasificación de etiquetas PoS.\n",
    "\n",
    "<b>Etiquetas PoS</b>\n",
    "\n",
    "<ul>\n",
    "<li>DT: Determinante</li>\n",
    "<li>JJ: Adjetivo</li>\n",
    "<li>NN: Nombre en singular</li>\n",
    "<li>NNS: Nombre en plural</li>\n",
    "<li>VBD: Verbo en pasado</li>\n",
    "<li>VBG: Verbo en gerundio</li>\n",
    "<li>MD: Verbo modal</li>\n",
    "<li>IN: Preposición o conjunción subordinada</li>\n",
    "<li>PRP: Pronombre</li>\n",
    "<li>RB: Adverbio</li>\n",
    "<li>RP: Partícula</li>    \n",
    "<li>CC: Conjunción coordinada</li>\n",
    "<li>CD: Numeral</li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "43dfad33",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "43dfad33",
    "outputId": "c0bb618e-e81a-4c73-81dc-e5ad69990a83"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20 mejores bigramas con PMI:\n",
      "((\"'not\", 'NNP'), ('valid', 'NNP'))\n",
      "((\"'restart\", 'NNP'), ('app.scpt', 'NN'))\n",
      "((\"'w2/1099\", 'POS'), ('reporter', 'NN'))\n",
      "((\"'wedding\", 'VBG'), ('rehearsal', 'NN'))\n",
      "(('.o1', 'JJ'), ('entires', 'NNS'))\n",
      "(('/s3d', 'NNP'), ('stereoscopic', 'NN'))\n",
      "(('/watch', 'JJ'), ('v=vrtqyte94bo', 'NN'))\n",
      "((':0', 'NN'), ('definitley', 'NN'))\n",
      "((':invalidaterect', 'NN'), ('hwnd=null', 'NN'))\n",
      "(('==additional', 'JJ'), ('features==', 'NN'))\n",
      "(('==font', 'NNP'), ('rendering==', 'NN'))\n",
      "(('==new', 'VB'), ('skins==', 'JJ'))\n",
      "(('abrasive', 'JJ'), ('screeching', 'VBG'))\n",
      "(('absurdy', 'JJ'), ('inintuitive', 'JJ'))\n",
      "(('ac3', 'JJ'), ('dts', 'NN'))\n",
      "(('accuratley', 'VB'), ('depict', 'NN'))\n",
      "(('actualizar', 'JJ'), ('mi', 'NN'))\n",
      "(('adams', 'NNS'), ('terry', 'VBP'))\n",
      "(('afs5sersg6rat5sgar', 'NN'), ('arad', 'NN'))\n",
      "(('ag', 'JJ'), ('createacard', 'JJ'))\n",
      "\n",
      "20 mejores bigramas con Likelihood Ratio:\n",
      "(('.', '.'), ('.', '.'))\n",
      "(('turbo', 'JJ'), ('tax', 'NN'))\n",
      "(('r', 'NN'), ('block', 'NN'))\n",
      "(('customer', 'NN'), ('service', 'NN'))\n",
      "(('hard', 'JJ'), ('drive', 'NN'))\n",
      "(('tech', 'JJ'), ('support', 'NN'))\n",
      "(('h', 'NN'), ('r', 'NN'))\n",
      "(('operating', 'NN'), ('system', 'NN'))\n",
      "(('year', 'NN'), ('old', 'JJ'))\n",
      "(('h', 'JJ'), ('r', 'NN'))\n",
      "(('last', 'JJ'), ('year', 'NN'))\n",
      "((\"'ve\", 'VBP'), ('used', 'VBN'))\n",
      "(('e', 'JJ'), ('mail', 'NN'))\n",
      "(('anti', 'JJ'), ('virus', 'NN'))\n",
      "(('many', 'JJ'), ('years', 'NNS'))\n",
      "(('credit', 'NN'), ('card', 'NN'))\n",
      "(('internet', 'JJ'), ('security', 'NN'))\n",
      "(('rosetta', 'NN'), ('stone', 'NN'))\n",
      "(('works', 'VBZ'), ('great', 'JJ'))\n",
      "(('windows', 'NNS'), ('xp', 'VBP'))\n",
      "\n",
      "20 mejores trigramas con PMI:\n",
      "(('ac3', 'JJ'), ('dts', 'NN'), ('passthrough', 'NN'))\n",
      "(('actualizar', 'JJ'), ('mi', 'NN'), ('archos', 'VBD'))\n",
      "(('adams', 'NNS'), ('terry', 'VBP'), ('pratchett', 'NN'))\n",
      "(('afs5sersg6rat5sgar', 'NN'), ('arad', 'NN'), ('ag', 'NN'))\n",
      "(('alienware', 'NN'), ('aurora', 'JJ'), ('alx', 'NN'))\n",
      "(('angelia', 'VB'), ('vernon', 'NN'), ('menchan', 'NN'))\n",
      "(('areeyah', 'JJ'), ('m.', 'NN'), ('castaneda', 'NN'))\n",
      "(('avec', 'NN'), ('votre', 'NN'), ('cours', 'NN'))\n",
      "(('barga', 'JJ'), ('lucca', 'NN'), ('pisa', 'NN'))\n",
      "(('be.re.sheet', 'NN'), ('ba.ra', 'IN'), ('elohim', 'JJ'))\n",
      "(('bien', 'JJ'), ('buena', 'NN'), ('presentacion', 'NN'))\n",
      "(('bonus.its', 'VBZ'), ('bogus', 'IN'), ('claim.this', 'NN'))\n",
      "(('camus', 'NN'), ('flume', 'JJ'), ('flafka', 'NN'))\n",
      "(('caymon', 'NN'), ('bahamas', 'NN'), ('jamica', 'NN'))\n",
      "(('chk', 'NN'), ('bk', 'NN'), ('ymail.com', 'NNP'))\n",
      "(('coleco', 'JJ'), ('mattel', 'NN'), ('activision', 'NN'))\n",
      "(('computadoras', 'NNS'), ('que', 'VBP'), ('tengo', 'JJ'))\n",
      "(('coodrr', 'NN'), ('danial', 'JJ'), ('lanois', 'NN'))\n",
      "(('coral', 'NN'), ('feather', 'NN'), ('dusters', 'NNS'))\n",
      "(('coutez', 'NN'), ('et', 'NN'), ('rptez', 'NN'))\n",
      "\n",
      "20 mejores trigramas con Likelihood Ratio:\n",
      "(('.', '.'), ('i', 'NN'), (\"'ve\", 'VBP'))\n",
      "(('.', '.'), ('i', 'NN'), (\"'m\", 'VBP'))\n",
      "(('.', '.'), ('i', 'NN'), ('bought', 'VBD'))\n",
      "(('.', '.'), ('i', 'NN'), ('purchased', 'VBD'))\n",
      "(('.', '.'), ('i', 'NN'), ('use', 'VBP'))\n",
      "(('.', '.'), ('i', 'NN'), ('found', 'VBD'))\n",
      "(('.', '.'), ('i', 'NN'), ('tried', 'VBD'))\n",
      "(('.', '.'), ('i', 'NN'), ('got', 'VBD'))\n",
      "(('.', '.'), ('i', 'NN'), ('needed', 'VBD'))\n",
      "(('.', '.'), ('i', 'NN'), ('used', 'VBD'))\n",
      "(('.', '.'), ('i', 'NN'), ('love', 'VBP'))\n",
      "(('easy', 'JJ'), ('to', 'TO'), ('use', 'VB'))\n",
      "(('.', '.'), ('i', 'NN'), ('think', 'VBP'))\n",
      "(('.', '.'), ('i', 'NN'), ('wanted', 'VBD'))\n",
      "(('.', '.'), ('i', 'NN'), ('know', 'VBP'))\n",
      "(('.', '.'), ('i', 'NN'), ('decided', 'VBD'))\n",
      "(('.', '.'), ('i', 'NN'), ('installed', 'VBD'))\n",
      "(('.', '.'), ('i', 'NN'), ('upgraded', 'VBD'))\n",
      "(('.', '.'), ('i', 'NN'), ('started', 'VBD'))\n",
      "(('.', '.'), ('i', 'NN'), ('downloaded', 'VBD'))\n"
     ]
    }
   ],
   "source": [
    "from nltk.collocations import BigramCollocationFinder, TrigramCollocationFinder\n",
    "from nltk.metrics import BigramAssocMeasures, TrigramAssocMeasures\n",
    "\n",
    "\n",
    "#Cargamos las métricas para el cálculo de bigramas y trigramas:\n",
    "bigram_measures = nltk.collocations.BigramAssocMeasures()\n",
    "trigram_measures = nltk.collocations.TrigramAssocMeasures()\n",
    "\n",
    "# Función para determinar si un n-grama es válido según las condiciones especificadas\n",
    "def valid_ngram(ngram):\n",
    "    # Lista de etiquetas PoS que representan palabras vacías o funcionales\n",
    "    bad_tags = {'DT', 'IN', 'PRP$', 'RB', 'PRP', 'MD', 'WP', 'WRB', 'WDT', 'EX', 'PDT', 'RP', 'CC', 'UH', 'CD'}\n",
    "    # Verifica si el primer y último token del n-grama son válidos\n",
    "    first_word, last_word = ngram[0], ngram[-1]\n",
    "    return (first_word[0].lower() not in stopwords and \n",
    "            last_word[0].lower() not in stopwords) and (first_word[1] not in bad_tags and last_word[1] not in bad_tags)\n",
    "\n",
    "# Crear buscadores de collocations para bigramas y trigramas\n",
    "bigram_finder = BigramCollocationFinder.from_words(pos_tokens)\n",
    "trigram_finder = TrigramCollocationFinder.from_words(pos_tokens)\n",
    "\n",
    "# Filtrar bigramas y trigramas que no cumplen con las condiciones\n",
    "bigram_finder.apply_ngram_filter(lambda w1, w2: not valid_ngram((w1, w2)))\n",
    "trigram_finder.apply_ngram_filter(lambda w1, w2, w3: not valid_ngram((w1, w2, w3)))\n",
    "\n",
    "# Calcular y mostrar los 500 mejores bigramas y trigramas con ambas métricas\n",
    "best_500_bigrams_pmi = bigram_finder.nbest(BigramAssocMeasures.pmi, 500)\n",
    "best_500_bigrams_lr = bigram_finder.nbest(BigramAssocMeasures.likelihood_ratio, 500)\n",
    "best_500_trigrams_pmi = trigram_finder.nbest(TrigramAssocMeasures.pmi, 500)\n",
    "best_500_trigrams_lr = trigram_finder.nbest(TrigramAssocMeasures.likelihood_ratio, 500)\n",
    "\n",
    "# Imprimir los primeros 20 n-grams de cada lista\n",
    "print(\"20 mejores bigramas con PMI:\")\n",
    "for bigram in best_500_bigrams_pmi[:20]:\n",
    "    print(bigram)\n",
    "    \n",
    "print(\"\\n20 mejores bigramas con Likelihood Ratio:\")\n",
    "for bigram in best_500_bigrams_lr[:20]:\n",
    "    print(bigram)\n",
    "\n",
    "print(\"\\n20 mejores trigramas con PMI:\")\n",
    "for trigram in best_500_trigrams_pmi[:20]:\n",
    "    print(trigram)\n",
    "    \n",
    "print(\"\\n20 mejores trigramas con Likelihood Ratio:\")\n",
    "for trigram in best_500_trigrams_lr[:20]:\n",
    "    print(trigram)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e230beb-392e-45a6-a4b0-e57c2941f5c3",
   "metadata": {
    "id": "0e230beb-392e-45a6-a4b0-e57c2941f5c3"
   },
   "source": [
    "<div style=\"background-color: #F8F7FF; border-color: #7C9DBF; border-left: 5px solid #7C9DBF; padding: 0.5em;\">\n",
    "\n",
    "<b> Análisis:</b> Observa las salidas que genera cada métrica (PMI vs. Likehood Ratio) y explica por qué se generan las diferencias y cuál métrica genera los mejores n-gramas desde el punto de vista del dominio.\n",
    "\n",
    "</div>\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "873069d0",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "\n",
    " <br>\n",
    "En el contexto \"opiniones realizadas por los clientes a diferentes productos de software disponibles en Amazon\", el análisis de las salidas de cada métrica revela diferencias significativas en los tipos de n-gramas que cada una. La elección de la mejor métrica depende del objetivo del análisis. \n",
    "\n",
    "\n",
    "**Análisis de los N-gramas con PMI**  \n",
    "Los n-gramas con PMI altos son valiosos para detectar discusiones detalladas o técnicas. Sin embargo, pueden no ser tan útiles para capturar la esencia general de las reseñas o para identificar temas ampliamente relevantes para la mayoría de los usuarios. Por ejemplo:  \n",
    "* `(('ac3', 'JJ'), ('dts', 'NN'), ('passthrough', 'NN'))`: Este trigram es muy específico y probablemente relacionado con términos técnicos de audio. La especificidad indica que 'ac3' y 'dts passthrough' son conceptos técnicos probablemente no comunes fuera de contextos especializados.  \n",
    "\n",
    "* `(('actualizar', 'JJ'), ('mi', 'NN'), ('archos', 'VBD'))`: Aquí se combina un verbo en español ('actualizar') con un nombre propio ('archos'), lo que sugiere una discusión técnica sobre un producto específico, posiblemente en un contexto de soporte o actualización de software.\n",
    "\n",
    "\n",
    "**Análisis de los N-gramas con Likelihood Ratio**  \n",
    "Los n-gramas generados tienden a ser más generales y reflejar experiencias o acciones comunes mencionadas en las reseñas. En este contexto quizás tiende a ofrecer una visión más clara de las experiencias y opiniones compartidas por los usuarios. Por ejemplo:  \n",
    "\n",
    "* `(('.', '.'), ('i', 'NN'), (\"'ve\", 'VBP'))`: Estos trigramas reflejan acciones comunes en las reseñas, como haber comprado algo. Aunque la presencia de puntos (.) puede parecer menos informativa, el enfoque en acciones comunes como 'bought' (comprado) o 'used' (usado) refleja patrones de lenguaje comunes en las reseñas.  \n",
    "\n",
    "* `(('easy', 'JJ'), ('to', 'TO'), ('use', 'VB'))`: Este trigram claramente captura una opinión común en las reseñas, destacando la facilidad de uso de un producto, un tema muy relevante para potenciales consumidores.  \n",
    "\n",
    "La diferencia clave entre las métricas, entonces, radica en su enfoque: PMI destaca lo específico y potencialmente único, mientras que Likelihood Ratio tiende a enfocarse en lo común y ampliamente relevante. Dependiendo del objetivo de análisis (identificar temas generales vs. explorar detalles técnicos o específicos), elegiríamos la métrica que mejor se alinee con nuestro objetivos.\n",
    " <br>\n",
    " <br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3883d1ca",
   "metadata": {
    "id": "3883d1ca"
   },
   "source": [
    "<div style=\"background-color: #EDF7FF; border-color: #7C9DBF; border-left: 5px solid #7C9DBF; padding: 0.5em;\">\n",
    "\n",
    "<strong>Ejercicio:</strong>  Detecta n-gramas que cumplen el patrón sintáctico de un sintagma nominal (e.g: adjetivo + nombre en singular/plural, nombre + nombre y nombre en singular/plural). Las palabras componentes de cada n-grama deben estar separdaas por un guión \"-\". (0,5 puntos)\n",
    "\n",
    "<br>\n",
    "<b>Salida esperada:</b> Lista de los 20 primeros n-gramas que cumplan el patrón sintáctico, como 'line_system' y 'minutes'.\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "50c96d2e",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "50c96d2e",
    "outputId": "ffd9e039-7dbb-4eb3-b94f-a8532b415e60"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Los primeros 20 n-gramas que cumplen con el patrón sintáctico son:\n",
      ".o1-entires\n",
      "/watch-v=vrtqyte94bo\n",
      ":0-definitley\n",
      ":invalidaterect-hwnd=null\n",
      "==additional-features==\n",
      "ac3-dts\n",
      "actualizar-mi\n",
      "afs5sersg6rat5sgar-arad\n",
      "alaska-homesteader\n",
      "alex-armani\n",
      "alibre-deltacad\n",
      "alice-springs\n",
      "alif-baa\n",
      "alto-saxophone\n",
      "ami-officewriter\n",
      "andriod-fanboy\n",
      "apagar-manualmente\n",
      "apis-improve\n",
      "arad-ag\n",
      "archicad-plotmaker\n"
     ]
    }
   ],
   "source": [
    "# Lista de n-gramas que cumplen con los patrones sintácticos deseados\n",
    "matching_ngrams = []\n",
    "\n",
    "# Patrones sintácticos deseados en términos de etiquetas PoS\n",
    "desired_patterns = [\n",
    "    ('JJ', 'NN'), ('JJ', 'NNS'),  # Adj + Nombre singular/plural\n",
    "    ('NN', 'NN'), ('NNS', 'NN'), ('NN', 'NNS'), ('NNS', 'NNS')  # Nombre + Nombre (combinaciones)\n",
    "]\n",
    "\n",
    "# Buscar n-gramas que coincidan\n",
    "for ngram in best_500_bigrams_pmi + best_500_bigrams_lr:\n",
    "    pos_pattern = tuple(tag for word, tag in ngram) # Convertir ngrama a formato de etiquetas PoS\n",
    "    if pos_pattern in desired_patterns:             # Verificar si el patrón coincide con alguno de los deseados\n",
    "        # Formatear ngrama para unir palabras con guión y agregar a la lista de coincidencias\n",
    "        formatted_ngram = '-'.join(word for word, tag in ngram)\n",
    "        matching_ngrams.append(formatted_ngram)\n",
    "\n",
    "\n",
    "# Eliminar duplicados manteniendo el orden\n",
    "from collections import OrderedDict\n",
    "matching_ngrams = list(OrderedDict.fromkeys(matching_ngrams))\n",
    "\n",
    "# Imprimir los primeros 20 n-gramas que cumplen con el patrón\n",
    "print(\"Los primeros 20 n-gramas que cumplen con el patrón sintáctico son:\")\n",
    "for ngram in matching_ngrams[:20]:\n",
    "    print(ngram)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "535c0a10",
   "metadata": {
    "id": "535c0a10"
   },
   "source": [
    ">\n",
    "><strong>Ejercicio:</strong> Detectar colocaciones con un modelo de detección de frases, con el módulo Phraser de Gensim. Entrena el modelo con todas las opiniones (0.5 puntos).\n",
    ">\n",
    "><i>Primer Paso: </i> Crear la lista de sentences.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "9964125a-792f-409b-ac9c-fdb846aad084",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9964125a-792f-409b-ac9c-fdb846aad084",
    "outputId": "c5e93853-c6e9-4645-8a3d-e1c22c84085c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['We run a top of the line system utilizing Windows 10 Pro',\n",
       " 'I personally tried to get this to work',\n",
       " 'When you click the application file as per the directions on the back of the case our entire system would bog down and have to be reset',\n",
       " \"I let it just sit once to see if it ever started and after about 20 minutes all these windows started popping up saying that the file required a version of Adobe that doesn't exist and that the wrong volume was inserted\",\n",
       " 'Now we are taking all our computers off line to do a complete virus scan just in case',\n",
       " 'Avoid',\n",
       " \"At the least it's a headache and a waste of time and money\",\n",
       " \"I don't really know why there were so many complaints about Windows 8\",\n",
       " 'I got this in 2013 and had no problem since them',\n",
       " 'All you have to do is add on a free start button utility and it works pretty much like windows has always worked']"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Crear la lista de sentences:\n",
    "opinions_string = \" \".join(df['text'])\n",
    "\n",
    "opinion_sentences = opinions_string.split('. ')\n",
    "\n",
    "opinion_sentences[:10]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9a766d9-8390-4766-83d4-1cbcb7cbd816",
   "metadata": {
    "id": "d9a766d9-8390-4766-83d4-1cbcb7cbd816"
   },
   "source": [
    "<div style=\"background-color: #F8F7FF; border-color: #7C9DBF; border-left: 5px solid #7C9DBF; padding: 0.5em;\">\n",
    "\n",
    "<i>Segundo paso</i>: Convierte las reseñas en una lista de *phrases*. \n",
    "* Las phrases no deben ser stopwords. \n",
    "* Tampoco deben empezar ni acabar con una stopword. \n",
    "* Utiliza la lista de stopwords para el filtrado.\n",
    "\n",
    "<br>\n",
    "<b> Salida esperada:</b> Lista de las 20 primeras *phrases* que no sean, o no contengan stopwords.\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "97f2bd0b",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "97f2bd0b",
    "outputId": "c853eefa-ad17-4179-9525-cbb5cc5b278b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "top_line\n",
      "windows_pro\n",
      "personally_tried\n",
      "get_work\n",
      "click_application\n",
      "file_per\n",
      "entire_system\n",
      "see_ever\n",
      "started_popping\n",
      "file_required\n",
      "version_adobe\n",
      "virus_scan\n",
      "least_headache\n",
      "waste_time\n",
      "really_know\n",
      "many_complaints\n",
      "got_problem\n",
      "start_button\n",
      "works_pretty\n",
      "much_like\n"
     ]
    }
   ],
   "source": [
    "from gensim.models.phrases import Phrases, Phraser\n",
    "import gensim.utils\n",
    "\n",
    "# Tokenizar cada oración y filtrar stopwords\n",
    "sentences_tokenized = [[word for word in gensim.utils.simple_preprocess(sentence) if word not in stopwords] \n",
    "                       for sentence in opinion_sentences]\n",
    "\n",
    "# Entrenar el modelo Phrases\n",
    "phrases = Phrases(sentences_tokenized, min_count=1, threshold=1)\n",
    "phraser = Phraser(phrases)\n",
    "\n",
    "# Generar las phrases a partir de las oraciones tokenizadas\n",
    "phrases_list = [phraser[sentence] for sentence in sentences_tokenized]\n",
    "\n",
    "# Filtrar phrases que no comiencen ni terminen con stopwords, y que no contengan stopwords\n",
    "opinion_phrases_no_stopwords = []\n",
    "for sentence in phrases_list:\n",
    "    for phrase in sentence:\n",
    "        if \"_\" in phrase:  # Verificar si la palabra es una phrase\n",
    "            words = phrase.split(\"_\")\n",
    "            if words[0] not in stopwords and words[-1] not in stopwords and all(word not in stopwords for word in words):\n",
    "                opinion_phrases_no_stopwords.append(phrase)\n",
    "\n",
    "# Imprimir las primeras 20 phrases que cumplen con los criterios\n",
    "for x in opinion_phrases_no_stopwords[:20]:\n",
    "    print(x)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4e13a71",
   "metadata": {
    "id": "d4e13a71"
   },
   "source": [
    "## 2.2 Vectorizar palabras y términos (1.25 puntos)\n",
    "\n",
    "Exploraremos la vectorización de palabras y términos con el método Word2Vec."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "391acd67",
   "metadata": {
    "id": "391acd67"
   },
   "source": [
    "Recordemos que el paquete gensim implementa un método para entrenar modelos Word2Vec."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "4OGwpBv8fOtp",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4OGwpBv8fOtp",
    "outputId": "f9c5ddad-56c8-434c-b809-ef5b57babae4"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['top_line',\n",
       " 'windows_pro',\n",
       " 'personally_tried',\n",
       " 'get_work',\n",
       " 'click_application',\n",
       " 'file_per',\n",
       " 'entire_system',\n",
       " 'see_ever',\n",
       " 'started_popping',\n",
       " 'file_required']"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gensim\n",
    "\n",
    "# opinion_phrases_no_stopwords = filtered_phrases  # Esta sería la lista obtenida previamente\n",
    "\n",
    "# Quitar espacios del texto:\n",
    "opinion_phrases_stripped_no_stopwords = [c.strip() for c in opinion_phrases_no_stopwords]\n",
    "opinion_phrases_stripped_no_stopwords[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20aaa498",
   "metadata": {
    "id": "20aaa498"
   },
   "source": [
    "\n",
    "<strong>Ejercicio:</strong> Obtener targets de las opiniones y sus aspectos utilizando el modelo word2vec (1.5 puntos).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9d68931",
   "metadata": {
    "id": "a9d68931"
   },
   "source": [
    "<i>Primer paso</i>: Convertir las phrases de cada oración en un token. Lo haremos concatenando los tokens de la phrase con el caracter '_' \n",
    "* (e.g: 'disneyland hongkong' -> 'disneyland_hongkong'). \n",
    "  Entonces, en cada oración sustituimos los bigramas que son phrases por la forma tokenizada \n",
    "* (e.g: we've been to disneyland hongkong -> we've been to disneyland_hongkong). \n",
    "\n",
    "De esta forma, las colocaciones formarán parte del vocabulario del modelo word2vec que generaremos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "dee08237",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 36
    },
    "id": "dee08237",
    "outputId": "60e8e199-99bc-4c22-93ad-4673626e34e1"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['We run a top of the line system utilizing Windows 10 Pro',\n",
       " 'I personally tried to get this to work',\n",
       " 'When you click the application file as per the directions on the back of the case our entire system would bog down and have to be reset']"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.util import ngrams\n",
    "\n",
    "collocation_phrases = [phrase for phrase in list(set(opinion_phrases_stripped_no_stopwords)) if ' ' in phrase]\n",
    "\n",
    "def transform_sentence(sentence):\n",
    "    transformed_sentence = sentence\n",
    "    n_grams = list(ngrams(nltk.word_tokenize(sentence), 2))\n",
    "    ngrams_t = [' '.join(gram) for gram in n_grams]\n",
    "    for ngram in ngrams_t:\n",
    "        if ngram in collocation_phrases:\n",
    "            opt = ngram.replace(' ', '_')\n",
    "            transformed_sentence = transformed_sentence.replace(ngram,opt)\n",
    "    return transformed_sentence\n",
    "\n",
    "opinion_sentences_transformed = [transform_sentence(os) for os in opinion_sentences]\n",
    "\n",
    "opinion_sentences_transformed[:3][:200]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b53930c4",
   "metadata": {
    "id": "b53930c4"
   },
   "source": [
    "<div style=\"background-color: #F8F7FF; border-color: #7C9DBF; border-left: 5px solid #7C9DBF; padding: 0.5em;\">\n",
    "\n",
    "<i>Segundo paso</i>: Crea una sentence stream donde todos los tokens de las oraciones están lematizados. \n",
    "* Los tokens no pueden ser stopwords ni tener un stopword al inicio o al final. \n",
    "* Para simplificar la tarea, consideramos que el lema de una colocación no cambia y su PoS es 'col'. \n",
    "* (e.g: ['We run a top of the line system utilizing Windows 10 Pro']  -> [run', 'top', 'line', 'system', 'utilize', 'window', 'pro]).\n",
    "\n",
    "<br>\n",
    "<b> Salida esperada:</b> Lista de los 10 primeros tokens lematizados (que no sean, ni contengan stopwords).\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "9cfcef92",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9cfcef92",
    "outputId": "32ca8612-8b3c-43d3-9650-54efcf5f0277"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['windows', 'line', 'time', 'many', 'Now', 'utility', 'started', 'waste', 'scan', 'directions', 'utilizing', 'required', 'know', '10', 'volume', 'click', 'version', 'button', 'works', \"'s\", 'since', 'exist', 'get', 'We', 'bog', 'let', 'saying', '8', 'taking', 'case', 'minutes', 'really', 'I', 'tried', 'would', 'free', 'run', 'see', 'top', 'Pro', 'like', 'popping', 'ever', 'complaints', 'file', 'much', 'money', 'personally', '20', 'headache', 'work', 'entire', 'wrong', 'computers', 'application', 'system', 'back', 'pretty', 'add', 'worked', 'inserted', 'sit', 'All', 'virus', 'always', 'per', 'start', 'got', '2013', 'At', 'least', 'Windows', 'When', 'Adobe', 'reset', \"n't\", 'Avoid', 'complete', 'problem']\n"
     ]
    }
   ],
   "source": [
    "from gensim.models import Word2Vec\n",
    "\n",
    "# Simplificando la lematización, en este caso no la modificamos realmente\n",
    "def lemmatize_tokens(tokens):\n",
    "    lemmatized_tokens = []\n",
    "    for token in tokens:\n",
    "        # Asegurar que el token no sea una stopword\n",
    "        if token not in stopwords:\n",
    "            lemmatized_tokens.append(token)\n",
    "    return lemmatized_tokens\n",
    "\n",
    "# Crear sentence stream lematizado\n",
    "lemmatized_sentence_stream = [lemmatize_tokens(nltk.word_tokenize(sentence)) for sentence in opinion_sentences_transformed]\n",
    "\n",
    "# Imprimir los primeros 10 tokens lematizados que no sean ni contengan stopwords\n",
    "# Para simplificar, mostraremos tokens únicos de las primeras oraciones\n",
    "unique_lemmatized_tokens = list(set([token for sentence in lemmatized_sentence_stream[:10] for token in sentence]))\n",
    "print(unique_lemmatized_tokens[:1000])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b807880",
   "metadata": {
    "id": "7b807880"
   },
   "source": [
    "<div style=\"background-color: #F8F7FF; border-color: #7C9DBF; border-left: 5px solid #7C9DBF; padding: 0.5em;\">\n",
    "\n",
    "<i>Tercer paso</i>: Crea un modelo word2vec de las opiniones lematizadas. El modelo debe llamarse w2v_opinions.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "b033b7ad",
   "metadata": {
    "id": "b033b7ad"
   },
   "outputs": [],
   "source": [
    "from gensim.models import Word2Vec\n",
    "\n",
    "# lemmatized_sentence_stream es un stream de oraciones lematizadas preparado anteriormente\n",
    "\n",
    "# Crear y entrenar el modelo Word2Vec\n",
    "w2v_opinions = Word2Vec(sentences=lemmatized_sentence_stream, \n",
    "                        vector_size=100, \n",
    "                        window=5,\n",
    "                        min_count=1, \n",
    "                        workers=4)\n",
    "\n",
    "# El modelo ahora está entrenado con las opiniones lematizadas y listo para ser utilizado\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00e07b3c",
   "metadata": {
    "id": "00e07b3c"
   },
   "source": [
    "<div style=\"background-color: #F8F7FF; border-color: #7C9DBF; border-left: 5px solid #7C9DBF; padding: 0.5em;\">\n",
    "\n",
    "<i>Cuarto paso</i>: A partir del vocabulario del modelo word2vec, selecciona posibles aspectos de la reseña (e.g: desktop) y lista los términos semánticamente relacionados con estos aspectos según este modelo.\n",
    "<br>\n",
    "\n",
    "<b>Salida esperada:</b> Lista los primeros 20 términos que tengan mayor relación semántica con el término seleccionado (i.e. \"desktop\").\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "d10af9ee",
   "metadata": {
    "id": "d10af9ee"
   },
   "outputs": [],
   "source": [
    "# Obtener el vocabulario:\n",
    "vocabulary = list(w2v_opinions.wv.key_to_index.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "568d1445",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 676
    },
    "id": "568d1445",
    "outputId": "7ea0eb29-95ca-4f54-fb33-7748e7d92105"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "machine: 0.970400869846344\n",
      "VMs: 0.9489480257034302\n",
      "Compaq: 0.9470210075378418\n",
      "drivers: 0.9459487795829773\n",
      "systems: 0.9441156983375549\n",
      "OSX: 0.9427224397659302\n",
      "x64: 0.942611038684845\n",
      "dual: 0.9420129060745239\n",
      "compatible: 0.9419837594032288\n",
      "hardware: 0.9416555762290955\n",
      "boot: 0.9412880539894104\n",
      "Camp: 0.9401734471321106\n",
      "Mountain: 0.9384134411811829\n",
      "xp: 0.9380716681480408\n",
      "defender: 0.9348011016845703\n",
      "Media: 0.9345252513885498\n",
      "Window: 0.9340389370918274\n",
      "Lion: 0.9333457350730896\n",
      "32bit: 0.9313788414001465\n",
      "running: 0.9305863976478577\n"
     ]
    }
   ],
   "source": [
    "# Asegurarse de que \"desktop\" está en el vocabulario antes de buscar términos relacionados\n",
    "if \"desktop\" in vocabulary:\n",
    "    # Encontrar los primeros 20 términos más relacionados con \"desktop\"\n",
    "    related_terms = w2v_opinions.wv.most_similar(\"desktop\", topn=20)\n",
    "\n",
    "    # Imprimir los términos relacionados\n",
    "    for term, similarity in related_terms:\n",
    "        print(f\"{term}: {similarity}\")\n",
    "else:\n",
    "    print(\"El término 'desktop' no se encuentra en el vocabulario.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5613ad3-1d17-4a73-8bd3-b71b76db1f8b",
   "metadata": {
    "id": "a5613ad3-1d17-4a73-8bd3-b71b76db1f8b"
   },
   "source": [
    "<div style=\"background-color: #F8F7FF; border-color: #7C9DBF; border-left: 5px solid #7C9DBF; padding: 0.5em;\">\n",
    "\n",
    "<b>Análisis</b>: De los 20 términos seleccionados, elije los 5 ejemplos que consideres los más pertinentes. Menciona al menos un criterio que tomaste en cuenta para la selección.\n",
    "<br>\n",
    "<b>Salida esperada:</b>\n",
    "- Lista de al menos 5 de los términos (aspectos) que tengan mayor relación semántica con el término seleccionado (e.g. \"desktop\").\n",
    "- Argumento o criterio para realizar la selección de términos.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15d8b783",
   "metadata": {},
   "source": [
    "Estos términos fueron elegidos porque representan componentes, sistemas operativos, o categorías de productos que frecuentemente se discuten o se asocian con computadoras de escritorio (desktops).\n",
    "\n",
    "Términos Seleccionados:\n",
    "\n",
    "* VMs (Virtual Machines): Representan un concepto relevante para discusiones sobre desarrollo de software, pruebas, y uso de múltiples sistemas operativos en una sola máquina física.\n",
    "* Compaq: Una marca específica que históricamente está asociada con computadoras de escritorio, reflejando la influencia de marcas específicas en la percepción de calidad o preferencia de los usuarios.\n",
    "* drivers: Esenciales para el funcionamiento óptimo de hardware en sistemas operativos.\n",
    "* OSX: Sistema operativo de Mac, se utiliza en computadoras de escritorio de Apple, reflejando discusiones específicas de plataforma en el ámbito tech.\n",
    "* hardware: Un término general que abarca todos los componentes físicos de una computadora, siendo central para cualquier discusión sobre computadoras de escritorio.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "764f6cdb",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 127
    },
    "id": "764f6cdb",
    "outputId": "f3982abf-9f7a-4bd1-abeb-4aed3f04e01b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Términos relacionados con 'hardware':\n",
      "  - Win7: 0.9809386730194092\n",
      "  - platform: 0.9739170670509338\n",
      "  - compatibility: 0.9717433452606201\n",
      "  - Center: 0.9707468748092651\n",
      "  - OSX: 0.9690712094306946\n",
      "\n",
      "Términos relacionados con 'VMs':\n",
      "  - desktop: 0.9489479660987854\n",
      "  - machines: 0.9389473795890808\n",
      "  - OSX: 0.9356549382209778\n",
      "  - HP: 0.9350480437278748\n",
      "  - VMware: 0.933670699596405\n",
      "\n",
      "Términos relacionados con 'Compaq':\n",
      "  - 32bit: 0.9512057304382324\n",
      "  - xp: 0.9505490064620972\n",
      "  - vista: 0.9474460482597351\n",
      "  - desktop: 0.947020947933197\n",
      "  - Toshiba: 0.9468113780021667\n",
      "\n",
      "Términos relacionados con 'drivers':\n",
      "  - printer: 0.9835860133171082\n",
      "  - Camp: 0.9662987589836121\n",
      "  - installer: 0.963064432144165\n",
      "  - virtual: 0.9627209901809692\n",
      "  - Win7: 0.9592075347900391\n",
      "\n",
      "Términos relacionados con 'OSX':\n",
      "  - Lion: 0.9785597324371338\n",
      "  - MAC: 0.9781866669654846\n",
      "  - platform: 0.9780310988426208\n",
      "  - virtual: 0.9766974449157715\n",
      "  - Outlook: 0.9763811230659485\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Imprimimos ejemplos de aspectos cercanos semánticamente al target según el modelo Word2Vec. Elije los términos:\n",
    "terms_to_explore = [\"hardware\", \"VMs\", \"Compaq\", \"drivers\", \"OSX\"]\n",
    "\n",
    "for term in terms_to_explore:\n",
    "    print(f\"Términos relacionados con '{term}':\")\n",
    "    if term in w2v_opinions.wv.key_to_index:\n",
    "        related_terms = w2v_opinions.wv.most_similar(term, topn=5)\n",
    "        for related_term, similarity in related_terms:\n",
    "            print(f\"  - {related_term}: {similarity}\")\n",
    "    else:\n",
    "        print(\"  El término no se encuentra en el vocabulario del modelo.\")\n",
    "    print()  # Espacio entre términos\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80090d4b",
   "metadata": {
    "id": "80090d4b"
   },
   "source": [
    "# 3. Detección de temas (3 puntos)\n",
    "\n",
    "En estos apartados exploraremos cúales son los tópicos tratados en las opiniones."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00bb679a",
   "metadata": {
    "id": "00bb679a"
   },
   "source": [
    "## 3.1 Exploración de los temas con WordNet (2 puntos)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e7a2020",
   "metadata": {
    "id": "9e7a2020"
   },
   "source": [
    "En este apartado accederemos a Wordnet a través de la librería nltk."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "320fee0c",
   "metadata": {
    "id": "320fee0c"
   },
   "outputs": [],
   "source": [
    "from nltk.corpus import wordnet as wn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ccd9034",
   "metadata": {
    "id": "7ccd9034"
   },
   "source": [
    "<div style=\"background-color: #EDF7FF; border-color: #7C9DBF; border-left: 5px solid #7C9DBF; padding: 0.5em;\">\n",
    "\n",
    "<strong>Ejercicio:</strong> Comprueba si, según Wordnet, existen aspectos que están alejados semánticamente del sentido del target, aunque en el modelo word2vec sean similares. Compruébalo calculando la similitud de Wu and Palmer entre el sentido de wordnet 'desktop.n.01' y algunos de sus aspectos.\n",
    "<br>\n",
    "\n",
    "<b> Salida esperada: </b>\n",
    "<br>\n",
    "- Lista de dos términos que según *Wordnet* no estén tan cercanos, y su respectivo score de similitud, y\n",
    "<br>\n",
    "- Lista de los mismos términos que según el modelo *word2vec* están más cercanos.\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "30cfcb0f",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "30cfcb0f",
    "outputId": "52515efa-9041-4d7b-996e-8a4678ff8741"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similitud de Wu and Palmer en WordNet:\n",
      "hardware: 0.35294117647058826\n",
      "drivers: 0.3157894736842105\n",
      "\n",
      "Cercanía según el modelo Word2Vec:\n",
      "hardware: 0.9416556358337402\n",
      "drivers: 0.9459488391876221\n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import wordnet as wn\n",
    "from gensim.models import Word2Vec\n",
    "\n",
    "# Cargar el synset para 'desktop' en WordNet\n",
    "desktop_synset = wn.synset('desktop.n.01')\n",
    "\n",
    "# Lista ajustada de términos para comparar en ambos WordNet y Word2Vec\n",
    "terms_to_compare = [\"hardware\", \"drivers\"]  # Asumimos \"operating_system\" para \"Operating\"\n",
    "\n",
    "# Diccionario para almacenar los resultados de similitud de WordNet\n",
    "similarity_scores_wn = {}\n",
    "\n",
    "# Diccionario para almacenar similitudes de Word2Vec\n",
    "similarity_scores_w2v = {}\n",
    "\n",
    "for term in terms_to_compare:\n",
    "    # WordNet\n",
    "    term_synsets = wn.synsets(term)\n",
    "    if term_synsets:\n",
    "        best_score = max([desktop_synset.wup_similarity(ts) for ts in term_synsets])\n",
    "        similarity_scores_wn[term] = best_score\n",
    "    else:\n",
    "        similarity_scores_wn[term] = None\n",
    "    \n",
    "    # Word2Vec\n",
    "    if term in w2v_opinions.wv.key_to_index:\n",
    "        similarity_scores_w2v[term] = w2v_opinions.wv.similarity('desktop', term)\n",
    "    else:\n",
    "        similarity_scores_w2v[term] = None\n",
    "\n",
    "# Imprimir los scores de similitud con WordNet\n",
    "print(\"Similitud de Wu and Palmer en WordNet:\")\n",
    "for term, score in similarity_scores_wn.items():\n",
    "    print(f\"{term}: {score}\")\n",
    "\n",
    "# Imprimir la cercanía según el modelo Word2Vec\n",
    "print(\"\\nCercanía según el modelo Word2Vec:\")\n",
    "for term, similarity in similarity_scores_w2v.items():\n",
    "    print(f\"{term}: {similarity}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc6f84f3-a786-4d80-bfa1-479ec174733e",
   "metadata": {
    "id": "cc6f84f3-a786-4d80-bfa1-479ec174733e"
   },
   "source": [
    "<div style=\"background-color: #F8F7FF; border-color: #7C9DBF; border-left: 5px solid #7C9DBF; padding: 0.5em;\">\n",
    "\n",
    "<i>Análisis</i>: ¿Por qué ocurren diferencias a nivel de distancia semántica entre Wordnet y el modelo basado en Word2vec?\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf35e1a4",
   "metadata": {},
   "source": [
    "Las diferencias fundamentales en cómo cada uno modela y entiende las relaciones entre palabras. \n",
    "\n",
    "**Fundamento Teórico y Metodológico**:  \n",
    "- WordNet es un recurso léxico que organiza el lenguaje inglés en un conjunto de sinónimos interconectados, agrupados en conjuntos de sinónimos (synsets), cada uno expresando un concepto distinto. Las relaciones entre estos synsets siguen una estructura jerárquica y conceptual, basada en relaciones semánticas y léxicas como la hiponimia (específico a general), la hiperonimia (general a específico), y la meronimia (parte de). Estas relaciones están cuidadosamente curadas por expertos.\n",
    "  \n",
    "- Word2Vec es un modelo de aprendizaje automático que aprende representaciones vectoriales de palabras a partir de grandes corpus de texto basado en el contexto en el que aparecen las palabras. Estos contextos son capturados a través del aprendizaje de vectores en un espacio dimensional donde las palabras que comparten contextos similares son mapeadas a puntos cercanos. Este enfoque refleja patrones estadísticos del uso del lenguaje, no necesariamente relaciones conceptuales o jerárquicas definidas explícitamente.\n",
    "\n",
    "**Fuente de Información**:  \n",
    "- WordNet se basa en la estructura semántica del lenguaje definida por lingüistas, reflejando una comprensión teórica y organizada del lenguaje. Esto puede hacer que sus relaciones semánticas sean más precisas desde un punto de vista lingüístico o conceptual, pero posiblemente menos representativas de la variabilidad y riqueza del uso del lenguaje en contextos reales y cotidianos.\n",
    "\n",
    "- Word2Vec aprende de la utilización real del lenguaje en extensos corpus textuales, capturando cómo las palabras se usan y se relacionan entre sí en práctica. Esto puede incluir asociaciones semánticas basadas en conocimiento del mundo, jerga, y otros patrones que no se capturan necesariamente en la estructura jerárquica de WordNet.\n",
    "\n",
    "**Sensibilidad al Contexto**:  \n",
    "- Word2Vec es particularmente efectivo en capturar relaciones basadas en el co-ocurrencia y patrones de proximidad en el uso del lenguaje, lo que puede revelar relaciones semánticas no evidentes solo por análisis estructural o conceptual. Esto incluye sinónimos, antónimos, y otras formas de asociación semántica emergente del uso contextual.\n",
    "  \n",
    "- WordNet, mientras ofrece una visión detallada de las relaciones entre conceptos y palabras, no captura necesariamente el dinamismo del lenguaje ni las sutilezas del significado que emergen del contexto específico de uso.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3209e5cc",
   "metadata": {
    "id": "3209e5cc"
   },
   "source": [
    "<div style=\"background-color: #EDF7FF; border-color: #7C9DBF; border-left: 5px solid #7C9DBF; padding: 0.5em;\">\n",
    "\n",
    "<strong>Ejercicio:</strong> Identifica a los términos monopalabra del vocabulario de word2vec que no están en Wordnet. Filtra a los términos que sean nombres o adjetivos.\n",
    "\n",
    "Del conjunto de términos que identifiques, menciona a:\n",
    "- Abreviaturas o términos específicos del dominio o expresiones típicas de la jerga tech.<br>\n",
    "\n",
    "<b>Salida esperada:</b>\n",
    "<br>\n",
    "- Cantidad de términos que no constan en *Wordnet*.\n",
    "- Lista de los 20 primeros terminos monopalabra que no constan en <i>Wordnet</i>.\n",
    "- Lista de al menos 3 términos de los enlistados que sean inherentes al vocabulario tech.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "70e8e4bd",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "70e8e4bd",
    "outputId": "109340c3-be75-4e62-9a2e-1301ac9bc479"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Cantidad de términos que no constan en Wordnet: 9822\n",
      "*************\n",
      "20 primeros términos monopalabra que no constan en Wordnet:\n",
      "************\n",
      "n't\n",
      "'s\n",
      "The\n",
      "would\n",
      "This\n",
      ".\n",
      "'ve\n",
      ":\n",
      "If\n",
      "'m\n",
      "Norton\n",
      "Microsoft\n",
      "You\n",
      "..\n",
      "My\n",
      "since\n",
      "without\n",
      "...\n",
      "something\n",
      "everything\n",
      "*************\n",
      "Términos inherentes al vocabulario tech:\n",
      "************\n",
      "webroot\n",
      "netbook\n",
      "Logitech\n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import wordnet as wn\n",
    "import gensim\n",
    "\n",
    "# Asumiendo que el modelo Word2Vec se llama 'w2v_opinions'\n",
    "vocabulary = list(w2v_opinions.wv.key_to_index.keys())\n",
    "\n",
    "# Lista para almacenar términos que son monopalabra y no están en WordNet\n",
    "terms_not_in_wordnet = []\n",
    "\n",
    "# Filtrar términos monopalabra que no están en WordNet\n",
    "for term in vocabulary:\n",
    "    if \"_\" not in term and wn.synsets(term) == []:\n",
    "        terms_not_in_wordnet.append(term)\n",
    "\n",
    "# Contar la cantidad de términos encontrados\n",
    "count_terms_not_in_wordnet = len(terms_not_in_wordnet)\n",
    "print(f\"\\nCantidad de términos que no constan en Wordnet: {count_terms_not_in_wordnet}\")\n",
    "\n",
    "# Listar los primeros 20 términos\n",
    "print(\"*************\\n20 primeros términos monopalabra que no constan en Wordnet:\\n************\")\n",
    "for term in terms_not_in_wordnet[:20]:\n",
    "    print(term)\n",
    "\n",
    "# Identificar términos del dominio tech\n",
    "tech_terms = [term for term in terms_not_in_wordnet if any(substring in term for substring in ['tech', 'sys', 'net', 'web'])]\n",
    "\n",
    "# Lista de al menos 3 términos inherentes al vocabulario tech\n",
    "print(\"*************\\nTérminos inherentes al vocabulario tech:\\n************\")\n",
    "for term in tech_terms[:3]:\n",
    "    print(term)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89f9d3df-d541-4500-84bb-1e8d8101d2ef",
   "metadata": {
    "id": "89f9d3df-d541-4500-84bb-1e8d8101d2ef"
   },
   "source": [
    "<div style=\"background-color: #F8F7FF; border-color: #7C9DBF; border-left: 5px solid #7C9DBF; padding: 0.5em;\">\n",
    "\n",
    "<i>Análisis</i>: ¿Crees que estos términos son importantes para realizar un buen análisis de sentimientos?\n",
    "<br>\n",
    "\n",
    "<b>Salida esperada:</b> Argumentos a favor y/o en contra de incorporar los términos del vocabulario que no están definidos en *Wordnet*.\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2a408c8",
   "metadata": {},
   "source": [
    "Incorporar términos específicos del sector tecnológico, como \"netbook\" o \"Logitech\", en el análisis de sentimientos es beneficioso ya que aportan relevancia contextual al referirse directamente a productos o marcas específicas, lo cual es esencial para interpretar correctamente el sentimiento hacia estos. Además, la inclusión de jerga técnica y nombres propios enriquece el léxico del análisis, permitiendo captar matices y opiniones específicas que se perderían con un vocabulario más genérico. También facilitan la identificación de aspectos concretos de los productos o servicios evaluados, lo cual resulta vital en análisis de sentimientos basados en aspectos para comprender las opiniones sobre características específicas.\n",
    "\n",
    "Sin embargo, la inclusión de términos altamente especializados en análisis de sentimientos generales puede resultar contraproducente por varias razones. Primero, puede llevar a una falta de relevancia y complicaciones innecesarias en el modelo, especialmente si el análisis no está destinado a un dominio específico. Además, la interpretación de términos técnicos y nombres propios suele requerir conocimiento especializado, lo que puede no ser adecuado para aplicaciones dirigidas a un público general. Por último, la ambigüedad y variabilidad inherentes a los nombres de marca y la jerga técnica, junto con la aparición constante de nuevos términos, exigen actualizaciones frecuentes del léxico y complican la gestión eficaz del vocabulario.\n",
    "\n",
    "La decisión de incorporar términos del vocabulario que no están definidos en WordNet depende en gran medida del objetivo y del contexto específico del análisis de sentimientos. Para análisis centrados en el ámbito tecnológico o cuando es crucial capturar opiniones sobre productos o marcas específicas, la inclusión de estos términos puede ser beneficiosa. Pero , para análisis más generales o aplicaciones destinadas a un público más amplio, podría ser preferible limitar la incorporación de términos altamente especializados para mantener la claridad y la generalización del análisis."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5f788a4",
   "metadata": {
    "id": "f5f788a4"
   },
   "source": [
    "## 3.2 LDA (1 punto)\n",
    "\n",
    "Recordad que en el notebook del módulo 1 hemos visto la aplicación del método LDA para extraer temas de documentos."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c6825ff",
   "metadata": {
    "id": "1c6825ff"
   },
   "source": [
    "> <br>\n",
    "> <i>Primer paso</i>: Convertir las opiniones transformadas (opinion_sentences_transformed) en listas de nombres y colocaciones. Esto es necesario ya que los nombres y las colocaciones expresan los temas de las opiniones (e.g: [['Now we are taking all our computers off line to do a complete virus scan just in case'] -> ['computer', 'line', 'virus_scan', 'case'].\n",
    "> <br>\n",
    "> <br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "76ad1379",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "76ad1379",
    "outputId": "0de5085b-e325-4378-dc07-9dca5eb1057c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['top', 'line', 'system', 'pro'],\n",
       " [],\n",
       " ['application', 'file', 'direction', 'back', 'case', 'system'],\n",
       " ['minute', 'window', 'file', 'version', 'volume'],\n",
       " ['computer', 'line', 'virus', 'case'],\n",
       " ['avoid'],\n",
       " ['headache', 'waste', 'time', 'money'],\n",
       " ['complaint'],\n",
       " ['problem'],\n",
       " ['start', 'button', 'utility', 'window'],\n",
       " ['course', 'point', 'year'],\n",
       " ['graphic', 'document'],\n",
       " ['feature', 'business'],\n",
       " ['build', 'cd', 'drive', 'build'],\n",
       " ['expectation']]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "lem = WordNetLemmatizer()\n",
    "\n",
    "def get_noun_and_collocation(sentence):\n",
    "    nouns_and_collocations = []\n",
    "    noun_tags = ['NN', 'NNS']\n",
    "    tokens_pos_tagged = pos_tag(word_tokenize(sentence))\n",
    "    for tpos in tokens_pos_tagged:\n",
    "        lemma = lem.lemmatize(tpos[0]).lower()\n",
    "        if '_' in lemma:\n",
    "            nouns_and_collocations.append(lemma)\n",
    "        elif tpos[1] in noun_tags and tpos[0] not in stopwords:\n",
    "            nouns_and_collocations.append(lemma)\n",
    "    return nouns_and_collocations\n",
    "\n",
    "noun_and_collocation_stream = [get_noun_and_collocation(opinion) for opinion in opinion_sentences_transformed]\n",
    "\n",
    "noun_and_collocation_stream[:15]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eef21d0c",
   "metadata": {
    "id": "eef21d0c"
   },
   "source": [
    "<div style=\"background-color: #EDF7FF; border-color: #7C9DBF; border-left: 5px solid #7C9DBF; padding: 0.5em;\">\n",
    "\n",
    "<strong>Ejercicio:</strong> Extrae temas a partir de las listas de nombres y colocaciones de cada oración transformada. Experimenta con el parámetro <i>num_topics</i> hasta encontrar un conjunto de temas informativos, asignando nombres a los temas encontrados. Prueba con al menos 3 valores diferentes para el parámetro *num_topics* ( n1, n2, n3).\n",
    "<br>\n",
    "<b>Importante:</b> Para cada valor diferente de <i>num_topics<i> genera un modelo diferente, cuyos nombres sean: <i>ldamodel1</i> (n1), <i>ldamodel2</i> (n2) y <i>ldamodel3</i> (n3).\n",
    "\n",
    "<b>Salida esperada:</b> Por cada experimento, imprime las 10 palabras que más se destaquen de cada tópico.\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "35cbb841",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim import corpora, models\n",
    "import gensim\n",
    "\n",
    "# Crear un diccionario Gensim a partir de las listas de nombres y colocaciones\n",
    "dictionary = corpora.Dictionary(noun_and_collocation_stream)\n",
    "\n",
    "# Filtrar tokens que aparezcan en menos de 15 documentos o en más del 50% de los documentos\n",
    "dictionary.filter_extremes(no_below=15, no_above=0.5)\n",
    "\n",
    "# Convertir el stream de documentos (listas de tokens) a un corpus para LDA\n",
    "corpus = [dictionary.doc2bow(text) for text in noun_and_collocation_stream]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "3284e474",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3284e474",
    "outputId": "4f6f8e10-f04f-4420-cb1c-f9293265f5c6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modelo con 5 tópicos:\n",
      "Tópico 0: 0.157*\"program\" + 0.050*\"support\" + 0.026*\"..\" + 0.024*\"review\" + 0.023*\"account\" + 0.019*\"error\" + 0.015*\"company\" + 0.015*\"experience\" + 0.014*\"question\" + 0.013*\"device\"\n",
      "\n",
      "Tópico 1: 0.099*\"product\" + 0.042*\"thing\" + 0.023*\"work\" + 0.022*\"hour\" + 0.021*\"lot\" + 0.019*\"bit\" + 0.017*\"card\" + 0.014*\"nothing\" + 0.013*\"option\" + 0.013*\"upgrade\"\n",
      "\n",
      "Tópico 2: 0.133*\"software\" + 0.107*\"year\" + 0.035*\"user\" + 0.034*\"product\" + 0.033*\"tax\" + 0.030*\"game\" + 0.023*\"customer\" + 0.018*\"business\" + 0.017*\"service\" + 0.016*\"interface\"\n",
      "\n",
      "Tópico 3: 0.106*\"version\" + 0.091*\"time\" + 0.032*\"money\" + 0.032*\"price\" + 0.030*\"file\" + 0.021*\"everything\" + 0.018*\"drive\" + 0.017*\"tool\" + 0.016*\"word\" + 0.015*\"window\"\n",
      "\n",
      "Tópico 4: 0.094*\"computer\" + 0.062*\"problem\" + 0.037*\"system\" + 0.033*\"pc\" + 0.031*\"issue\" + 0.031*\"feature\" + 0.030*\"day\" + 0.020*\"something\" + 0.020*\"help\" + 0.019*\"installation\"\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Experimento 1: con n1 tópicos:\n",
    "\n",
    "# Definir n1\n",
    "n1 = 5\n",
    "\n",
    "# Entrenar el modelo LDA\n",
    "ldamodel1 = gensim.models.ldamodel.LdaModel(corpus, num_topics=n1, id2word=dictionary, passes=15)\n",
    "\n",
    "# Imprimir las 10 palabras más destacadas de cada tópico para n1\n",
    "print(f\"Modelo con {n1} tópicos:\")\n",
    "for idx, topic in ldamodel1.print_topics(-1):\n",
    "    print(f\"Tópico {idx}: {topic}\\n\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "187a952a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Experimento con 5 tópicos:\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.corpus import wordnet as wn\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk import pos_tag, word_tokenize\n",
    "from gensim import corpora, models\n",
    "import gensim\n",
    "import re\n",
    "from gensim.models.ldamodel import LdaModel\n",
    "import gensim.corpora as corpora\n",
    "\n",
    "# Asumiendo que 'opinion_sentences_transformed' y 'stopwords' ya están definidos\n",
    "\n",
    "lem = WordNetLemmatizer()\n",
    "\n",
    "def isnp(t):\n",
    "    if ' ' in t:  # Si el término es una multipalabra, asumimos que es nominal\n",
    "        return True\n",
    "    elif wn.synsets(t) == []:  # Si no tiene synset en WordNet, asumimos que es nominal\n",
    "        return True\n",
    "    else:\n",
    "        try:\n",
    "            wn.synset(t + '.n.01')  # Si existe un synset nominal, el término es nominal\n",
    "            return True\n",
    "        except:\n",
    "            return False\n",
    "\n",
    "def get_nominals(sentence):\n",
    "    nps = [lem.lemmatize(token).lower() for token in word_tokenize(sentence) if isnp(token) and token.lower() not in stopwords]\n",
    "    return nps\n",
    "\n",
    "# Transformar las opiniones en listas de nombres y colocaciones\n",
    "nps_in_sentences = [get_nominals(sentence) for sentence in opinion_sentences_transformed if len(get_nominals(sentence)) > 0]\n",
    "\n",
    "# Creación del modelo LDA\n",
    "def perform_lda(terms, num_topics):\n",
    "    # Creación del diccionario y corpus\n",
    "    dictionary = corpora.Dictionary(terms)\n",
    "    corpus = [dictionary.doc2bow(text) for text in terms]\n",
    "    \n",
    "    # Entrenamiento del modelo LDA\n",
    "    lda_model = LdaModel(corpus=corpus,\n",
    "                         id2word=dictionary,\n",
    "                         num_topics=num_topics,\n",
    "                         random_state=100,\n",
    "                         update_every=1,\n",
    "                         chunksize=100,\n",
    "                         passes=10,\n",
    "                         alpha='auto')\n",
    "    \n",
    "    # Imprimir los temas\n",
    "    for idx, topic in lda_model.print_topics(-1, num_words=10):\n",
    "        print(f\"Tópico {idx + 1}: {topic}\")\n",
    "\n",
    "# Experimentos con diferentes números de temas\n",
    "num_topics_values = [5, 10, 15]  # Ejemplo de valores para n1, n2, n3\n",
    "\n",
    "for num_topics in num_topics_values:\n",
    "    print(f\"\\nExperimento con {num_topics} tópicos:\")\n",
    "    perform_lda(nps_in_sentences, num_topics)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "xs2hNFPBP4uF",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xs2hNFPBP4uF",
    "outputId": "61f44657-7fa9-48cd-daf6-4f1ac3380aa3"
   },
   "outputs": [],
   "source": [
    "#Experimento 2: con n2 tópicos:\n",
    "\n",
    "#############################################\n",
    "# SOLUCIÓN                                 #\n",
    "#############################################\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "nNirywI8P_s4",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "nNirywI8P_s4",
    "outputId": "661604eb-4472-44c4-9d2d-45d15133fedd"
   },
   "outputs": [],
   "source": [
    "#Experimento 3: con n3 tópicos:\n",
    "\n",
    "#############################################\n",
    "# SOLUCIÓN                                 #\n",
    "#############################################\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30283ece-3d7f-4a0a-be7b-da947f9d8f30",
   "metadata": {
    "id": "30283ece-3d7f-4a0a-be7b-da947f9d8f30"
   },
   "source": [
    "Usa la librería pyLDAvis para visualizar los tópicos del mejor modelo que encontraste. Para ejecutar las siguientes líneas es importante que los modelos previamente creados se denominen: *ldamodel1*, *ldamodel2* y *ldamodel3*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "lGhUAJ-Qoyo4",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 905
    },
    "id": "lGhUAJ-Qoyo4",
    "outputId": "eeee6466-da0c-49db-b6da-36876290e4bb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pyLDAvis in /usr/local/lib/python3.10/dist-packages (3.4.1)\n",
      "Requirement already satisfied: numpy>=1.24.2 in /usr/local/lib/python3.10/dist-packages (from pyLDAvis) (1.25.2)\n",
      "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from pyLDAvis) (1.11.4)\n",
      "Collecting pandas>=2.0.0 (from pyLDAvis)\n",
      "  Using cached pandas-2.2.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (13.0 MB)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from pyLDAvis) (1.3.2)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from pyLDAvis) (3.1.3)\n",
      "Requirement already satisfied: numexpr in /usr/local/lib/python3.10/dist-packages (from pyLDAvis) (2.9.0)\n",
      "Requirement already satisfied: funcy in /usr/local/lib/python3.10/dist-packages (from pyLDAvis) (2.0)\n",
      "Requirement already satisfied: scikit-learn>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from pyLDAvis) (1.2.2)\n",
      "Requirement already satisfied: gensim in /usr/local/lib/python3.10/dist-packages (from pyLDAvis) (4.3.2)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from pyLDAvis) (67.7.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas>=2.0.0->pyLDAvis) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=2.0.0->pyLDAvis) (2023.4)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas>=2.0.0->pyLDAvis) (2024.1)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=1.0.0->pyLDAvis) (3.3.0)\n",
      "Requirement already satisfied: smart-open>=1.8.1 in /usr/local/lib/python3.10/dist-packages (from gensim->pyLDAvis) (6.4.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->pyLDAvis) (2.1.5)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas>=2.0.0->pyLDAvis) (1.16.0)\n",
      "Installing collected packages: pandas\n",
      "  Attempting uninstall: pandas\n",
      "    Found existing installation: pandas 1.5.3\n",
      "    Uninstalling pandas-1.5.3:\n",
      "      Successfully uninstalled pandas-1.5.3\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "bigframes 0.25.0 requires pandas<2.1.4,>=1.5.0, but you have pandas 2.2.1 which is incompatible.\n",
      "google-colab 1.0.0 requires pandas==1.5.3, but you have pandas 2.2.1 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed pandas-2.2.1\n",
      "Collecting pandas==1.5.3\n",
      "  Using cached pandas-1.5.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (12.1 MB)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas==1.5.3) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas==1.5.3) (2023.4)\n",
      "Requirement already satisfied: numpy>=1.21.0 in /usr/local/lib/python3.10/dist-packages (from pandas==1.5.3) (1.25.2)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas==1.5.3) (1.16.0)\n",
      "Installing collected packages: pandas\n",
      "  Attempting uninstall: pandas\n",
      "    Found existing installation: pandas 2.2.1\n",
      "    Uninstalling pandas-2.2.1:\n",
      "      Successfully uninstalled pandas-2.2.1\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "pyldavis 3.4.1 requires pandas>=2.0.0, but you have pandas 1.5.3 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed pandas-1.5.3\n"
     ]
    },
    {
     "data": {
      "application/vnd.colab-display-data+json": {
       "id": "52a1094b62794dd49191a9cf5ed654c4",
       "pip_warning": {
        "packages": [
         "pandas"
        ]
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#!pip install pyLDAvis\n",
    "\n",
    "#Instalar la versión pandas 1.5.3 si usas Google Colab como entorno de ejecución.\n",
    "#!pip install pandas==1.5.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "0aeb8277",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 973
    },
    "id": "0aeb8277",
    "outputId": "62582306-1ad9-4618-94ad-484f1c96b69d"
   },
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name '_fit_context' from 'sklearn.base' (/Users/alex/anaconda3/envs/env_nlp/lib/python3.8/site-packages/sklearn/base.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[54], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpyLDAvis\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mgensim\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# Modelo 1: con n1 tópicos:\u001b[39;00m\n\u001b[1;32m      5\u001b[0m pyLDAvis\u001b[38;5;241m.\u001b[39menable_notebook()\n",
      "File \u001b[0;32m~/anaconda3/envs/env_nlp/lib/python3.8/site-packages/pyLDAvis/__init__.py:44\u001b[0m\n\u001b[1;32m     36\u001b[0m __all__ \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__version__\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     37\u001b[0m            \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mprepare\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mjs_PCoA\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     38\u001b[0m            \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPreparedData\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mprepared_data_to_html\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     39\u001b[0m            \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdisplay\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mshow\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msave_html\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msave_json\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     40\u001b[0m            \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124menable_notebook\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdisable_notebook\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m     42\u001b[0m __version__ \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m3.4.0\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m---> 44\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpyLDAvis\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_display\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n\u001b[1;32m     45\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpyLDAvis\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_prepare\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m prepare, js_PCoA, PreparedData\n",
      "File \u001b[0;32m~/anaconda3/envs/env_nlp/lib/python3.8/site-packages/pyLDAvis/_display.py:11\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpyLDAvis\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_server\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m serve\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpyLDAvis\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m get_id, write_ipynb_local_js, NumPyEncoder\n\u001b[0;32m---> 11\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpyLDAvis\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_prepare\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m PreparedData\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpyLDAvis\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01murls\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01murls\u001b[39;00m\n\u001b[1;32m     14\u001b[0m __all__ \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mprepared_data_to_html\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdisplay\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     15\u001b[0m            \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mshow\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msave_html\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msave_json\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     16\u001b[0m            \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124menable_notebook\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdisable_notebook\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[0;32m~/anaconda3/envs/env_nlp/lib/python3.8/site-packages/pyLDAvis/_prepare.py:14\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mscipy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mstats\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m entropy\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mscipy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mspatial\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdistance\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m pdist, squareform\n\u001b[0;32m---> 14\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmanifold\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m MDS, TSNE\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpyLDAvis\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m NumPyEncoder\n\u001b[1;32m     19\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__num_dist_rows__\u001b[39m(array, ndigits\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m):\n",
      "File \u001b[0;32m~/anaconda3/envs/env_nlp/lib/python3.8/site-packages/sklearn/manifold/__init__.py:5\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;124;03mThe :mod:`sklearn.manifold` module implements data embedding techniques.\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m----> 5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_isomap\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Isomap\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_locally_linear\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m LocallyLinearEmbedding, locally_linear_embedding\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_mds\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m MDS, smacof\n",
      "File \u001b[0;32m~/anaconda3/envs/env_nlp/lib/python3.8/site-packages/sklearn/manifold/_isomap.py:12\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mscipy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msparse\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m issparse\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mscipy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msparse\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcsgraph\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m connected_components, shortest_path\n\u001b[0;32m---> 12\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbase\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m     13\u001b[0m     BaseEstimator,\n\u001b[1;32m     14\u001b[0m     ClassNamePrefixFeaturesOutMixin,\n\u001b[1;32m     15\u001b[0m     TransformerMixin,\n\u001b[1;32m     16\u001b[0m     _fit_context,\n\u001b[1;32m     17\u001b[0m )\n\u001b[1;32m     18\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdecomposition\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m KernelPCA\n\u001b[1;32m     19\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmetrics\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpairwise\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _VALID_METRICS\n",
      "\u001b[0;31mImportError\u001b[0m: cannot import name '_fit_context' from 'sklearn.base' (/Users/alex/anaconda3/envs/env_nlp/lib/python3.8/site-packages/sklearn/base.py)"
     ]
    }
   ],
   "source": [
    "import pyLDAvis.gensim\n",
    "\n",
    "# Modelo 1: con n1 tópicos:\n",
    "\n",
    "pyLDAvis.enable_notebook()\n",
    "\n",
    "pyLDAvis.gensim.prepare(ldamodel1, corpus, dictionary)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "B0_drQA8zqjm",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 973
    },
    "id": "B0_drQA8zqjm",
    "outputId": "aeeb81dc-d4ef-4642-d7be-42b5c36d8837"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n",
      "/usr/local/lib/python3.10/dist-packages/pandas/core/dtypes/cast.py:1641: DeprecationWarning: np.find_common_type is deprecated.  Please use `np.result_type` or `np.promote_types`.\n",
      "See https://numpy.org/devdocs/release/1.25.0-notes.html and the docs for more information.  (Deprecated NumPy 1.25)\n",
      "  return np.find_common_type(types, [])\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<link rel=\"stylesheet\" type=\"text/css\" href=\"https://cdn.jsdelivr.net/gh/bmabey/pyLDAvis@3.4.0/pyLDAvis/js/ldavis.v1.0.0.css\">\n",
       "\n",
       "\n",
       "<div id=\"ldavis_el362101338300619838883656436106\" style=\"background-color:white;\"></div>\n",
       "<script type=\"text/javascript\">\n",
       "\n",
       "var ldavis_el362101338300619838883656436106_data = {\"mdsDat\": {\"x\": [0.07726448038243104, 0.21404287486405332, -0.18414028430046056, -0.22835395559845573, 0.013126290948733608, 0.10806059370369847], \"y\": [-0.30803992316147594, 0.03515054949240085, -0.0820572090460017, 0.07098639601007607, 0.1401822052060913, 0.14377798149890922], \"topics\": [1, 2, 3, 4, 5, 6], \"cluster\": [1, 1, 1, 1, 1, 1], \"Freq\": [18.26035664068688, 17.90519061394457, 17.41886365017562, 17.048417873142352, 15.515975722447337, 13.851195499603245]}, \"tinfo\": {\"Term\": [\"program\", \"product\", \"software\", \"computer\", \"version\", \"year\", \"pc\", \"money\", \"problem\", \"issue\", \"..\", \"feature\", \"game\", \"price\", \"review\", \"upgrade\", \"lot\", \"company\", \"tax\", \"way\", \"cd\", \"time\", \"option\", \"day\", \"work\", \"update\", \"help\", \"file\", \"everything\", \"thing\", \"cd\", \"point\", \"company\", \"week\", \"place\", \"wife\", \"difference\", \"comment\", \"game\", \"sound\", \"fix\", \"unit\", \"player\", \"mind\", \"task\", \"chance\", \"entry\", \"capability\", \"phone\", \"session\", \"money_back\", \"tutorial\", \"error_message\", \"past\", \"would_like\", \"dollar\", \"star\", \"expense\", \"instruction\", \"lack\", \"computer\", \"product\", \"info\", \"disk\", \"suite\", \"trouble\", \"device\", \"tablet\", \"problem\", \"way\", \"time\", \"format\", \"order\", \"number\", \"anyone\", \"part\", \"people\", \"subscription\", \"support\", \"one\", \"image\", \"operating_system\", \"day\", \"state\", \"date\", \"many_years\", \"kid\", \"user_friendly\", \"improvement\", \"setting\", \"new_version\", \"xp\", \"drive\", \"pain\", \"app\", \"hard_drive\", \"look\", \"64_bit\", \"daughter\", \"internet\", \"husband\", \"junk\", \"great_product\", \"works_great\", \"voice\", \"mess\", \"others\", \"scan\", \"web_site\", \"program\", \"music\", \"list\", \"account\", \"bug\", \"information\", \"interface\", \"photo\", \"house\", \"access\", \"thing\", \"user\", \"end\", \"virus\", \"system\", \"file\", \"way\", \"issue\", \"refund\", \"question\", \"help\", \"word\", \"item\", \"piece\", \"tech_support\", \"try\", \"answer\", \"project\", \"mistake\", \"download\", \"stuff\", \"every_time\", \"message\", \"matter\", \"person\", \"practice\", \"response\", \"deal\", \"difficulty\", \"patch\", \"glitch\", \"direction\", \"seller\", \"category\", \"customer_service\", \"camera\", \"reviewer\", \"update\", \"picture\", \"nothing\", \"something\", \"backup\", \"store\", \"software\", \"video\", \"box\", \"need\", \"purchase\", \"someone\", \"example\", \"data\", \"problem\", \"price\", \"year\", \"pc\", \"review\", \"card\", \"version\", \"set\", \"complaint\", \"windows\", \"last_year\", \"child\", \"line\", \"button\", \"addition\", \"key\", \"quality\", \"none\", \"older_version\", \"install\", \"minute\", \"crash\", \"tax\", \"mouse\", \"color\", \"font\", \"technical_support\", \"alternative\", \"object\", \"choice\", \"professional\", \"etc\", \"school\", \"feature\", \"hardware\", \"everything\", \"hour\", \"lot\", \"installation\", \"software\", \"time\", \"function\", \"user\", \"cost\", \"thing\", \"anything\", \"code\", \"screen\", \"kind\", \"step\", \"password\", \"family\", \"menu\", \"name\", \"fun\", \"value\", \"apps\", \"icon\", \"server\", \"several_years\", \"speed\", \"license\", \"effect\", \"side\", \"service\", \"room\", \"story\", \"partition\", \"space\", \"effort\", \"good_product\", \"accountant\", \"pcs\", \"operation\", \"success\", \"desktop\", \"experience\", \"process\", \"idea\", \"option\", \"friend\", \"ease\", \"hand\", \"tool\", \"search\", \"file\", \"reason\", \"application\", \"fact\", \"system\", \"use\", \"window\", \"lot\", \"time\", \"customer\", \"thing\", \"..\", \"upgrade\", \"email\", \"disc\", \"money\", \"much_better\", \"solution\", \"job\", \"package\", \"book\", \"even_though\", \"area\", \"world\", \"month\", \"learning_curve\", \"10_years\", \"waste\", \"next_year\", \"song\", \"new_computer\", \"guy\", \"trial\", \"mac\", \"_1\", \"investment\", \"go_back\", \"release\", \"trial_version\", \"works_well\", \"malware\", \"laptop\", \"thanks\", \"driver\", \"business\", \"bit\", \"case\", \"life\", \"make_sure\", \"long_time\", \"work\", \"office\", \"home\", \"support\", \"error\", \"return\", \"time\", \"course\"], \"Freq\": [3970.0, 3982.0, 4208.0, 2465.0, 1818.0, 1492.0, 1112.0, 917.0, 1855.0, 925.0, 797.0, 1017.0, 856.0, 726.0, 683.0, 606.0, 966.0, 616.0, 570.0, 1076.0, 575.0, 2029.0, 566.0, 563.0, 683.0, 543.0, 500.0, 970.0, 607.0, 1064.0, 574.1034484358515, 322.389533050739, 614.3565733793447, 202.0954562492861, 200.46462692241082, 166.33479810760676, 172.80181285219393, 147.14662874580793, 851.7966971372899, 139.23560681492344, 137.04062580765085, 135.0425758102067, 127.37172696360676, 124.72500319586361, 124.16130364210788, 115.55422848116324, 106.16941872047653, 101.70854106873391, 232.21033224131696, 96.51543152491325, 90.66028061744727, 88.93734541605967, 88.59969212171191, 94.43528215391099, 85.23996464019497, 79.82638790910964, 79.40456228320559, 82.13150014171836, 254.73296117685229, 75.97605183732884, 2437.723262809807, 3905.8268541057787, 92.45448121437771, 274.1039944384424, 120.49472719271017, 140.86676883876137, 247.8703612129555, 123.09100898249727, 1316.1351257553042, 771.2950197008674, 1071.4262387568779, 194.0171645223992, 247.44099445589754, 258.0779988078635, 233.0285449715176, 225.06277306354502, 290.3899884800046, 162.02882928009953, 161.46259611101266, 324.43587476603386, 264.1342759024495, 226.13319985492205, 561.4884935146935, 208.09872566637554, 206.28723468620112, 218.88419115851673, 174.83806426387645, 196.87717133704035, 164.88576316617792, 171.58356708229135, 203.23176880457757, 150.52979627080137, 230.74451266404188, 129.13143882394468, 323.35471171725567, 199.7898506216082, 132.54317692242802, 117.57643973078805, 114.84053309739645, 188.48744244065372, 111.81300554232041, 110.85866911243843, 148.18531897596992, 106.77698834583626, 106.40833627170393, 101.51353309581113, 240.17426667808076, 93.64365782765053, 93.50747103288404, 3910.2096387370784, 319.86968151781144, 150.26986945668838, 389.8485646227383, 188.44543457361132, 364.8462048750945, 312.54897002644645, 199.5599700556864, 125.1212517330915, 222.1843599757154, 640.1509765603984, 447.4246375305495, 202.17907942752623, 183.08360128211154, 213.78102996586586, 222.23305965749975, 203.0525118171784, 923.8436629537118, 403.6627794938937, 339.01625504485, 499.30713487072876, 359.9937739399101, 275.7061801637323, 292.0576852211952, 219.73821248317242, 156.35162815908592, 148.73985812922604, 207.28906334538252, 138.9005419516862, 311.01949521802885, 148.0243052320631, 128.63259549447272, 158.50440630400084, 125.60507728760506, 175.01784902526697, 117.47157502774124, 117.12799864063398, 114.55969984299954, 111.7801008756006, 108.59114953433453, 102.011109587035, 113.85014433569705, 104.64231180885027, 93.76211891889506, 192.20864688520896, 89.1094219858401, 89.4566440047757, 534.5121876798376, 267.9358576996241, 371.4321065527263, 413.2746180104308, 179.44970041772117, 175.695773793916, 3236.5739694373074, 359.15023332534537, 255.4672760421778, 268.75093309067205, 255.26360891405383, 203.73886895026965, 160.10435042237637, 300.9288745714654, 466.7268718774515, 724.8954738159752, 1489.075860760957, 1110.0668812970316, 681.9833317390148, 255.43244060441972, 1811.5948017031344, 203.02500984756952, 203.3892268844185, 295.1519929666416, 182.4067256034507, 159.8420903636817, 327.51663903433985, 156.77215410110756, 152.42099899204862, 147.35948924672113, 177.41334427564357, 140.39068646219891, 129.99777362521326, 223.2963122542214, 111.16097502221203, 128.6335884793002, 566.1246259602808, 103.90251894234488, 95.87721595762466, 94.6199623213712, 87.70805799543743, 101.57370421770882, 86.11568964143942, 139.39889790478242, 81.23682203669843, 227.6423382189171, 105.37862934561285, 945.2561951602918, 138.51999831041636, 537.472206089984, 290.94902552842484, 696.837333814944, 283.1139548622075, 868.2959644911482, 411.2051602186252, 150.7560500595069, 211.46541512276715, 160.4354463498013, 204.65319460250146, 363.57565533432677, 260.06992613170513, 367.41022210738583, 224.87505034877188, 224.81356773344456, 207.20090778442224, 175.30468086820383, 171.31223961249572, 172.73274752639566, 165.4428606713795, 151.77899091587463, 151.3586736637677, 144.1263551807074, 143.27977682544793, 138.71141989501828, 143.6647064180373, 133.0950605448731, 129.01562160593474, 118.33709452965428, 285.6918963702211, 111.80222172940069, 110.47442339461378, 99.31125500015527, 94.37142912517477, 92.19553747797164, 88.4529699213397, 91.88197034092313, 87.70047113037326, 87.73883071541361, 86.37785554375412, 286.4462435538908, 358.174898307961, 277.65528785751087, 163.47509804255574, 547.6979812398248, 254.40062301566144, 159.19964249389307, 187.25833071152965, 384.41711665167975, 155.58407038886864, 611.0970681106271, 288.5403927520198, 290.0020582101108, 231.48333695803694, 375.72190044872633, 233.1662151554064, 216.40545403318924, 266.65507521348553, 268.2394159582778, 184.8876764622008, 212.3244493969023, 795.9551281715242, 604.3264097052437, 281.16382949650273, 270.13002381083663, 913.675974277082, 198.54463492013025, 206.07231974250917, 202.7621366232835, 295.9882410844229, 336.67004167541285, 160.9728089344537, 196.9792942360172, 143.7668090101283, 255.14598896431312, 133.29301772743645, 131.57458935676436, 155.3723025363606, 123.09421225622536, 119.59572701176228, 117.57623525006623, 107.72853882749378, 106.94712383293884, 105.6394529298208, 102.61656967514558, 99.75871932088467, 114.55447145476099, 93.17867303234246, 100.30618671970645, 89.18041712325432, 91.41182966163511, 388.8050375514121, 234.36377578424103, 196.84521794615742, 404.95460431538476, 362.28303910920533, 310.20278673765654, 143.8926155365498, 111.72425815812511, 112.42190782583474, 517.6182894816791, 207.0773224804775, 189.64215045761568, 339.41050409654895, 218.911353960632, 156.27095016331853, 246.909666948154, 135.6324807430411], \"Total\": [3970.0, 3982.0, 4208.0, 2465.0, 1818.0, 1492.0, 1112.0, 917.0, 1855.0, 925.0, 797.0, 1017.0, 856.0, 726.0, 683.0, 606.0, 966.0, 616.0, 570.0, 1076.0, 575.0, 2029.0, 566.0, 563.0, 683.0, 543.0, 500.0, 970.0, 607.0, 1064.0, 575.3664453316385, 323.3907558226081, 616.7334439041232, 202.9428693886823, 201.33364291925324, 167.17995686361704, 173.74671436325463, 147.97917164944084, 856.6208228060109, 140.07046554311648, 137.87397223467372, 135.87854271873005, 128.20443312610382, 125.56846650844646, 125.00310266690651, 116.386988258608, 107.0032957101249, 102.54018983234627, 234.1869961977222, 97.35356288423591, 91.49039983031238, 89.77131304550022, 89.45141148413293, 95.35158483667283, 86.0886611818271, 80.65737651724798, 80.23511251980575, 83.00790952245498, 257.47272484966726, 76.81000973118623, 2465.029869961096, 3982.32255954234, 93.48639040461698, 282.010035170854, 123.1196832028847, 146.83291897138903, 270.35184115176713, 127.52798376288371, 1855.3767129182527, 1076.2617367991372, 2029.1233452351487, 241.56003329042383, 352.4140597754705, 404.1399023481492, 348.52418707188326, 338.35439834570786, 574.6051313701469, 210.90184008953355, 659.0139665532852, 325.57217318209877, 265.15306443886817, 227.00987101581853, 563.6735839832207, 208.93541262485815, 207.15637583753877, 219.81075244881, 175.66253867703685, 197.81649125573392, 165.7099409086594, 172.47670079442278, 204.3418102427149, 151.35515275927577, 232.1699271549819, 129.99086239722868, 325.5295077918424, 201.1351911570617, 133.48434233094807, 118.41802183406871, 115.66455384320054, 189.87783230647017, 112.64045581746963, 111.6847482878498, 149.29265993651399, 107.60041718603465, 107.2354788029286, 102.3406173750889, 242.18979897689943, 94.4733943710967, 94.37510398582188, 3970.1955243210555, 324.90481303369756, 152.46949198854608, 405.1764526420461, 192.62402329601585, 384.02057128259844, 338.5594283903987, 212.69522266942795, 127.40121977726258, 266.3071484312593, 1064.5426433322286, 827.1830208232111, 324.1211779233908, 299.16441307688507, 759.9454650171155, 970.9297983488034, 1076.2617367991372, 925.1780442920546, 404.59299062004845, 339.94379522553976, 500.6821867270074, 361.084432260068, 276.57113150115674, 293.04971628616767, 220.90097706995138, 157.21570480537287, 149.5842076475389, 208.49238149402782, 139.74467706218604, 312.9136670280294, 148.95065784550337, 129.46699016490828, 159.54206620758734, 126.43273687345312, 176.23529495570256, 118.30173585385023, 117.9759668937563, 115.39102208320504, 112.61460170851366, 109.43088751039846, 102.83796080936523, 114.78450690844261, 105.54165585322346, 94.59116921787981, 193.94610626886222, 89.9365833889122, 90.28828483130096, 543.0430472443102, 272.12372077344384, 386.8887337206915, 440.1569487424054, 186.45650365425416, 182.4580715681233, 4208.189014408939, 429.0839409213101, 295.7107920640439, 315.6946985308475, 305.24496450608063, 239.0327666421563, 176.10192019367108, 437.7029974719213, 1855.3767129182527, 726.1542902255952, 1492.0197031023336, 1112.285460064879, 683.5145104315068, 256.32729282192344, 1818.6690982022824, 203.86334543738155, 204.24981798743653, 296.4487914577743, 183.29124119713217, 160.67620725227084, 329.24825658668163, 157.60205746735352, 153.25125921052387, 148.19047443247655, 178.46738124200868, 141.23457482863333, 130.8342284701486, 224.91644582641658, 111.98982667716892, 129.61591266308284, 570.5688955825191, 104.74332630202451, 96.70588853846074, 95.44903739741207, 88.54382444660334, 102.55285566054413, 86.94658407021248, 140.76974885158378, 82.06757153576635, 229.9988068880762, 106.61098875008095, 1017.3744218254323, 142.2958131899257, 607.9897952205866, 322.832660222496, 966.2927186178224, 554.2674934491486, 4208.189014408939, 2029.1233452351487, 200.4473479460623, 827.1830208232111, 274.7367044108113, 1064.5426433322286, 364.6977281374731, 260.9450578868789, 368.7110677765328, 225.69722989293425, 225.64160139831978, 208.02399669601414, 176.1254635547752, 172.13605165481005, 173.57599025830342, 166.26596326661831, 152.60695797753812, 152.1870227134596, 144.94739701348004, 144.10057410527816, 139.53855596854467, 144.54376260699377, 133.93781988403492, 129.83709233937682, 119.15897526163118, 287.7424385020087, 112.63611487962602, 111.30962968886138, 100.13619947409964, 95.19165679589986, 93.01788618962834, 89.2720875198862, 92.73369318936334, 88.52148032916833, 88.56627971605587, 87.20227953600009, 289.3809794684004, 362.8755659348668, 281.11375372920423, 165.8065036489365, 566.9779200185371, 259.8586747721211, 163.2557842794237, 196.53088377902634, 443.7755359487609, 166.79774646009213, 970.9297983488034, 395.5337981793924, 407.8781526909743, 321.6678984620812, 759.9454650171155, 443.0412968812069, 406.44590433565514, 966.2927186178224, 2029.1233452351487, 388.8122777122515, 1064.5426433322286, 797.59679698663, 606.0764917938208, 282.01125015168503, 271.13517857774565, 917.6801819730994, 199.41481067180825, 207.0033708392982, 203.73819786749405, 297.48839908419217, 338.43889525744214, 161.84183293079937, 198.05801460653853, 144.59482276134682, 256.6751971798586, 134.12199818937813, 132.40613958287906, 156.41104688215836, 123.92039964545717, 120.42983775186103, 118.4022989205776, 108.55513367889357, 107.78038948050659, 106.46805093296162, 103.45754323386896, 100.59808640445888, 115.53677222459409, 94.0045826019072, 101.21974797970934, 90.00856322868384, 92.27485902300685, 392.5689790525364, 237.13913457878834, 199.1068008182573, 413.4295602615501, 370.91864352729266, 322.74412492002136, 146.6004472225593, 112.97289660032219, 113.7757484219908, 683.6988796331649, 283.9155430959466, 255.38784464178843, 659.0139665532852, 339.26316293433916, 281.03415755470456, 2029.1233452351487, 264.8452084102745], \"Category\": [\"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\"], \"logprob\": [30.0, 29.0, 28.0, 27.0, 26.0, 25.0, 24.0, 23.0, 22.0, 21.0, 20.0, 19.0, 18.0, 17.0, 16.0, 15.0, 14.0, 13.0, 12.0, 11.0, 10.0, 9.0, 8.0, 7.0, 6.0, 5.0, 4.0, 3.0, 2.0, 1.0, -4.1561, -4.7331, -4.0883, -5.2001, -5.2082, -5.3949, -5.3567, -5.5174, -3.7615, -5.5727, -5.5886, -5.6033, -5.6618, -5.6828, -5.6873, -5.7591, -5.8438, -5.8868, -5.0612, -5.9392, -6.0018, -6.0209, -6.0247, -5.961, -6.0634, -6.129, -6.1343, -6.1005, -4.9687, -6.1785, -2.71, -2.2386, -5.9822, -4.8954, -5.7173, -5.5611, -4.996, -5.6959, -3.3264, -3.8608, -3.5321, -5.2409, -4.9977, -4.9556, -5.0577, -5.0925, -4.8376, -5.4211, -5.4246, -4.7071, -4.9128, -5.0681, -4.1586, -5.1512, -5.16, -5.1007, -5.3254, -5.2066, -5.384, -5.3442, -5.1749, -5.4751, -5.0479, -5.6284, -4.7105, -5.192, -5.6023, -5.7221, -5.7457, -5.2502, -5.7724, -5.781, -5.4908, -5.8185, -5.8219, -5.869, -5.0079, -5.9497, -5.9512, -2.2179, -4.7213, -5.4768, -4.5235, -5.2504, -4.5898, -4.7445, -5.1931, -5.6599, -5.0857, -4.0275, -4.3857, -5.1801, -5.2793, -5.1243, -5.0855, -5.1758, -3.6331, -4.4611, -4.6356, -4.2485, -4.5756, -4.8424, -4.7847, -5.0693, -5.4096, -5.4595, -5.1276, -5.5279, -4.7218, -5.4643, -5.6047, -5.3959, -5.6285, -5.2968, -5.6955, -5.6984, -5.7206, -5.7452, -5.7741, -5.8366, -5.7268, -5.8111, -5.9209, -5.2031, -5.9718, -5.9679, -4.1803, -4.8709, -4.5443, -4.4376, -5.2718, -5.2929, -2.3794, -4.578, -4.9186, -4.8679, -4.9194, -5.1449, -5.3859, -4.7548, -4.3159, -3.8542, -3.1343, -3.428, -3.9152, -4.8972, -2.9382, -5.1269, -5.1251, -4.7527, -5.234, -5.366, -4.6487, -5.3854, -5.4135, -5.4473, -5.2617, -5.4958, -5.5727, -5.0317, -5.7292, -5.5832, -4.1014, -5.7967, -5.8771, -5.8903, -5.9662, -5.8194, -5.9845, -5.5029, -6.0428, -5.0124, -5.7826, -3.5887, -5.5092, -4.1533, -4.767, -3.8936, -4.7943, -3.6737, -4.4211, -5.4245, -5.0861, -5.3623, -5.1189, -4.45, -4.7851, -4.4395, -4.9305, -4.9307, -5.0123, -5.1795, -5.2025, -5.1943, -5.2374, -5.3236, -5.3264, -5.3753, -5.3812, -5.4136, -5.3785, -5.4549, -5.4861, -5.5725, -4.6911, -5.6293, -5.6412, -5.7477, -5.7988, -5.8221, -5.8635, -5.8255, -5.8721, -5.8716, -5.8873, -4.6885, -4.465, -4.7196, -5.2493, -4.0403, -4.8071, -5.2758, -5.1135, -4.3943, -5.2988, -3.9308, -4.6812, -4.6761, -4.9015, -4.4172, -4.8943, -4.9689, -4.7601, -4.7541, -5.1263, -4.9879, -3.553, -3.8284, -4.5936, -4.6336, -3.415, -4.9415, -4.9043, -4.9205, -4.5422, -4.4134, -5.1513, -4.9494, -5.2643, -4.6907, -5.34, -5.3529, -5.1867, -5.4196, -5.4484, -5.4654, -5.5529, -5.5602, -5.5725, -5.6015, -5.6298, -5.4915, -5.698, -5.6243, -5.7418, -5.7171, -4.2694, -4.7756, -4.9501, -4.2287, -4.3401, -4.4953, -5.2634, -5.5165, -5.5102, -3.9833, -4.8994, -4.9874, -4.4053, -4.8438, -5.1809, -4.7235, -5.3226], \"loglift\": [30.0, 29.0, 28.0, 27.0, 26.0, 25.0, 24.0, 23.0, 22.0, 21.0, 20.0, 19.0, 18.0, 17.0, 16.0, 15.0, 14.0, 13.0, 12.0, 11.0, 10.0, 9.0, 8.0, 7.0, 6.0, 5.0, 4.0, 3.0, 2.0, 1.0, 1.6982, 1.6973, 1.6966, 1.6963, 1.6961, 1.6954, 1.695, 1.6948, 1.6948, 1.6945, 1.6944, 1.6943, 1.6939, 1.6937, 1.6937, 1.6933, 1.6926, 1.6923, 1.692, 1.6918, 1.6913, 1.6911, 1.6909, 1.6908, 1.6905, 1.6901, 1.69, 1.6898, 1.6897, 1.6895, 1.6893, 1.681, 1.6893, 1.672, 1.6789, 1.659, 1.6136, 1.665, 1.357, 1.3673, 1.0618, 1.4813, 1.3468, 1.2519, 1.2979, 1.2927, 1.018, 1.4368, 0.294, 1.7166, 1.7162, 1.7162, 1.7162, 1.7161, 1.7159, 1.7159, 1.7154, 1.7153, 1.7151, 1.7149, 1.7146, 1.7146, 1.7139, 1.7134, 1.7134, 1.7134, 1.713, 1.7129, 1.7129, 1.7127, 1.7127, 1.7127, 1.7126, 1.7124, 1.7123, 1.712, 1.7117, 1.7113, 1.7108, 1.7049, 1.7045, 1.7055, 1.6815, 1.6981, 1.6689, 1.6401, 1.6563, 1.702, 1.5389, 1.2115, 1.1056, 1.2481, 1.229, 0.4518, 0.2456, 0.0523, 1.7462, 1.7453, 1.7449, 1.7449, 1.7446, 1.7445, 1.7442, 1.7423, 1.7421, 1.742, 1.7418, 1.7416, 1.7415, 1.7414, 1.7412, 1.7411, 1.741, 1.7407, 1.7406, 1.7404, 1.7404, 1.7402, 1.7399, 1.7395, 1.7394, 1.7391, 1.7388, 1.7386, 1.7384, 1.7384, 1.7318, 1.7321, 1.7068, 1.6846, 1.7093, 1.7099, 1.4851, 1.5697, 1.6013, 1.5866, 1.5688, 1.5879, 1.6524, 1.3729, 0.3675, 1.7674, 1.7671, 1.7671, 1.7669, 1.7656, 1.7652, 1.765, 1.7649, 1.7647, 1.7643, 1.7639, 1.7638, 1.7638, 1.7637, 1.7635, 1.7632, 1.7631, 1.7627, 1.7619, 1.7617, 1.7615, 1.7613, 1.7611, 1.7605, 1.7604, 1.7596, 1.7595, 1.7595, 1.7593, 1.7589, 1.7588, 1.7575, 1.6956, 1.7422, 1.6458, 1.6651, 1.4422, 1.0973, 0.1909, 0.1728, 1.4842, 0.4051, 1.2312, 0.1201, 1.8602, 1.8599, 1.8598, 1.8597, 1.8596, 1.8593, 1.8586, 1.8585, 1.8584, 1.8583, 1.8579, 1.8578, 1.8576, 1.8576, 1.8574, 1.8572, 1.857, 1.857, 1.8564, 1.8561, 1.8559, 1.8558, 1.855, 1.8546, 1.8544, 1.8541, 1.8541, 1.854, 1.8539, 1.8538, 1.8531, 1.8503, 1.8509, 1.8491, 1.8287, 1.8421, 1.8381, 1.815, 1.7197, 1.7937, 1.4003, 1.5479, 1.5222, 1.5343, 1.1589, 1.2214, 1.233, 0.5758, -0.1602, 1.12, 0.2511, 1.9747, 1.9739, 1.9738, 1.9731, 1.9724, 1.9724, 1.9723, 1.972, 1.9717, 1.9716, 1.9714, 1.9713, 1.9711, 1.9708, 1.9706, 1.9705, 1.9701, 1.9701, 1.9698, 1.9698, 1.9692, 1.969, 1.969, 1.9686, 1.9684, 1.9683, 1.968, 1.9677, 1.9676, 1.9674, 1.9672, 1.965, 1.9654, 1.9561, 1.9532, 1.9372, 1.9582, 1.9657, 1.9648, 1.6985, 1.6612, 1.6792, 1.3133, 1.5387, 1.3899, -0.1295, 1.3076]}, \"token.table\": {\"Topic\": [2, 6, 6, 2, 6, 1, 2, 3, 4, 6, 2, 5, 5, 4, 4, 3, 1, 2, 5, 2, 5, 3, 4, 5, 5, 6, 3, 5, 1, 2, 3, 4, 6, 2, 6, 1, 3, 4, 2, 4, 3, 5, 6, 4, 3, 1, 4, 1, 3, 6, 3, 1, 5, 1, 4, 4, 5, 5, 4, 1, 1, 6, 4, 1, 2, 3, 4, 5, 6, 1, 2, 3, 4, 5, 2, 3, 4, 6, 4, 1, 3, 4, 5, 6, 3, 6, 1, 3, 4, 5, 2, 2, 2, 3, 3, 3, 4, 5, 1, 2, 4, 1, 3, 3, 6, 1, 2, 1, 3, 6, 2, 5, 2, 6, 5, 6, 5, 5, 6, 1, 2, 3, 1, 2, 3, 6, 1, 4, 5, 6, 3, 1, 2, 3, 4, 6, 1, 2, 3, 1, 2, 5, 1, 3, 5, 6, 5, 1, 2, 3, 4, 5, 6, 1, 2, 3, 4, 5, 1, 4, 1, 2, 3, 1, 5, 5, 4, 5, 1, 2, 4, 3, 6, 5, 2, 6, 4, 5, 2, 2, 4, 3, 2, 4, 5, 6, 1, 3, 4, 5, 1, 2, 4, 2, 5, 3, 5, 2, 2, 1, 2, 3, 4, 5, 6, 2, 4, 1, 4, 5, 1, 3, 5, 1, 2, 4, 2, 6, 6, 3, 3, 6, 2, 4, 2, 5, 1, 1, 2, 3, 6, 4, 6, 5, 3, 4, 6, 2, 4, 2, 5, 4, 6, 2, 1, 4, 5, 6, 5, 6, 6, 2, 3, 5, 2, 3, 1, 4, 3, 1, 5, 6, 1, 1, 6, 4, 6, 1, 2, 5, 3, 4, 6, 6, 2, 6, 4, 1, 3, 4, 5, 6, 1, 3, 6, 4, 2, 5, 6, 4, 2, 2, 5, 1, 3, 4, 5, 6, 1, 2, 5, 2, 5, 4, 6, 2, 1, 2, 3, 5, 5, 5, 1, 3, 4, 5, 5, 1, 2, 3, 4, 2, 3, 1, 5, 2, 3, 2, 3, 3, 1, 1, 1, 3, 2, 4, 1, 2, 3, 4, 5, 1, 2, 5, 1, 2, 3, 4, 5, 6, 4, 1, 2, 3, 4, 5, 2, 3, 1, 3, 4, 3, 1, 5, 3, 6, 3, 3, 6, 4, 5, 3, 5, 2, 1, 4, 2, 5, 1, 5, 3, 5, 3, 5, 1, 4, 2, 5, 5, 1, 2, 3, 4, 5, 6, 6, 1, 3, 4, 2, 3, 6, 1, 5, 5, 1, 2, 5, 1, 3, 5, 3, 1, 3, 5, 5, 1, 6, 1, 3, 4, 6, 1, 2, 3, 5, 6, 1, 2, 1, 2, 4, 6, 3, 4, 1, 3, 6, 1, 2, 4, 5, 6, 1, 2, 3, 4, 5, 6, 2, 3, 5, 6, 6, 6, 1, 3, 3, 1, 1, 1, 2, 3, 3, 6, 1, 2, 3, 4, 5, 6, 2, 3, 4, 5, 6, 2, 5, 1, 2, 4, 2, 3, 5, 6, 1, 2, 4, 2, 6, 1, 2, 4, 5, 2, 1, 1, 1, 2, 4, 5, 6, 4, 3, 1, 2, 6, 2, 6, 6, 1, 2, 1, 2, 4, 5], \"Freq\": [0.0012537663187440844, 0.9979979897202912, 0.9969326227306489, 0.9964699474995921, 0.9955774782624146, 0.02253037530289486, 0.8336238862071098, 0.007510125100964954, 0.10138668886302687, 0.030040500403859815, 0.9625435966402179, 0.03455284705887962, 0.9920881702849349, 0.991835243527722, 0.9946090661543925, 0.99609445638195, 0.6685332285186384, 0.3299627522731477, 0.9980868316865135, 0.9922295591296754, 0.006143836279440714, 0.002451712584757248, 0.28439865983184076, 0.710996649579602, 0.9922002369696491, 0.9946580570918052, 0.9600094203842804, 0.032179086716791525, 0.0026960089967179523, 0.016176053980307713, 0.0026960089967179523, 0.0026960089967179523, 0.9759552568118987, 0.0029547431279709283, 0.9957484341262028, 0.13188561610410732, 0.8623290283730094, 0.00338168246420788, 0.9759945659067153, 0.020765841827802452, 0.01693154208801991, 0.0024187917268599876, 0.979610649378295, 0.9961798882766602, 0.989586180021292, 0.9947319208865374, 0.9948218825732087, 0.021689008287090143, 0.01549214877649296, 0.9605132241425636, 0.9937502705298196, 0.9976250868594694, 0.0017380227994067412, 0.9966749869173681, 0.9957914910749097, 0.9874280598919754, 0.0071037989920286, 0.9963783261712947, 0.9927006664317034, 0.9933830441235306, 0.9955678682076659, 0.0032428920788523316, 0.9938809346331294, 0.9890346683865852, 0.0016226983894775803, 0.0008113491947387901, 0.004056745973693951, 0.0032453967789551606, 0.0016226983894775803, 0.021839091405232314, 0.0036398485675387194, 0.17835257980939725, 0.5823757708061951, 0.21475106548478443, 0.030206323338903364, 0.26430532921540445, 0.19634110170287186, 0.5135074967613572, 0.9952481709195398, 0.010287740972419296, 0.27005320052600656, 0.1054493449672978, 0.4758080199743925, 0.1388845031276605, 0.9899657368415307, 0.005156071546049639, 0.006853962658074897, 0.687680920026848, 0.3015743569552955, 0.004569308438716598, 0.9944178602620194, 0.9942544727739024, 0.9952568577645101, 0.0017740763953021572, 0.9966113301005074, 0.003455652136629792, 0.003455652136629792, 0.9883165110761206, 0.9173231406283655, 0.0036988836315659896, 0.07767655626288579, 0.9957022821065067, 0.9945424332263372, 0.9931653937489284, 0.9958132375750712, 0.9715966307156368, 0.02482181173361116, 0.9918497656924484, 0.9938843609925865, 0.0031957696494938474, 0.9949609013995988, 0.004307190049348913, 0.005022430152512922, 0.9894187400450456, 0.973931800957572, 0.018376071716180605, 0.9935527488771176, 0.9890570917989552, 0.9964141496087794, 0.01851159507206949, 0.6232237007596729, 0.35480557221466524, 0.990623693378166, 0.09432205879125541, 0.25643809733872563, 0.6455165898526541, 0.9949535566108646, 0.9913094901877084, 0.008695697282348319, 0.9947984219187673, 0.9963929789028582, 0.0049342933443670065, 0.0065790577924893425, 0.0032895288962446713, 0.8832385086416942, 0.10033063133546247, 0.017035589371772318, 0.07382088727768005, 0.9085647664945237, 0.9878576688865737, 0.01102306238143895, 0.9865640831387861, 0.031087963852814544, 0.22694213612554617, 0.718131965000016, 0.021761574696970182, 0.9936098759823836, 0.001965844586903889, 0.011795067521423336, 0.022607212749394725, 0.9288615673120877, 0.001965844586903889, 0.032436435683914175, 0.015449108705397152, 0.22864680883987784, 0.11947310732173798, 0.006179643482158861, 0.629293694599844, 0.9936610788787159, 0.9952955272294423, 0.8031129875146061, 0.19042885270964888, 0.004139757667601063, 0.019241227965103223, 0.9774543806272438, 0.9923859144605065, 0.7533150303421928, 0.24445322176667184, 0.994605754748204, 0.00116737764641808, 0.0035021329392542393, 0.9918516391926655, 0.995354100566782, 0.9857504450133663, 0.9913414367654533, 0.9948861591333336, 0.04579432925218685, 0.9515043966843267, 0.9943560788615292, 0.021082840968734806, 0.976838298218046, 0.9966402105535171, 0.007831226277841202, 0.24276801461307726, 0.007831226277841202, 0.7439664963949142, 0.006195160051717202, 0.08982982074989943, 0.9013957875248528, 0.003097580025858601, 0.007849218412102447, 0.981152301512806, 0.007849218412102447, 0.9943141581519568, 0.9934638563161508, 0.0060311265118846505, 0.983073621437198, 0.9956513252399766, 0.9957157615000857, 0.984100462129474, 0.9504699156634469, 0.0026040271662012243, 0.010416108664804897, 0.028644298828213465, 0.0078120814986036725, 0.004446095510382413, 0.9914792988152782, 0.23995634160746995, 0.5105837945482256, 0.2471730736858901, 0.9903961677839428, 0.0038839065403291875, 0.0038839065403291875, 0.056120132557911734, 0.9245053416119143, 0.017722147123551073, 0.9901103131226016, 0.0052665442187372425, 0.9940546940221681, 0.9987266836915094, 0.9979349561971389, 0.9963767331054231, 0.9938689185556029, 0.9919665927446707, 0.9962283439484217, 0.9969107733698592, 0.9894543727566103, 0.0025473230269327336, 0.005094646053865467, 0.0025473230269327336, 0.9909086574768334, 0.9929552487685791, 0.9916344954256208, 0.9929980950500247, 0.006821261591936789, 0.006821261591936789, 0.9822616692388976, 0.003037221853099558, 0.9962087678166551, 0.9838033697342443, 0.006558689131561628, 0.008789219265700018, 0.9843925577584021, 0.9963715419914402, 0.002069766191409146, 0.7213135177060874, 0.276313786553121, 0.9956038367485817, 0.008851680625113299, 0.9913882300126895, 0.9861841130237978, 0.9963115887654367, 0.9965773352364724, 0.993400268892607, 0.9966717283535578, 0.9966023618693641, 0.9954728561696004, 0.9911614589776777, 0.9946711597332994, 0.0021794085121243554, 0.0010897042560621777, 0.9959896900408303, 0.9946398766294394, 0.0038959744104112848, 0.9934734746548777, 0.992903354053497, 0.9979198602630828, 0.012311298077277603, 0.9849038461822083, 0.9966816248177742, 0.8520890634269399, 0.07285519873167144, 0.07285519873167144, 0.9966022710348938, 0.9934335012442088, 0.9925726543160732, 0.9912586926386029, 0.012923612305572265, 0.9589320330734621, 0.002584722461114453, 0.015508334766686718, 0.007754167383343359, 0.6383927904692372, 0.3563122551456208, 0.002474390660733478, 0.9891130389958956, 0.0035221741969303152, 0.267685238966704, 0.7290900587645752, 0.9936237750632746, 0.995171045588041, 0.9955514224500477, 0.9936061476459057, 0.014109896906987917, 0.0035274742267469793, 0.014109896906987917, 0.9665279381286723, 0.0017637371133734897, 0.7008800958661191, 0.2951074087857344, 0.002837571238324369, 0.9909583352141587, 0.004128993063392328, 0.0033614756174642968, 0.9949967827694318, 0.992377445776144, 0.6649832279411071, 0.31328098738558824, 0.017732886078429523, 0.002955481013071587, 0.9886534591879181, 0.9950775068632562, 0.9858252504246474, 0.9960624690139928, 0.9979452576277085, 0.0008990497816465842, 0.9941089967403482, 0.5046944138986272, 0.0034806511303353605, 0.23494395129763684, 0.255827858079649, 0.005674232282763529, 0.9929906494836176, 0.9906613252092112, 0.004270091919005221, 0.9403126101747996, 0.05641875661048797, 0.011024397253841921, 0.984846154676545, 0.9964179583605445, 0.993375955950948, 0.9906053706823139, 0.9956994570884673, 0.9889964771484131, 0.0013771178019058854, 0.9984104063817668, 0.7092899198514315, 0.015630248993686563, 0.2517009062086767, 0.01886409361306999, 0.00485076692907514, 0.007114557624692359, 0.0035572788123461796, 0.9889235098322379, 0.9808346615822322, 0.004268865654607769, 0.001506658466332154, 0.002259987699498231, 0.001506658466332154, 0.009542170286770308, 0.9869915544497246, 0.004030028219513488, 0.9848381461436085, 0.001007507054878372, 0.008815686730185754, 0.0012593838185979648, 0.0047963383258138115, 0.9928420334434591, 0.16052680862168292, 0.8353946162965131, 0.9917778742995121, 0.9972236727400375, 0.26799226889815425, 0.7306581670902507, 0.9985343527105112, 0.9893134720233647, 0.9917274092389071, 0.4412275044390746, 0.5550926668749648, 0.9977842307538568, 0.0014630267313106404, 0.9857314286819375, 0.9943524785073967, 0.9949891249885954, 0.009379896122567765, 0.9848890928696155, 0.0027121507527028636, 0.995359326241951, 0.06594813319394485, 0.9352644343868544, 0.9948678476868248, 0.9923624585667917, 0.0034753302474463425, 0.993944450769654, 0.9963682594271733, 0.9957650776527321, 0.9972361438256465, 0.9961404504668511, 0.9902737057020968, 0.01140633175830431, 0.0002376319116313398, 0.7692144979506469, 0.20626449929600293, 0.009505276465253593, 0.003326846762838757, 0.9951528768095417, 0.08367053722781435, 0.8534394797237064, 0.06275290292086076, 0.0590698387797487, 0.9383016698475467, 0.9964308035293821, 0.9923576641302233, 0.9874814995766396, 0.9962380762947743, 0.9846063340473179, 0.9955229579653035, 0.9971565465129492, 0.03288426731924444, 0.9646051746978369, 0.988234354093872, 0.9936176324478578, 0.7681298557244765, 0.2133694043679101, 0.014224626957860673, 0.9862127510611263, 0.9746613772734951, 0.016244356287891584, 0.24430438226073953, 0.22457794145707735, 0.013656766710227676, 0.5144048794185758, 0.03684474911547684, 0.28159915395400154, 0.12106131852228104, 0.4947723452649747, 0.06579419484906579, 0.9644941946913964, 0.03136566486801289, 0.9919753778465846, 0.005257910172157505, 0.9919923858137158, 0.0017526367240525015, 0.9959213531696328, 0.9938581323993827, 0.004216933665445907, 0.004216933665445907, 0.9867624777143421, 0.0028181116264252297, 0.6011971469707157, 0.19257096113905736, 0.19914655493404956, 0.004696852710708716, 0.5278141432431676, 0.0024641183157944327, 0.012813415242131051, 0.20255052555830239, 0.1320767417265816, 0.12172744480024499, 0.015773740174826203, 0.10365600686314363, 0.8653023181618946, 0.011266957267733003, 0.9927594483164516, 0.9879495058617035, 0.9602751275922969, 0.03405230948908854, 0.9922672813961056, 0.9914080231275075, 0.9935343528039696, 0.00920737320065631, 0.005524423920393786, 0.9851889324702252, 0.0016499567522249103, 0.9965738783438458, 0.16251306708165725, 0.24602672655417554, 0.0045142518633793675, 0.013542755590138103, 0.5259103420836964, 0.04965677049717305, 0.5403882680705249, 0.0024178445998681206, 0.2550826052860867, 0.06407288189650519, 0.13660821989254882, 0.9958724813560748, 0.996022737196377, 0.0027492631864380382, 0.0005498526372876076, 0.996332978765145, 0.09555239916918495, 0.8366661293106683, 0.0419498337815934, 0.023305463211996332, 0.3710334356228161, 0.6117037722430212, 0.016713217820847573, 0.9884788242033302, 0.9909785983133182, 0.7163684944268272, 0.18861582927191428, 0.09105591757954482, 0.002787426048353413, 0.9960253926090695, 0.995354015681741, 0.9929419956449707, 0.27555942575695647, 0.029524224188245338, 0.0024603520156871116, 0.5314360353884161, 0.15746252900397514, 0.9951128441082525, 0.9969967349373651, 0.007313161025922295, 0.23402115282951344, 0.7576434822855498, 0.9944199362629184, 0.9887948080437481, 0.9958862789829718, 0.9873541861740914, 0.9976535139187457, 0.000670232435885877, 0.000670232435885877, 0.9979760970340709, 0.000670232435885877], \"Term\": [\"..\", \"..\", \"10_years\", \"64_bit\", \"_1\", \"access\", \"access\", \"access\", \"access\", \"access\", \"account\", \"account\", \"accountant\", \"addition\", \"alternative\", \"answer\", \"anyone\", \"anyone\", \"anything\", \"app\", \"app\", \"application\", \"application\", \"application\", \"apps\", \"area\", \"backup\", \"backup\", \"bit\", \"bit\", \"bit\", \"bit\", \"bit\", \"book\", \"book\", \"box\", \"box\", \"box\", \"bug\", \"bug\", \"business\", \"business\", \"business\", \"button\", \"camera\", \"capability\", \"card\", \"case\", \"case\", \"case\", \"category\", \"cd\", \"cd\", \"chance\", \"child\", \"choice\", \"choice\", \"code\", \"color\", \"comment\", \"company\", \"company\", \"complaint\", \"computer\", \"computer\", \"computer\", \"computer\", \"computer\", \"computer\", \"cost\", \"cost\", \"cost\", \"cost\", \"cost\", \"course\", \"course\", \"course\", \"course\", \"crash\", \"customer\", \"customer\", \"customer\", \"customer\", \"customer\", \"customer_service\", \"customer_service\", \"data\", \"data\", \"data\", \"data\", \"date\", \"daughter\", \"day\", \"day\", \"deal\", \"desktop\", \"desktop\", \"desktop\", \"device\", \"device\", \"device\", \"difference\", \"difficulty\", \"direction\", \"disc\", \"disk\", \"disk\", \"dollar\", \"download\", \"download\", \"drive\", \"drive\", \"driver\", \"driver\", \"ease\", \"ease\", \"effect\", \"effort\", \"email\", \"end\", \"end\", \"end\", \"entry\", \"error\", \"error\", \"error\", \"error_message\", \"etc\", \"etc\", \"even_though\", \"every_time\", \"everything\", \"everything\", \"everything\", \"everything\", \"everything\", \"example\", \"example\", \"example\", \"expense\", \"experience\", \"experience\", \"fact\", \"fact\", \"fact\", \"fact\", \"family\", \"feature\", \"feature\", \"feature\", \"feature\", \"feature\", \"feature\", \"file\", \"file\", \"file\", \"file\", \"file\", \"fix\", \"font\", \"format\", \"format\", \"format\", \"friend\", \"friend\", \"fun\", \"function\", \"function\", \"game\", \"game\", \"game\", \"glitch\", \"go_back\", \"good_product\", \"great_product\", \"guy\", \"hand\", \"hand\", \"hard_drive\", \"hardware\", \"hardware\", \"help\", \"home\", \"home\", \"home\", \"home\", \"hour\", \"hour\", \"hour\", \"hour\", \"house\", \"house\", \"house\", \"husband\", \"icon\", \"idea\", \"idea\", \"image\", \"improvement\", \"info\", \"information\", \"information\", \"information\", \"information\", \"information\", \"install\", \"install\", \"installation\", \"installation\", \"installation\", \"instruction\", \"instruction\", \"instruction\", \"interface\", \"interface\", \"interface\", \"internet\", \"internet\", \"investment\", \"issue\", \"item\", \"job\", \"junk\", \"key\", \"kid\", \"kind\", \"lack\", \"laptop\", \"laptop\", \"laptop\", \"laptop\", \"last_year\", \"learning_curve\", \"license\", \"life\", \"life\", \"life\", \"line\", \"line\", \"list\", \"list\", \"long_time\", \"long_time\", \"look\", \"lot\", \"lot\", \"lot\", \"mac\", \"make_sure\", \"make_sure\", \"malware\", \"many_years\", \"matter\", \"menu\", \"mess\", \"message\", \"mind\", \"minute\", \"mistake\", \"money\", \"money\", \"money\", \"money_back\", \"month\", \"month\", \"mouse\", \"much_better\", \"music\", \"music\", \"name\", \"need\", \"need\", \"need\", \"new_computer\", \"new_version\", \"next_year\", \"none\", \"nothing\", \"nothing\", \"nothing\", \"nothing\", \"nothing\", \"number\", \"number\", \"number\", \"object\", \"office\", \"office\", \"office\", \"older_version\", \"one\", \"operating_system\", \"operation\", \"option\", \"option\", \"option\", \"option\", \"option\", \"order\", \"order\", \"order\", \"others\", \"others\", \"package\", \"package\", \"pain\", \"part\", \"part\", \"part\", \"part\", \"partition\", \"password\", \"past\", \"patch\", \"pc\", \"pc\", \"pcs\", \"people\", \"people\", \"people\", \"people\", \"person\", \"person\", \"phone\", \"phone\", \"photo\", \"photo\", \"picture\", \"picture\", \"piece\", \"place\", \"player\", \"point\", \"practice\", \"price\", \"price\", \"problem\", \"problem\", \"problem\", \"problem\", \"problem\", \"process\", \"process\", \"process\", \"product\", \"product\", \"product\", \"product\", \"product\", \"product\", \"professional\", \"program\", \"program\", \"program\", \"program\", \"program\", \"project\", \"project\", \"purchase\", \"purchase\", \"quality\", \"question\", \"reason\", \"reason\", \"refund\", \"release\", \"response\", \"return\", \"return\", \"review\", \"review\", \"reviewer\", \"room\", \"scan\", \"school\", \"school\", \"screen\", \"screen\", \"search\", \"search\", \"seller\", \"server\", \"service\", \"service\", \"session\", \"set\", \"setting\", \"several_years\", \"side\", \"software\", \"software\", \"software\", \"software\", \"software\", \"software\", \"solution\", \"someone\", \"someone\", \"someone\", \"something\", \"something\", \"song\", \"sound\", \"space\", \"speed\", \"star\", \"state\", \"step\", \"store\", \"store\", \"story\", \"stuff\", \"subscription\", \"subscription\", \"subscription\", \"success\", \"suite\", \"suite\", \"support\", \"support\", \"support\", \"support\", \"system\", \"system\", \"system\", \"system\", \"system\", \"tablet\", \"tablet\", \"task\", \"tax\", \"tax\", \"tax\", \"tech_support\", \"technical_support\", \"thanks\", \"thanks\", \"thanks\", \"thing\", \"thing\", \"thing\", \"thing\", \"thing\", \"time\", \"time\", \"time\", \"time\", \"time\", \"time\", \"tool\", \"tool\", \"tool\", \"tool\", \"trial\", \"trial_version\", \"trouble\", \"trouble\", \"try\", \"tutorial\", \"unit\", \"update\", \"update\", \"update\", \"upgrade\", \"upgrade\", \"use\", \"use\", \"use\", \"use\", \"use\", \"use\", \"user\", \"user\", \"user\", \"user\", \"user\", \"user_friendly\", \"value\", \"version\", \"version\", \"version\", \"video\", \"video\", \"video\", \"video\", \"virus\", \"virus\", \"virus\", \"voice\", \"waste\", \"way\", \"way\", \"way\", \"way\", \"web_site\", \"week\", \"wife\", \"window\", \"window\", \"window\", \"window\", \"window\", \"windows\", \"word\", \"work\", \"work\", \"work\", \"works_great\", \"works_well\", \"world\", \"would_like\", \"xp\", \"year\", \"year\", \"year\", \"year\"]}, \"R\": 30, \"lambda.step\": 0.01, \"plot.opts\": {\"xlab\": \"PC1\", \"ylab\": \"PC2\"}, \"topic.order\": [6, 2, 4, 1, 3, 5]};\n",
       "\n",
       "function LDAvis_load_lib(url, callback){\n",
       "  var s = document.createElement('script');\n",
       "  s.src = url;\n",
       "  s.async = true;\n",
       "  s.onreadystatechange = s.onload = callback;\n",
       "  s.onerror = function(){console.warn(\"failed to load library \" + url);};\n",
       "  document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
       "}\n",
       "\n",
       "if(typeof(LDAvis) !== \"undefined\"){\n",
       "   // already loaded: just create the visualization\n",
       "   !function(LDAvis){\n",
       "       new LDAvis(\"#\" + \"ldavis_el362101338300619838883656436106\", ldavis_el362101338300619838883656436106_data);\n",
       "   }(LDAvis);\n",
       "}else if(typeof define === \"function\" && define.amd){\n",
       "   // require.js is available: use it to load d3/LDAvis\n",
       "   require.config({paths: {d3: \"https://d3js.org/d3.v5\"}});\n",
       "   require([\"d3\"], function(d3){\n",
       "      window.d3 = d3;\n",
       "      LDAvis_load_lib(\"https://cdn.jsdelivr.net/gh/bmabey/pyLDAvis@3.4.0/pyLDAvis/js/ldavis.v3.0.0.js\", function(){\n",
       "        new LDAvis(\"#\" + \"ldavis_el362101338300619838883656436106\", ldavis_el362101338300619838883656436106_data);\n",
       "      });\n",
       "    });\n",
       "}else{\n",
       "    // require.js not available: dynamically load d3 & LDAvis\n",
       "    LDAvis_load_lib(\"https://d3js.org/d3.v5.js\", function(){\n",
       "         LDAvis_load_lib(\"https://cdn.jsdelivr.net/gh/bmabey/pyLDAvis@3.4.0/pyLDAvis/js/ldavis.v3.0.0.js\", function(){\n",
       "                 new LDAvis(\"#\" + \"ldavis_el362101338300619838883656436106\", ldavis_el362101338300619838883656436106_data);\n",
       "            })\n",
       "         });\n",
       "}\n",
       "</script>"
      ],
      "text/plain": [
       "PreparedData(topic_coordinates=              x         y  topics  cluster       Freq\n",
       "topic                                                \n",
       "5      0.077264 -0.308040       1        1  18.260357\n",
       "1      0.214043  0.035151       2        1  17.905191\n",
       "3     -0.184140 -0.082057       3        1  17.418864\n",
       "0     -0.228354  0.070986       4        1  17.048418\n",
       "2      0.013126  0.140182       5        1  15.515976\n",
       "4      0.108061  0.143778       6        1  13.851195, topic_info=         Term         Freq        Total Category  logprob  loglift\n",
       "95    program  3970.000000  3970.000000  Default  30.0000  30.0000\n",
       "47    product  3982.000000  3982.000000  Default  29.0000  29.0000\n",
       "76   software  4208.000000  4208.000000  Default  28.0000  28.0000\n",
       "16   computer  2465.000000  2465.000000  Default  27.0000  27.0000\n",
       "13    version  1818.000000  1818.000000  Default  26.0000  26.0000\n",
       "..        ...          ...          ...      ...      ...      ...\n",
       "505   support   339.410504   659.013967   Topic6  -4.4053   1.3133\n",
       "427     error   218.911354   339.263163   Topic6  -4.8438   1.5387\n",
       "190    return   156.270950   281.034158   Topic6  -5.1809   1.3899\n",
       "21       time   246.909667  2029.123345   Topic6  -4.7235  -0.1295\n",
       "29     course   135.632481   264.845208   Topic6  -5.3226   1.3076\n",
       "\n",
       "[313 rows x 6 columns], token_table=      Topic      Freq      Term\n",
       "term                           \n",
       "201       2  0.001254        ..\n",
       "201       6  0.997998        ..\n",
       "488       6  0.996933  10_years\n",
       "2233      2  0.996470    64_bit\n",
       "2037      6  0.995577        _1\n",
       "...     ...       ...       ...\n",
       "1892      2  0.997654        xp\n",
       "31        1  0.000670      year\n",
       "31        2  0.000670      year\n",
       "31        4  0.997976      year\n",
       "31        5  0.000670      year\n",
       "\n",
       "[516 rows x 3 columns], R=30, lambda_step=0.01, plot_opts={'xlab': 'PC1', 'ylab': 'PC2'}, topic_order=[6, 2, 4, 1, 3, 5])"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Modelo 2: con n2 tópicos:\n",
    "\n",
    "pyLDAvis.gensim.prepare(ldamodel2, corpus, dictionary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "OU8SmW48zq-l",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 973
    },
    "id": "OU8SmW48zq-l",
    "outputId": "c8554391-2bb1-40b3-cd33-c3ee4b8b6d08"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n",
      "/usr/local/lib/python3.10/dist-packages/pandas/core/dtypes/cast.py:1641: DeprecationWarning: np.find_common_type is deprecated.  Please use `np.result_type` or `np.promote_types`.\n",
      "See https://numpy.org/devdocs/release/1.25.0-notes.html and the docs for more information.  (Deprecated NumPy 1.25)\n",
      "  return np.find_common_type(types, [])\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<link rel=\"stylesheet\" type=\"text/css\" href=\"https://cdn.jsdelivr.net/gh/bmabey/pyLDAvis@3.4.0/pyLDAvis/js/ldavis.v1.0.0.css\">\n",
       "\n",
       "\n",
       "<div id=\"ldavis_el362101338300619827688705410779\" style=\"background-color:white;\"></div>\n",
       "<script type=\"text/javascript\">\n",
       "\n",
       "var ldavis_el362101338300619827688705410779_data = {\"mdsDat\": {\"x\": [0.23971666282668094, -0.13055284867311687, -0.15021594875206554, 0.19189677490424473, -0.1064870300132608, 0.13338167532040274, -0.10980982487117887, -0.06792946074170622], \"y\": [-0.0082038020051375, 0.28118542301034594, 0.06170889230624896, 0.10838939445892358, -0.22726459820368813, -0.08373301093057893, -0.1227703857624627, -0.009311912873650994], \"topics\": [1, 2, 3, 4, 5, 6, 7, 8], \"cluster\": [1, 1, 1, 1, 1, 1, 1, 1], \"Freq\": [15.373344240268974, 13.77623389293511, 13.153885961491948, 12.626895761380712, 12.586477535010362, 11.601131762612201, 10.461021168384251, 10.421009677916441]}, \"tinfo\": {\"Term\": [\"software\", \"product\", \"computer\", \"program\", \"version\", \"problem\", \"time\", \"year\", \"pc\", \"feature\", \"lot\", \"..\", \"issue\", \"game\", \"money\", \"price\", \"file\", \"review\", \"work\", \"upgrade\", \"option\", \"company\", \"everything\", \"day\", \"cd\", \"way\", \"update\", \"installation\", \"tax\", \"use\", \"money\", \"many_years\", \"set\", \"card\", \"difference\", \"new_version\", \"improvement\", \"waste\", \"life\", \"setting\", \"speed\", \"unit\", \"server\", \"letter\", \"64_bit\", \"difficulty\", \"default\", \"rest\", \"office\", \"glitch\", \"computer\", \"control\", \"virus\", \"star\", \"technical_support\", \"didn't_work\", \"keyboard\", \"title\", \"32_bit\", \"boot\", \"tax\", \"data\", \"year\", \"file\", \"client\", \"scan\", \"process\", \"program\", \"something\", \"system\", \"thing\", \"user\", \"level\", \"time\", \"page\", \"way\", \"word\", \"piece\", \"need\", \"item\", \"tech_support\", \"issue\", \"complaint\", \"area\", \"try\", \"customer_service\", \"project\", \"everyone\", \"icon\", \"stuff\", \"every_time\", \"practice\", \"example\", \"patch\", \"response\", \"works_great\", \"protection\", \"deduction\", \"number\", \"category\", \"space\", \"term\", \"reviewer\", \"camera\", \"instance\", \"sort\", \"software\", \"problem\", \"help\", \"person\", \"make_sure\", \"email\", \"return\", \"picture\", \"someone\", \"couple\", \"support\", \"company\", \"cd\", \"part\", \"windows\", \"installation\", \"user_friendly\", \"game\", \"highly_recommend\", \"product\", \"box\", \"fix\", \"anyone\", \"player\", \"task\", \"entry\", \"capability\", \"suite\", \"session\", \"tutorial\", \"instruction\", \"student\", \"basic\", \"first_time\", \"lesson\", \"gift\", \"training\", \"browser\", \"windows_8\", \"bug\", \"really_like\", \"mistake\", \"alternative\", \"order\", \"people\", \"market\", \"way\", \"support\", \"hour\", \"case\", \"point\", \"device\", \"reason\", \"disk\", \"result\", \"addition\", \"upgrade\", \"update\", \"download\", \"phone\", \"format\", \"place\", \"install\", \"solution\", \"driver\", \"would_recommend\", \"xp\", \"value\", \"sound\", \"graphic\", \"wife\", \"choice\", \"note\", \"answer\", \"amount\", \"several_years\", \"effect\", \"direction\", \"side\", \"color\", \"search\", \"opinion\", \"road\", \"pcs\", \"click\", \"child\", \"home\", \"hard_drive\", \"son\", \"bit\", \"crash\", \"functionality\", \"time\", \"website\", \"question\", \"subscription\", \"information\", \"site\", \"language\", \"program\", \"end\", \"version\", \"lot\", \"price\", \"review\", \"function\", \"type\", \"button\", \"key\", \"last_year\", \"apps\", \"none\", \"change\", \"mind\", \"minute\", \"go_back\", \"pc\", \"story\", \"mouse\", \"application\", \"mac\", \"font\", \"object\", \"everything\", \"success\", \"start\", \"desktop\", \"future\", \"customer_support\", \"backup\", \"downloads\", \"feature\", \"others\", \"older_version\", \"line\", \"business\", \"fun\", \"movie\", \"ability\", \"user\", \"thing\", \"window\", \"app\", \"interface\", \"music\", \"one\", \"operating_system\", \"date\", \"week\", \"photo\", \"kid\", \"day\", \"comment\", \"machine\", \"great_product\", \"hardware\", \"link\", \"state\", \"tablet\", \"edition\", \"daughter\", \"collection\", \"husband\", \"junk\", \"account\", \"character\", \"voice\", \"performance\", \"mess\", \"folder\", \"design\", \"vendor\", \"image\", \"text\", \"deal\", \"every_year\", \"work\", \"background\", \"security\", \"disc\", \"program\", \"bank\", \"window\", \"..\", \"laptop\", \"use\", \"transaction\", \"purchase\", \"even_though\", \"ease\", \"map\", \"world\", \"thanks\", \"learning_curve\", \"matter\", \"user_interface\", \"song\", \"chance\", \"book\", \"new_computer\", \"next_year\", \"internet\", \"_1\", \"seller\", \"release\", \"memory\", \"operation\", \"works_well\", \"course\", \"option\", \"tool\", \"location\", \"record\", \"video\", \"job\", \"month\", \"investment\", \"guy\", \"fact\", \"error\", \"document\", \"refund\", \"form\", \"screen\", \"nothing\", \"friend\", \"kind\", \"step\", \"cost\", \"much_better\", \"store\", \"password\", \"family\", \"menu\", \"copy\", \"name\", \"license\", \"10_years\", \"room\", \"online\", \"paper\", \"trial_version\", \"partition\", \"money_back\", \"effort\", \"half\", \"good_product\", \"template\", \"error_message\", \"headache\", \"lack\", \"drive\", \"look\", \"trouble\", \"service\", \"package\", \"experience\", \"anything\", \"code\", \"customer\", \"thing\"], \"Freq\": [4439.0, 4182.0, 2622.0, 4096.0, 1942.0, 1985.0, 2167.0, 1570.0, 1187.0, 1085.0, 1018.0, 865.0, 973.0, 900.0, 946.0, 775.0, 983.0, 730.0, 732.0, 641.0, 598.0, 647.0, 648.0, 601.0, 604.0, 1131.0, 579.0, 570.0, 600.0, 474.0, 944.1627002781458, 223.86796139281267, 213.45487240608793, 268.3134412588734, 183.98376231117265, 207.83061760524316, 168.53021178805895, 160.4828479412749, 150.39725659078746, 175.3128171099162, 143.81751307228896, 143.70864883610287, 143.3688987663695, 131.46191782080317, 120.20812947431901, 116.16925051149106, 125.36271962775724, 112.85847205006884, 288.3588246485252, 106.01172459248274, 2598.142168576703, 112.74135573528548, 307.67862840673433, 84.47688051683056, 92.0641173666669, 76.60398098099994, 76.06791187866686, 74.90604937642367, 73.38801164887528, 72.56319161529393, 592.4189201813284, 450.1226049014989, 1524.979643233551, 936.162507582125, 85.17458693936445, 94.99082584797812, 262.0006083139083, 3003.8345193794403, 343.47713647306847, 514.28298282324, 673.3146284098354, 432.25387422258643, 148.73511990329467, 628.0884688714284, 166.32756036146046, 255.87171987462978, 379.0941778341588, 307.5264898556703, 331.3061082299593, 290.1470090373098, 231.53609014405234, 969.4205176547574, 216.41960640143378, 205.8517452364542, 164.55477740185603, 202.9068834012512, 218.10945298808153, 158.65162856166643, 145.99440938171293, 155.78888809100758, 135.34984583251412, 123.60757192442996, 183.7522038382034, 114.24959787256805, 123.16633048609563, 110.50617656145309, 210.8149005014198, 108.1057613528156, 427.9038475106372, 98.65169371991853, 95.5882128510233, 98.89566367972567, 94.12010682033196, 93.75103049646734, 92.04340167390772, 88.58847348873755, 4385.533357673712, 1938.9553358921405, 511.22747912905095, 172.28409686817412, 112.75706137950918, 224.34609437278118, 225.3430580356968, 212.65578346605514, 187.55093478935694, 144.51258213243162, 153.85467252224848, 646.7963462023282, 602.9869357198986, 349.8550710740353, 306.6248486806359, 567.4957310190972, 198.75757476106787, 895.4032040447473, 172.8020801847964, 4156.538269651357, 302.52230530231424, 143.94731451846226, 359.1378119578806, 133.77931033934817, 130.42023818858024, 111.51226534426533, 106.8239340381025, 128.21144297234096, 101.36997841414956, 93.40631425282224, 267.62429952153843, 126.49142911460288, 81.24016893050658, 132.52199803013542, 189.3290229132483, 80.69589730714159, 79.27562305618768, 91.9641081352793, 74.9648836453538, 192.24321430930095, 74.23921477630617, 141.6345687683984, 105.12430962652365, 353.7449939468989, 494.9394874298094, 165.0981510207003, 754.6368274801679, 478.7809189447157, 249.27242147551627, 246.30325600311022, 245.10360932462638, 214.1465307576188, 249.25214264118068, 181.55197933372037, 156.20320290036491, 132.94008614312244, 639.7470187782569, 577.2092576813324, 332.53770827126505, 254.6902299483692, 260.7918236883438, 218.864939029962, 241.54048020973704, 218.160845456348, 209.74713961232308, 253.54447338846478, 157.88242483889638, 155.8199426933598, 152.00797442286265, 163.9647055564178, 181.40681877707505, 150.88529438825964, 210.2142386868292, 158.54097884826524, 150.73493124154868, 142.40195784263503, 132.44807090195863, 121.49238433477657, 121.40858445787677, 103.3933923944196, 170.46348452174914, 130.7827503861496, 93.10113233402434, 90.01919513247614, 89.98594889101427, 171.54146263694156, 266.7555717628676, 207.73455042460841, 160.70270420997545, 384.1629628023384, 137.9953679199308, 168.54941888351922, 1522.2245397264269, 346.12348164082255, 274.676294127217, 188.7730084631306, 260.9660774095616, 219.4282374844823, 174.87307108935445, 559.0283063231487, 210.2654647976977, 1940.4361313167342, 1017.1895877777348, 774.6257574033821, 728.9810041479325, 210.67200894956582, 206.22191187229657, 167.41395788284316, 157.36091424684082, 194.61607120747183, 153.8554784822893, 149.9121572484239, 236.15639054127305, 134.81138254387906, 118.69328117641128, 120.14261328354647, 1178.1739498929155, 112.2874524702095, 110.94370209379808, 417.05489238904295, 110.60497736779708, 101.02674575874646, 91.9482222029276, 641.6962180930093, 87.79544271489411, 90.74118829015276, 291.2130882959009, 83.75792347890159, 83.60898244307883, 194.54912124166538, 77.84692828512236, 1063.629461547519, 248.59948798031024, 137.93909725595597, 340.4527712979479, 405.6771849381089, 163.82984738243266, 170.7612915324637, 171.04853075867535, 158.2923690231804, 146.9421330495209, 121.18076699537913, 346.5262355073836, 361.42716167440324, 346.03640292319244, 346.3402096872931, 241.34011317311484, 220.1876918757289, 224.45392881933302, 226.21992757894276, 186.57542113825824, 598.6095403196642, 163.45229897122826, 315.636670844103, 158.45306913448934, 155.14602172856306, 152.14099258537897, 221.5856495739616, 140.5523492555351, 145.81622309632417, 122.54919702604738, 120.0754286621591, 119.32112550435251, 118.30575534521277, 428.7875425373747, 115.20330165529907, 113.5574576687754, 112.91031284084961, 108.32711009890694, 120.28312244719312, 107.14545267103348, 97.86438799096373, 279.42042884384375, 181.3071356607848, 123.8758097791784, 124.6359011777453, 663.1998035633416, 128.13636687604395, 159.20542119990483, 208.6658409420741, 485.2344664318492, 148.14730157000903, 156.72763141781041, 864.7468343448112, 424.9472125969886, 472.75977974133576, 240.7641831191728, 333.50897279978375, 174.73332148242156, 171.06314726664866, 163.57338138617763, 156.01344687446215, 255.8455419869967, 144.6482984744186, 137.32956069110813, 133.28483122837616, 129.7884316462424, 129.35375559544093, 364.54831460550446, 127.54477524532768, 133.48183901934473, 202.65064301824654, 111.3621041203508, 114.39705625163037, 101.10298889247501, 94.62035154848951, 92.36044073418024, 96.70615540801988, 285.99355939928586, 591.9139544636731, 464.4596487615686, 87.0264420873095, 82.04895560433928, 460.8688602015928, 218.33193928484258, 270.24834018404255, 107.70404007787668, 115.57284754069347, 198.84929969378152, 191.27052061861158, 134.1804953449269, 447.1569662101864, 312.36472986104087, 392.22454246890106, 427.1965552599479, 276.6239993287012, 239.95038916630108, 239.86042144078434, 302.92553809810903, 218.3628476374314, 201.42560542049273, 220.9481734398831, 187.0451602791915, 182.77856747452924, 195.98131172057606, 184.1268759981932, 142.00850477106857, 144.5965179211656, 119.2931243298851, 168.55729899737818, 111.10257554533702, 110.3992499300799, 105.94511725948935, 102.84813409684513, 98.35062413002328, 100.16546983638575, 94.35682632166, 91.85362041065937, 100.4033779971299, 88.02496790451355, 86.18812684188025, 249.7749426868629, 143.80675902675137, 163.85691375686946, 298.02862595588715, 312.9082556590706, 329.10634095881477, 291.83316016850677, 206.6745990513169, 269.9794154344826, 177.28977675019576], \"Total\": [4439.0, 4182.0, 2622.0, 4096.0, 1942.0, 1985.0, 2167.0, 1570.0, 1187.0, 1085.0, 1018.0, 865.0, 973.0, 900.0, 946.0, 775.0, 983.0, 730.0, 732.0, 641.0, 598.0, 647.0, 648.0, 601.0, 604.0, 1131.0, 579.0, 570.0, 600.0, 474.0, 946.9906489122362, 224.8258169195927, 214.3796582970289, 269.55433697428464, 184.93274354585117, 209.01647926119173, 169.4987287079941, 161.40892282616252, 151.32829588266628, 176.4269797234662, 144.73947234352107, 144.63072728226487, 144.29009917734248, 132.4551176755385, 121.13821568175295, 117.09144159538708, 126.36377498232974, 113.77952108195869, 290.74012577343785, 106.93252924487146, 2622.6048869801643, 113.86444101671866, 310.82038250489296, 85.39775019958266, 93.11611496744034, 77.52589199271226, 76.98959102572393, 75.83894201618531, 74.30889819064015, 73.48494825375927, 600.0552427543906, 456.80087509995406, 1570.8900777996193, 983.6032543368298, 86.32151517432503, 96.6896450141422, 282.0784088451208, 4096.88820907879, 458.5765514690824, 779.9087904236343, 1107.4938852230698, 859.6890993978894, 172.26290170362833, 2167.1255853461616, 214.18522699775104, 1131.6359454820185, 380.04557924679705, 308.44690079285715, 332.38526716051746, 291.10463349662245, 232.50793567226387, 973.7908727204862, 217.4399694896152, 206.92054008503035, 165.47956238191782, 204.1458399869627, 219.4483517823843, 159.62765479139583, 146.91477420599696, 156.77749151742748, 136.27303891221803, 124.52712502545236, 185.20142422183244, 115.18497381674928, 124.18527217749316, 111.4253716734463, 212.59539012409098, 109.0253568221038, 431.77779649045306, 99.57103810707223, 96.50761466321593, 99.84973809955632, 95.0401108873048, 94.67022293821438, 92.9634103453151, 89.52101663544921, 4439.691178618905, 1985.4327906863705, 527.1737488906585, 186.14064391751822, 118.11247553138912, 295.46764820568995, 297.9136971904576, 287.3048620651284, 252.32541216893136, 185.47881829960394, 683.1338068729672, 647.929333672315, 604.5261878723476, 350.9535505632518, 307.7179894420596, 570.243141598889, 199.73552552027857, 900.0633170215904, 173.77549775160261, 4182.529117050037, 304.4546136088171, 144.8700294773467, 361.51571882827585, 134.70736861323428, 131.34546046676746, 112.43511604798466, 107.74640425877361, 129.31913704448934, 102.29975782512852, 94.32970458418195, 270.51735410785403, 127.87334657372598, 82.16289347243867, 134.0392684314182, 191.56413251207988, 81.67017589414698, 80.23627493671893, 93.08703338801678, 75.88888221699966, 194.63771066444917, 75.1762709997326, 143.47288718828563, 106.48417507038917, 366.62133383023877, 601.0746339083513, 182.4368371946269, 1131.6359454820185, 683.1338068729672, 336.92284832879255, 332.77019512470787, 345.9822833348297, 287.7035002333747, 404.3949409372069, 300.74699998923563, 217.50143476218622, 159.41479900579722, 641.5562251234375, 579.252864587049, 333.7266847118389, 255.63040942316758, 261.7883291320505, 219.8291574015716, 242.60686036606438, 219.13261401604126, 210.76755294345605, 255.0019110876831, 158.80994941200092, 156.7454533144073, 152.93089112942195, 164.96026290478224, 182.5249881830194, 151.81672303730574, 211.51439192898036, 159.53512101090936, 151.6836041834039, 143.32610850861897, 133.3685551738477, 122.4232901920223, 122.4024626169962, 104.31081893956463, 172.02174329188648, 132.0473094163774, 94.02372417592042, 90.93682859162931, 90.90336273064753, 173.29988560124733, 271.611079244034, 211.06305450867677, 162.87758364634274, 392.9253020782319, 139.80953891005674, 172.60982159948236, 2167.1255853461616, 401.4367461831579, 361.4118439988414, 230.04918137958387, 403.93948143243927, 319.96701698892844, 204.7314199539172, 4096.88820907879, 340.1651993013264, 1942.5892275855604, 1018.436872145153, 775.597188582584, 730.0436493405565, 211.59162866332264, 207.20244269956592, 168.33287510106132, 158.2798890834065, 195.77411346367606, 154.77746238390495, 150.84974006319277, 237.6400464808795, 135.74626449401418, 119.6121046622475, 121.10771771384466, 1187.884779363343, 113.2214563849427, 111.87465171671674, 420.72010955325686, 111.60423950889846, 101.94559480942651, 92.86720494769433, 648.1508647006851, 88.71450133429632, 91.7076037538228, 294.3974003162929, 84.6768111120176, 84.53403989224694, 196.70533502061895, 78.76557516541125, 1085.6033310217645, 251.65268225257375, 139.73626789744446, 351.90816839044476, 434.1147998098985, 169.09889277259958, 180.73380719190638, 225.39636163806668, 859.6890993978894, 1107.4938852230698, 425.9761286103667, 347.45498668312274, 362.40971870925574, 346.9840875545971, 347.52695662654776, 242.31823206918202, 221.12462796128602, 225.4316294609874, 227.25927695383126, 187.5083365943597, 601.6772982677071, 164.3677660964949, 317.4636203885107, 159.37029613201318, 156.06440561741059, 153.0755206838051, 223.00158611760855, 141.48944343053873, 146.85118859587524, 123.46423395004396, 120.996642207036, 120.23684341638597, 119.2209650511729, 432.2005067181048, 116.12898176807805, 114.47277408344777, 113.85540019924734, 109.24339063660118, 121.3007427036944, 108.08754514490215, 98.78369169365024, 282.9931922954808, 183.42912354528755, 125.20821471241985, 126.11089196950863, 732.254437652889, 131.38089886336027, 174.4641295917703, 287.96574375244995, 4096.88820907879, 227.9391137418404, 425.9761286103667, 865.7309710421032, 426.1117650892514, 474.7967410234983, 241.85541863239197, 335.0559437861232, 175.65070518246142, 172.02201658966266, 164.50423500117572, 156.92818136614042, 257.4122734187673, 145.5636215414903, 138.24388941947237, 134.2136224316635, 130.70458969133617, 130.27085030205683, 367.254885331803, 128.49873898904028, 134.48092802521157, 204.234040015397, 112.2790158581762, 115.39056968307115, 102.01712855927595, 95.5431037706606, 93.27543547640612, 97.67893308528565, 288.93547669499884, 598.09677550909, 469.35899383962294, 87.95572766327336, 82.98544019851802, 467.46957155730064, 221.10417899104291, 278.287069545607, 109.14540150974915, 117.72959169959016, 335.86568691859287, 362.1141958938873, 268.73339559748723, 448.39816309934037, 313.3641811951776, 393.48485318934013, 428.6399764674711, 277.6270887814833, 240.8627977356185, 240.80060449781934, 304.21877113439785, 219.3419143900476, 202.3544352134568, 221.99316614252794, 187.9574928737164, 183.70028919258516, 197.04985160600663, 185.22547169079002, 142.9370347966008, 145.62164254954445, 120.20648953061503, 169.91133424727724, 112.0169748300838, 111.32795976206494, 106.86580010023845, 103.76027268385168, 99.26361025428852, 101.09542293715585, 95.26884971920866, 92.76630913593819, 101.4429727344173, 88.93735841209346, 87.10302761398397, 253.04750129872434, 145.5037895985089, 166.32986224277448, 306.71286107467955, 326.6234960061771, 384.4184100723514, 383.31547074099547, 273.2154467690202, 415.8088582906907, 1107.4938852230698], \"Category\": [\"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\"], \"logprob\": [30.0, 29.0, 28.0, 27.0, 26.0, 25.0, 24.0, 23.0, 22.0, 21.0, 20.0, 19.0, 18.0, 17.0, 16.0, 15.0, 14.0, 13.0, 12.0, 11.0, 10.0, 9.0, 8.0, 7.0, 6.0, 5.0, 4.0, 3.0, 2.0, 1.0, -3.4865, -4.9257, -4.9733, -4.7446, -5.1219, -5.0, -5.2097, -5.2586, -5.3235, -5.1702, -5.3682, -5.369, -5.3714, -5.4581, -5.5475, -5.5817, -5.5056, -5.6106, -4.6726, -5.6732, -2.4742, -5.6117, -4.6077, -5.9003, -5.8143, -5.9981, -6.0051, -6.0205, -6.041, -6.0523, -3.9526, -4.2273, -3.007, -3.495, -5.8921, -5.783, -4.7684, -2.3291, -4.4977, -4.094, -3.8246, -4.2678, -5.3346, -3.8941, -5.2228, -4.7921, -4.2893, -4.4985, -4.424, -4.5567, -4.7823, -3.3504, -4.8499, -4.8999, -5.1238, -4.9143, -4.8421, -5.1604, -5.2435, -5.1786, -5.3192, -5.41, -5.0135, -5.4887, -5.4135, -5.522, -4.8761, -5.544, -4.1682, -5.6355, -5.667, -5.633, -5.6825, -5.6864, -5.7048, -5.7431, -1.841, -2.6572, -3.9903, -5.0779, -5.5018, -4.8139, -4.8095, -4.8674, -4.993, -5.2537, -5.1911, -3.7088, -3.779, -4.3233, -4.4552, -3.8396, -4.8888, -3.3836, -5.0287, -1.8484, -4.4687, -5.2114, -4.2971, -5.2847, -5.3101, -5.4667, -5.5097, -5.3272, -5.5621, -5.6439, -4.5913, -5.3407, -5.7834, -5.2941, -4.9374, -5.7902, -5.8079, -5.6595, -5.8638, -4.9221, -5.8736, -5.2276, -5.5257, -4.3123, -3.9764, -5.0743, -3.5546, -4.0096, -4.6623, -4.6743, -4.6792, -4.8142, -4.6624, -4.9793, -5.1297, -5.291, -3.6789, -3.7818, -4.3332, -4.5999, -4.5762, -4.7515, -4.6529, -4.7547, -4.7941, -4.6044, -5.0781, -5.0913, -5.116, -5.0403, -4.9392, -5.1234, -4.7918, -5.074, -5.1244, -5.1813, -5.2538, -5.3401, -5.3408, -5.5014, -5.0014, -5.2664, -5.6063, -5.6399, -5.6403, -4.9951, -4.5536, -4.8037, -5.0604, -4.1889, -5.2127, -5.0127, -2.812, -4.2932, -4.5244, -4.8994, -4.5756, -4.7489, -4.9759, -3.8138, -4.7916, -2.5661, -3.212, -3.4844, -3.5451, -4.7865, -4.8078, -5.0163, -5.0782, -4.8657, -5.1007, -5.1267, -4.6723, -5.2329, -5.3602, -5.3481, -3.065, -5.4157, -5.4277, -4.1035, -5.4308, -5.5214, -5.6155, -3.6726, -5.6618, -5.6287, -4.4627, -5.7088, -5.7106, -4.8661, -5.782, -3.1673, -4.6209, -5.2099, -4.3065, -4.1312, -5.0379, -4.9965, -4.9948, -5.0723, -5.1467, -5.3395, -4.2073, -4.1652, -4.2087, -4.2078, -4.569, -4.6608, -4.6416, -4.6337, -4.8264, -3.6606, -4.9587, -4.3006, -4.9898, -5.0109, -5.0304, -4.6544, -5.1097, -5.0729, -5.2467, -5.2671, -5.2734, -5.282, -3.9943, -5.3085, -5.3229, -5.3286, -5.3701, -5.2654, -5.3811, -5.4717, -4.4225, -4.855, -5.236, -5.2298, -3.5582, -5.2021, -4.985, -4.7145, -3.8706, -5.057, -5.0007, -3.1894, -3.8998, -3.7932, -4.468, -4.1421, -4.7885, -4.8098, -4.8545, -4.9019, -4.4072, -4.9775, -5.0294, -5.0593, -5.0859, -5.0892, -4.0531, -5.1033, -5.0578, -4.6403, -5.239, -5.2121, -5.3357, -5.4019, -5.4261, -5.3801, -4.2958, -3.5684, -3.8109, -5.4856, -5.5445, -3.8187, -4.5658, -4.3525, -5.2724, -5.2019, -4.6592, -4.6981, -5.0526, -3.8451, -4.2038, -3.9761, -3.8907, -4.3253, -4.4675, -4.4679, -4.2345, -4.5618, -4.6425, -4.55, -4.7166, -4.7397, -4.6699, -4.7323, -4.9921, -4.974, -5.1664, -4.8207, -5.2375, -5.2439, -5.285, -5.3147, -5.3594, -5.3411, -5.4009, -5.4278, -5.3388, -5.4703, -5.4914, -4.4274, -4.9795, -4.849, -4.2508, -4.2021, -4.1516, -4.2718, -4.6168, -4.3496, -4.7702], \"loglift\": [30.0, 29.0, 28.0, 27.0, 26.0, 25.0, 24.0, 23.0, 22.0, 21.0, 20.0, 19.0, 18.0, 17.0, 16.0, 15.0, 14.0, 13.0, 12.0, 11.0, 10.0, 9.0, 8.0, 7.0, 6.0, 5.0, 4.0, 3.0, 2.0, 1.0, 1.8695, 1.8683, 1.8682, 1.8679, 1.8674, 1.8668, 1.8668, 1.8668, 1.8664, 1.8662, 1.8661, 1.8661, 1.8661, 1.865, 1.8648, 1.8646, 1.8646, 1.8644, 1.8643, 1.8639, 1.8632, 1.8626, 1.8624, 1.8617, 1.8612, 1.8606, 1.8605, 1.8602, 1.8601, 1.8599, 1.8597, 1.8578, 1.8429, 1.8231, 1.8592, 1.8548, 1.7987, 1.5622, 1.5835, 1.4561, 1.3749, 1.185, 1.7257, 0.6341, 1.6197, 0.3858, 1.9797, 1.9792, 1.979, 1.9789, 1.978, 1.9777, 1.9775, 1.977, 1.9766, 1.9761, 1.9761, 1.9761, 1.9759, 1.9759, 1.9754, 1.9748, 1.9744, 1.9741, 1.974, 1.9739, 1.9738, 1.9738, 1.9732, 1.9729, 1.9727, 1.9726, 1.9725, 1.9725, 1.9723, 1.9718, 1.97, 1.9585, 1.9515, 1.9049, 1.9358, 1.7069, 1.703, 1.6814, 1.6856, 1.7327, 0.4915, 2.0267, 2.0259, 2.0253, 2.0249, 2.0236, 2.0235, 2.0233, 2.0228, 2.0222, 2.0221, 2.0221, 2.0219, 2.0215, 2.0214, 2.0202, 2.0199, 2.0199, 2.0193, 2.0186, 2.0177, 2.0176, 2.0172, 2.0171, 2.0167, 2.0165, 2.0164, 2.0163, 2.0162, 2.0161, 2.0159, 2.0156, 2.0156, 1.9927, 1.8342, 1.9286, 1.6233, 1.673, 1.7271, 1.7276, 1.6837, 1.7332, 1.5445, 1.5237, 1.6974, 1.8468, 2.0665, 2.0658, 2.0658, 2.0657, 2.0655, 2.0649, 2.0649, 2.0649, 2.0645, 2.0636, 2.0635, 2.0634, 2.0633, 2.0633, 2.0632, 2.0632, 2.0632, 2.0631, 2.0631, 2.0629, 2.0624, 2.0617, 2.0612, 2.0605, 2.0602, 2.0597, 2.0595, 2.0592, 2.0592, 2.0591, 2.0513, 2.0534, 2.0559, 2.0468, 2.0563, 2.0455, 1.7161, 1.9211, 1.7949, 1.8716, 1.6325, 1.6921, 1.9117, 0.0776, 1.5883, 2.0714, 2.0713, 2.0713, 2.0711, 2.0682, 2.0678, 2.0671, 2.0667, 2.0666, 2.0666, 2.0663, 2.0663, 2.0656, 2.0648, 2.0645, 2.0643, 2.0643, 2.0642, 2.0638, 2.0636, 2.0635, 2.0626, 2.0625, 2.0621, 2.062, 2.0617, 2.0616, 2.0615, 2.0615, 2.0608, 2.0521, 2.0603, 2.0596, 2.0395, 2.0048, 2.0409, 2.0158, 1.7966, 0.3804, 0.0527, 0.8154, 2.1514, 2.1514, 2.1513, 2.1506, 2.15, 2.1498, 2.1497, 2.1495, 2.1491, 2.149, 2.1485, 2.1483, 2.1483, 2.1482, 2.1479, 2.1477, 2.1474, 2.147, 2.1466, 2.1464, 2.1464, 2.1464, 2.1461, 2.1461, 2.146, 2.1457, 2.1456, 2.1456, 2.1453, 2.1447, 2.1414, 2.1424, 2.1434, 2.1423, 2.055, 2.1291, 2.0625, 1.832, 0.0207, 1.7232, 1.1542, 2.2564, 2.2548, 2.2532, 2.253, 2.2529, 2.2523, 2.2519, 2.2518, 2.2517, 2.2514, 2.2512, 2.2509, 2.2506, 2.2505, 2.2504, 2.2501, 2.2501, 2.2501, 2.2497, 2.2493, 2.2489, 2.2485, 2.2478, 2.2477, 2.2475, 2.2473, 2.2471, 2.247, 2.2469, 2.2462, 2.2433, 2.2449, 2.2282, 2.2442, 2.239, 1.7334, 1.6192, 1.563, 2.2586, 2.2582, 2.2581, 2.258, 2.2577, 2.2576, 2.2574, 2.2571, 2.2569, 2.2567, 2.2566, 2.2565, 2.2563, 2.2559, 2.2554, 2.2548, 2.2543, 2.2537, 2.2533, 2.2531, 2.253, 2.2527, 2.2525, 2.2521, 2.2521, 2.2517, 2.2515, 2.251, 2.251, 2.2508, 2.2483, 2.2496, 2.2464, 2.2326, 2.2184, 2.106, 1.9887, 1.9822, 1.8295, 0.4293]}, \"token.table\": {\"Topic\": [7, 8, 1, 1, 7, 1, 2, 5, 6, 7, 1, 3, 3, 5, 4, 4, 3, 4, 1, 2, 4, 8, 6, 1, 2, 5, 5, 2, 6, 8, 5, 7, 2, 4, 6, 3, 4, 7, 8, 1, 3, 7, 1, 1, 3, 3, 3, 4, 3, 4, 5, 6, 7, 5, 2, 3, 1, 2, 3, 5, 6, 8, 2, 3, 8, 7, 5, 6, 1, 4, 4, 4, 1, 3, 8, 6, 4, 6, 3, 2, 1, 2, 3, 4, 5, 1, 8, 8, 2, 3, 4, 5, 1, 7, 4, 5, 1, 2, 3, 5, 6, 7, 8, 2, 5, 1, 2, 4, 8, 6, 6, 2, 6, 7, 6, 8, 2, 1, 6, 2, 5, 7, 3, 6, 1, 1, 1, 4, 2, 3, 6, 1, 3, 8, 1, 2, 7, 4, 5, 6, 8, 4, 7, 6, 4, 8, 1, 2, 4, 1, 2, 3, 4, 5, 3, 1, 2, 4, 6, 7, 8, 7, 2, 4, 6, 2, 4, 5, 2, 3, 1, 2, 3, 5, 6, 7, 8, 1, 2, 7, 8, 8, 2, 3, 5, 7, 8, 1, 2, 3, 4, 6, 8, 3, 6, 3, 6, 5, 8, 4, 8, 2, 5, 6, 5, 1, 4, 5, 3, 5, 6, 3, 1, 5, 8, 4, 6, 3, 7, 8, 3, 4, 6, 8, 6, 8, 2, 4, 3, 4, 7, 2, 3, 6, 2, 4, 6, 1, 2, 4, 5, 6, 7, 4, 3, 4, 2, 3, 4, 8, 6, 1, 7, 7, 2, 5, 2, 6, 7, 6, 5, 1, 6, 8, 8, 3, 4, 7, 5, 7, 1, 3, 1, 1, 8, 8, 1, 5, 6, 6, 7, 6, 8, 5, 5, 5, 6, 2, 3, 8, 1, 7, 1, 2, 3, 7, 7, 8, 6, 5, 5, 2, 3, 1, 6, 8, 3, 6, 7, 5, 2, 3, 4, 5, 8, 6, 8, 2, 7, 1, 7, 5, 4, 8, 1, 2, 3, 5, 1, 8, 2, 5, 6, 8, 6, 7, 4, 7, 8, 3, 6, 5, 7, 1, 3, 5, 7, 8, 1, 2, 4, 5, 6, 8, 3, 8, 8, 2, 1, 3, 5, 7, 4, 1, 2, 3, 5, 6, 2, 8, 4, 6, 2, 3, 4, 2, 4, 3, 2, 3, 5, 7, 8, 2, 5, 1, 2, 3, 4, 5, 6, 8, 1, 3, 8, 1, 2, 3, 4, 5, 6, 7, 8, 1, 2, 3, 4, 5, 6, 8, 2, 4, 2, 6, 2, 7, 2, 4, 3, 1, 3, 8, 7, 8, 7, 2, 1, 1, 3, 4, 2, 5, 7, 8, 5, 2, 4, 8, 1, 6, 8, 4, 8, 3, 6, 7, 7, 1, 2, 8, 3, 1, 1, 4, 4, 1, 2, 3, 4, 6, 7, 1, 2, 3, 4, 5, 6, 7, 8, 4, 1, 2, 3, 4, 5, 1, 2, 4, 6, 7, 2, 4, 2, 1, 1, 5, 1, 6, 8, 8, 5, 3, 2, 2, 4, 8, 5, 3, 2, 3, 4, 5, 1, 2, 4, 6, 7, 8, 6, 3, 1, 2, 4, 6, 2, 1, 8, 2, 6, 8, 4, 7, 1, 3, 4, 5, 6, 7, 8, 1, 2, 3, 4, 5, 6, 7, 8, 1, 3, 5, 7, 3, 7, 8, 2, 3, 8, 2, 3, 5, 1, 2, 4, 1, 4, 3, 5, 7, 1, 2, 3, 4, 5, 6, 7, 8, 3, 7, 4, 6, 5, 6, 2, 7, 1, 6, 6, 1, 1, 3, 5, 6, 7, 8, 3, 4, 5, 6, 6, 4, 3, 4, 5, 6, 7, 3, 3, 2, 1, 6, 7, 2, 7, 7, 4, 4, 1, 2, 3, 4, 5, 8], \"Freq\": [0.9991556602841374, 0.9957311115390493, 0.9823857139251054, 0.9906039916854711, 0.9886085939710073, 0.02661977308060803, 0.20852155579809625, 0.7586635327973289, 0.9925948566270602, 0.004627481849077204, 0.16309652655933465, 0.8343014627842887, 0.9860620127882093, 0.009391066788459137, 0.9954932229684011, 0.9966457479236013, 0.9930411910264105, 0.002766131451327049, 0.21914064631312108, 0.015652903308080078, 0.0026088172180133463, 0.7617746276598971, 0.9986905161803371, 0.004753754228966395, 0.0023768771144831976, 0.9911577567394935, 0.9949769018568314, 0.9955512387283927, 0.9742664352838954, 0.015222913051310866, 0.9913305095642668, 0.005083746202893676, 0.3421966450582121, 0.004387136475105284, 0.6492961983155819, 0.9858464883198307, 0.9772849902232693, 0.0025450129953730975, 0.01781509096761168, 0.0027229045546842273, 0.0027229045546842273, 0.993860162459743, 0.9934007131353669, 0.003284561820714809, 0.9952222316765871, 0.9883223973473763, 0.9864481006509754, 0.010275501048447662, 0.006910614430362011, 0.0023035381434540034, 0.9352364862423255, 0.0023035381434540034, 0.05298137729944208, 0.9920819085382988, 0.9929204461824095, 0.9930725831278696, 0.9942336784793304, 0.1171979960085803, 0.7392488979002757, 0.012020307282931313, 0.0751269205183207, 0.05409138277319091, 0.9942650180421121, 0.9974753982491329, 0.0016541880567978986, 0.9902445535658198, 0.9930986106711965, 0.9902782083258704, 0.005770344259204765, 0.9924992125832196, 0.9946203354876456, 0.990062383794049, 0.98469077875132, 0.2415676008823807, 0.757643839131103, 0.9917630589671186, 0.9874335284403808, 0.9916786233154016, 0.9985656866821452, 0.9933776228308201, 0.9906181494962072, 0.0007626005769793743, 0.00800730605828343, 0.00038130028848968716, 0.00038130028848968716, 0.9924081564973236, 0.9946721522627393, 0.9959937674790639, 0.7817604259575425, 0.21026659732651143, 0.005391451213500293, 0.005391451213500293, 0.0069219606497515915, 0.9898403729144776, 0.9870571140984817, 0.007152587783322332, 0.036074267541249795, 0.2525198727887486, 0.019239609355333226, 0.012024755847083266, 0.026454462863583186, 0.0048099023388333065, 0.6493368157424964, 0.9943871499559537, 0.9936825461917156, 0.9851119481799023, 0.004378275325244011, 0.004378275325244011, 0.004378275325244011, 0.9949140538000909, 0.9962399317179436, 0.0016620204931765022, 0.9955502754127249, 0.0016620204931765022, 0.9903503558836384, 0.007986696418416438, 0.9905952445193381, 0.9892075479501903, 0.9899382935985438, 0.0033967691254257887, 0.9884598154989046, 0.0033967691254257887, 0.7438213293422253, 0.2537334441214133, 0.9932165631481971, 0.9949563093697363, 0.9906787244181467, 0.9883740243397326, 0.06250743496585386, 0.21183075182872693, 0.7257807726590808, 0.219453560641876, 0.6051598187397187, 0.17622785930332466, 0.4279334161067524, 0.07070204266111561, 0.49863545876786797, 0.9978225154141738, 0.9902803329525176, 0.007903654411663153, 0.9879568014578941, 0.9963582964610214, 0.9940588035768668, 0.9942037336979433, 0.989738546900626, 0.9872701561926726, 0.010153395873349723, 0.7581202252101127, 0.23014363979592706, 0.09995143556669944, 0.25575808512655446, 0.0029397481049029247, 0.6173471020296142, 0.023517984839223398, 0.9961300698280156, 0.22920946193537806, 0.01104623912941581, 0.22368634237067017, 0.008284679347061858, 0.527457918429605, 0.9857755279097048, 0.9962954593220363, 0.9906581747763175, 0.007929529197539751, 0.9911911496924689, 0.996068007187, 0.007714253381902052, 0.9905101342362236, 0.9935128780630035, 0.0053995265112119755, 0.02861465453210134, 0.09624929251706814, 0.0026013322301910308, 0.013006661150955154, 0.0026013322301910308, 0.0052026644603820615, 0.8558383037328491, 0.35133091767305435, 0.04466070987369335, 0.5924987509909985, 0.00893214197473867, 0.9949058009921439, 0.005526880609654016, 0.002763440304827008, 0.9801001614453122, 0.010132614451032362, 0.0009211467682756693, 0.9516031955700217, 0.029483432341378877, 0.0010166700807372026, 0.0010166700807372026, 0.012200040968846432, 0.0040666803229488105, 0.992246537573801, 0.007460500282509781, 0.9939944136100094, 0.9892767127826103, 0.9907245152554736, 0.9956466588173077, 0.9969886773231482, 0.9977412550618328, 0.023654797109636375, 0.9698466814950913, 0.005913699277409094, 0.997203912711197, 0.017380239271442458, 0.9790868122912585, 0.9920071256447971, 0.9943744879656407, 0.0033330988423429294, 0.0011110329474476432, 0.9917941171693374, 0.9912792744036195, 0.9908534506738703, 0.9866813788247847, 0.9941788229002974, 0.9914018097144144, 0.008494041179992314, 0.9853087768791083, 0.9891644655580817, 0.004737920629111762, 0.9854874908552466, 0.004737920629111762, 0.004737920629111762, 0.9931797028720312, 0.9894604648841695, 0.9693198894582796, 0.0284536171073859, 0.9955373584789777, 0.9830232284453644, 0.014726939751990478, 0.2582193532778739, 0.7390415973125356, 0.9897132743904236, 0.9937734362596214, 0.010600961725141498, 0.9858894404381593, 0.9970576256719111, 0.1287321551624491, 0.6461363941807542, 0.0024756183685086365, 0.13120777353095775, 0.09159787963481955, 0.9974985853031991, 0.9943127038936486, 0.0017536379257383572, 0.9896366716567682, 0.9906942971693773, 0.007393241023652069, 0.0036966205118260345, 0.9961101520282719, 0.004896343429942486, 0.9939577162783247, 0.9895057281946337, 0.9950801831741328, 0.003080743601158306, 0.9962053730187869, 0.009045509719113094, 0.9859605593833273, 0.9897588058388151, 0.9919137605489978, 0.9871464309325493, 0.9972889920331415, 0.9964178870970122, 0.9873365180958775, 0.14164899557931843, 0.8547784215993353, 0.9973909073150832, 0.9960458844635776, 0.9961280055035615, 0.005220183898136259, 0.9866147567477529, 0.9890142585573556, 0.8649569845070225, 0.13351684995745985, 0.9934444225883501, 0.9912224222514461, 0.9661611481060236, 0.028416504356059517, 0.9929739211142276, 0.9891339917403419, 0.0068726732324932375, 0.9896649454790262, 0.9985891397057076, 0.9945858731571726, 0.0031499672270359795, 0.9953896437433696, 0.9567151944924696, 0.016933012291902118, 0.025399518437853173, 0.996326859028436, 0.9969348205462789, 0.08770158618202152, 0.005481349136376345, 0.904422607502097, 0.9910022104796398, 0.9943156151597896, 0.9961878710389453, 0.988618161434248, 0.9945025043834846, 0.9948825859725826, 0.00696995801504752, 0.9897340381367478, 0.9968419446214475, 0.0010559766362515334, 0.9926727960115509, 0.017967058290434067, 0.010780234974260441, 0.9702211476834397, 0.9921818597573694, 0.033197994847909626, 0.011065998282636543, 0.005532999141318272, 0.9461428531654243, 0.9938820886387391, 0.997163882754588, 0.9933838921850026, 0.9958323448799298, 0.996118724643027, 0.9951368463157323, 0.9889878211954789, 0.9943669769478104, 0.992840241672591, 0.9961740001924538, 0.002316006075643843, 0.9912506003755648, 0.004632012151287686, 0.9906618816816682, 0.9905753436470165, 0.00687899544199317, 0.0071563382581100714, 0.9875746796191899, 0.9956062210501022, 0.9946364128601866, 0.994559913804564, 0.9863261375313682, 0.9920686803767051, 0.9898063728835513, 0.008359851122327292, 0.9655739241948125, 0.03273131946423093, 0.9894589549818056, 0.007947461485797636, 0.003061629099644099, 0.009184887298932297, 0.018369774597864593, 0.009184887298932297, 0.958289908188603, 0.7750301098111823, 0.004668856083199893, 0.004668856083199893, 0.004668856083199893, 0.2100985237439952, 0.9909212435737849, 0.9972829721718973, 0.991898249024231, 0.9955261409178232, 0.9897124270858934, 0.0008418324886155698, 0.005050994931693419, 0.9916786715891412, 0.0016836649772311396, 0.9896980287729592, 0.0049910607281714444, 0.1680323778484386, 0.8235250201482882, 0.0033273738187809625, 0.9924869597950524, 0.9240324755522811, 0.0698396638498817, 0.997533902853772, 0.9944588534703158, 0.7413727650446639, 0.0034806233100688443, 0.25408550163502563, 0.9985511256825457, 0.9962281736809966, 0.9947488498920557, 0.011561285628400048, 0.7081287447395029, 0.017341928442600074, 0.17052896301890072, 0.09249028502720039, 0.9957669863064402, 0.9992300274016267, 0.0005036685223952088, 0.9766132649243098, 0.007555027835928131, 0.009569701925508966, 0.0035256796567664614, 0.002014674089580835, 0.0005036685223952088, 0.9288197599833132, 0.03190602228950313, 0.0354511358772257, 0.0004781795760481429, 0.00023908978802407145, 0.993896248816065, 0.0014345387281444286, 0.0009563591520962858, 0.0009563591520962858, 0.0016736285161685, 0.0004781795760481429, 0.7332394360537037, 0.0009763507803644523, 0.0007322630852733392, 0.1364450215559322, 0.00951942010855341, 0.11838253211918984, 0.00048817539018222614, 0.9934000334446779, 0.004556880887360908, 0.9924956504317438, 0.0047037708551267475, 0.0029845762134526753, 0.9968484552931935, 0.2379556769597061, 0.7609047809758044, 0.9843531611226529, 0.18298943065039597, 0.6157347058371432, 0.1978264115139416, 0.9881251434449145, 0.9968818714829779, 0.9900298256416328, 0.9904556139652446, 0.9931488454640517, 0.27126257840326423, 0.7172366479815122, 0.009195341640788618, 0.7552522832011865, 0.01678338407113748, 0.0033566768142274956, 0.2215406697390147, 0.9985704288483309, 0.9890560850824539, 0.9891120652272292, 0.9899631913773861, 0.9825250675613189, 0.010342369132224409, 0.9962264031834902, 0.9882471642642524, 0.005813218613319132, 0.07451388448971591, 0.91136212568191, 0.011463674536879371, 0.9879490179579626, 0.9910589902931811, 0.02608302753255636, 0.9715927755877244, 0.9872946148381863, 0.9935644160085499, 0.9919117828480494, 0.9907476137989246, 0.9885422026076013, 0.003125322132920351, 0.20939658290566351, 0.009375966398761053, 0.6844455471095569, 0.08438369758884948, 0.006250644265840702, 0.0006757226751373364, 0.9879065510507857, 0.0027028907005493454, 0.0013514453502746727, 0.0031533724839742363, 0.00022524089171244545, 0.002027168025412009, 0.0018019271336995636, 0.9948313763283162, 0.01585254519398945, 0.7450696241175041, 0.01585254519398945, 0.003963136298497362, 0.22589876901434966, 0.7479667220253091, 0.24859535367605023, 0.9884724244778855, 0.006139580276260158, 0.9946092964830073, 0.994179951758469, 0.9939129948008074, 0.994740159468376, 0.9948910111972357, 0.9836324704536596, 0.9922841321236321, 0.004484273037737997, 0.9955086143778353, 0.9966752388371741, 0.9933066195854414, 0.9892117940897187, 0.9853499839965016, 0.9950407962909583, 0.0347751726479735, 0.8215634538083739, 0.139100690591894, 0.9919460592851228, 0.9897993670957183, 0.22543167744095738, 0.7011803473650557, 0.02195763091957377, 0.05123447214567213, 0.6590514253862984, 0.15386414600458326, 0.061545658401833306, 0.05769905475171873, 0.012822012167048607, 0.055134652318309, 0.9965407777522356, 0.9897563230431714, 0.9865758313894314, 0.0033330264573967275, 0.006666052914793455, 0.0016665132286983637, 0.9978154050063055, 0.9880137292258101, 0.9917393594390476, 0.9914898314634628, 0.9867571544892225, 0.005451696986128301, 0.003884818647994942, 0.9945135738867051, 0.6076782987063132, 0.000902939522594819, 0.024379367110060116, 0.1327321098214384, 0.07313810133018034, 0.000902939522594819, 0.15982029549928298, 0.2897847749325001, 0.0004614407244148091, 0.0050758479685629, 0.7023127825593394, 0.0009228814488296182, 0.0004614407244148091, 0.0004614407244148091, 0.0009228814488296182, 0.9889378465220906, 0.002130565330855669, 0.006391695992567006, 0.9885823135170303, 0.9845920696381536, 0.9964630991638349, 0.988071641976525, 0.006012149511315073, 0.006012149511315073, 0.9859925198556719, 0.9971019842268436, 0.9859036494384937, 0.9941967735326875, 0.9956390506075937, 0.0017263617689882342, 0.9961107407062112, 0.001558709838420782, 0.9975742965893004, 0.0021061644143646483, 0.0021061644143646483, 0.9962157679944788, 0.5025072439589672, 0.013958534554415754, 0.13260607826694967, 0.015121745767283734, 0.18378737163314077, 0.09770974188091028, 0.004652844851471918, 0.04769165972758716, 0.9963175027659068, 0.9909575316597878, 0.9952441790262838, 0.9920665883182354, 0.9986671255308162, 0.0005147768688303176, 0.01283506000189906, 0.9861604434792445, 0.9909260052955229, 0.006434584449970928, 0.9958699866650987, 0.991271097028013, 0.2262211632831769, 0.6671756964015569, 0.009720440609824008, 0.04595117379189531, 0.0008836764190749098, 0.05036955588726986, 0.09465999403717336, 0.86190415623321, 0.007473157423987371, 0.034874734645274394, 0.9936493851177385, 0.9916450443405027, 0.15728580899255928, 0.1784137534840971, 0.28405347594178615, 0.36856525390793743, 0.009390197551794583, 0.9976667290613674, 0.9882870561400818, 0.9972488056593916, 0.08603566842412763, 0.9054229867491527, 0.006828227652708543, 0.9961824522812188, 0.9930493396698666, 0.994085311140038, 0.996070966357038, 0.994899882438098, 0.9707872126457768, 0.000636581778784116, 0.001273163557568232, 0.000636581778784116, 0.008275563124193508, 0.01846087158473936], \"Term\": [\"..\", \"10_years\", \"32_bit\", \"64_bit\", \"_1\", \"ability\", \"ability\", \"ability\", \"account\", \"account\", \"addition\", \"addition\", \"alternative\", \"alternative\", \"amount\", \"answer\", \"anyone\", \"anyone\", \"anything\", \"anything\", \"anything\", \"anything\", \"app\", \"application\", \"application\", \"application\", \"apps\", \"area\", \"background\", \"background\", \"backup\", \"backup\", \"bank\", \"bank\", \"bank\", \"basic\", \"bit\", \"bit\", \"bit\", \"book\", \"book\", \"book\", \"boot\", \"box\", \"box\", \"browser\", \"bug\", \"bug\", \"business\", \"business\", \"business\", \"business\", \"business\", \"button\", \"camera\", \"capability\", \"card\", \"case\", \"case\", \"case\", \"case\", \"case\", \"category\", \"cd\", \"cd\", \"chance\", \"change\", \"character\", \"child\", \"child\", \"choice\", \"click\", \"client\", \"code\", \"code\", \"collection\", \"color\", \"comment\", \"company\", \"complaint\", \"computer\", \"computer\", \"computer\", \"computer\", \"computer\", \"control\", \"copy\", \"cost\", \"couple\", \"couple\", \"couple\", \"couple\", \"course\", \"course\", \"crash\", \"crash\", \"customer\", \"customer\", \"customer\", \"customer\", \"customer\", \"customer\", \"customer\", \"customer_service\", \"customer_support\", \"data\", \"data\", \"data\", \"data\", \"date\", \"daughter\", \"day\", \"day\", \"day\", \"deal\", \"deal\", \"deduction\", \"default\", \"design\", \"desktop\", \"desktop\", \"desktop\", \"device\", \"device\", \"didn't_work\", \"difference\", \"difficulty\", \"direction\", \"disc\", \"disc\", \"disc\", \"disk\", \"disk\", \"disk\", \"document\", \"document\", \"document\", \"download\", \"downloads\", \"drive\", \"drive\", \"driver\", \"ease\", \"edition\", \"effect\", \"effort\", \"email\", \"email\", \"email\", \"end\", \"end\", \"end\", \"end\", \"end\", \"entry\", \"error\", \"error\", \"error\", \"error\", \"error\", \"error_message\", \"even_though\", \"every_time\", \"every_year\", \"every_year\", \"everyone\", \"everything\", \"everything\", \"example\", \"example\", \"experience\", \"experience\", \"experience\", \"experience\", \"experience\", \"experience\", \"experience\", \"fact\", \"fact\", \"fact\", \"fact\", \"family\", \"feature\", \"feature\", \"feature\", \"feature\", \"feature\", \"file\", \"file\", \"file\", \"file\", \"file\", \"file\", \"first_time\", \"first_time\", \"fix\", \"folder\", \"font\", \"form\", \"format\", \"friend\", \"fun\", \"fun\", \"fun\", \"function\", \"functionality\", \"functionality\", \"future\", \"game\", \"game\", \"game\", \"gift\", \"glitch\", \"go_back\", \"good_product\", \"graphic\", \"great_product\", \"guy\", \"guy\", \"half\", \"hard_drive\", \"hard_drive\", \"hard_drive\", \"hard_drive\", \"hardware\", \"headache\", \"help\", \"help\", \"highly_recommend\", \"home\", \"home\", \"hour\", \"hour\", \"husband\", \"icon\", \"image\", \"image\", \"improvement\", \"information\", \"information\", \"information\", \"information\", \"information\", \"install\", \"installation\", \"installation\", \"instance\", \"instruction\", \"instruction\", \"instruction\", \"interface\", \"internet\", \"internet\", \"investment\", \"issue\", \"issue\", \"item\", \"job\", \"job\", \"junk\", \"key\", \"keyboard\", \"kid\", \"kind\", \"lack\", \"language\", \"language\", \"laptop\", \"last_year\", \"learning_curve\", \"lesson\", \"lesson\", \"letter\", \"level\", \"level\", \"license\", \"life\", \"line\", \"line\", \"link\", \"location\", \"look\", \"look\", \"lot\", \"mac\", \"machine\", \"machine\", \"make_sure\", \"make_sure\", \"make_sure\", \"many_years\", \"map\", \"market\", \"market\", \"market\", \"matter\", \"memory\", \"menu\", \"mess\", \"mind\", \"minute\", \"mistake\", \"mistake\", \"money\", \"money\", \"money_back\", \"month\", \"month\", \"month\", \"mouse\", \"movie\", \"movie\", \"movie\", \"movie\", \"much_better\", \"music\", \"name\", \"need\", \"new_computer\", \"new_version\", \"next_year\", \"none\", \"note\", \"nothing\", \"number\", \"number\", \"number\", \"object\", \"office\", \"office\", \"older_version\", \"older_version\", \"one\", \"online\", \"operating_system\", \"operation\", \"opinion\", \"option\", \"option\", \"order\", \"order\", \"others\", \"others\", \"package\", \"package\", \"package\", \"package\", \"package\", \"page\", \"page\", \"page\", \"page\", \"page\", \"paper\", \"part\", \"partition\", \"password\", \"patch\", \"pc\", \"pc\", \"pc\", \"pc\", \"pcs\", \"people\", \"people\", \"people\", \"people\", \"performance\", \"person\", \"person\", \"phone\", \"photo\", \"picture\", \"picture\", \"picture\", \"piece\", \"place\", \"player\", \"point\", \"point\", \"point\", \"point\", \"point\", \"practice\", \"price\", \"problem\", \"problem\", \"problem\", \"problem\", \"problem\", \"problem\", \"problem\", \"process\", \"process\", \"process\", \"product\", \"product\", \"product\", \"product\", \"product\", \"product\", \"product\", \"product\", \"program\", \"program\", \"program\", \"program\", \"program\", \"program\", \"program\", \"project\", \"project\", \"protection\", \"protection\", \"purchase\", \"purchase\", \"question\", \"question\", \"really_like\", \"reason\", \"reason\", \"reason\", \"record\", \"refund\", \"release\", \"response\", \"rest\", \"result\", \"result\", \"result\", \"return\", \"return\", \"return\", \"return\", \"review\", \"reviewer\", \"road\", \"room\", \"scan\", \"scan\", \"screen\", \"search\", \"search\", \"security\", \"security\", \"security\", \"seller\", \"server\", \"service\", \"service\", \"session\", \"set\", \"setting\", \"several_years\", \"side\", \"site\", \"site\", \"site\", \"site\", \"site\", \"site\", \"software\", \"software\", \"software\", \"software\", \"software\", \"software\", \"software\", \"software\", \"solution\", \"someone\", \"someone\", \"someone\", \"someone\", \"someone\", \"something\", \"something\", \"son\", \"son\", \"song\", \"sort\", \"sound\", \"space\", \"speed\", \"star\", \"start\", \"state\", \"state\", \"step\", \"store\", \"story\", \"student\", \"stuff\", \"subscription\", \"subscription\", \"subscription\", \"success\", \"suite\", \"support\", \"support\", \"support\", \"support\", \"system\", \"system\", \"system\", \"system\", \"system\", \"system\", \"tablet\", \"task\", \"tax\", \"tax\", \"tax\", \"tax\", \"tech_support\", \"technical_support\", \"template\", \"term\", \"text\", \"text\", \"thanks\", \"thanks\", \"thing\", \"thing\", \"thing\", \"thing\", \"thing\", \"thing\", \"thing\", \"time\", \"time\", \"time\", \"time\", \"time\", \"time\", \"time\", \"time\", \"title\", \"tool\", \"tool\", \"tool\", \"training\", \"transaction\", \"trial_version\", \"trouble\", \"trouble\", \"trouble\", \"try\", \"tutorial\", \"type\", \"unit\", \"update\", \"update\", \"upgrade\", \"upgrade\", \"use\", \"use\", \"use\", \"user\", \"user\", \"user\", \"user\", \"user\", \"user\", \"user\", \"user\", \"user_friendly\", \"user_interface\", \"value\", \"vendor\", \"version\", \"version\", \"video\", \"video\", \"virus\", \"virus\", \"voice\", \"waste\", \"way\", \"way\", \"way\", \"way\", \"way\", \"way\", \"website\", \"website\", \"website\", \"website\", \"week\", \"wife\", \"window\", \"window\", \"window\", \"window\", \"window\", \"windows\", \"windows_8\", \"word\", \"work\", \"work\", \"work\", \"works_great\", \"works_well\", \"world\", \"would_recommend\", \"xp\", \"year\", \"year\", \"year\", \"year\", \"year\", \"year\"]}, \"R\": 30, \"lambda.step\": 0.01, \"plot.opts\": {\"xlab\": \"PC1\", \"ylab\": \"PC2\"}, \"topic.order\": [7, 4, 6, 8, 1, 2, 5, 3]};\n",
       "\n",
       "function LDAvis_load_lib(url, callback){\n",
       "  var s = document.createElement('script');\n",
       "  s.src = url;\n",
       "  s.async = true;\n",
       "  s.onreadystatechange = s.onload = callback;\n",
       "  s.onerror = function(){console.warn(\"failed to load library \" + url);};\n",
       "  document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
       "}\n",
       "\n",
       "if(typeof(LDAvis) !== \"undefined\"){\n",
       "   // already loaded: just create the visualization\n",
       "   !function(LDAvis){\n",
       "       new LDAvis(\"#\" + \"ldavis_el362101338300619827688705410779\", ldavis_el362101338300619827688705410779_data);\n",
       "   }(LDAvis);\n",
       "}else if(typeof define === \"function\" && define.amd){\n",
       "   // require.js is available: use it to load d3/LDAvis\n",
       "   require.config({paths: {d3: \"https://d3js.org/d3.v5\"}});\n",
       "   require([\"d3\"], function(d3){\n",
       "      window.d3 = d3;\n",
       "      LDAvis_load_lib(\"https://cdn.jsdelivr.net/gh/bmabey/pyLDAvis@3.4.0/pyLDAvis/js/ldavis.v3.0.0.js\", function(){\n",
       "        new LDAvis(\"#\" + \"ldavis_el362101338300619827688705410779\", ldavis_el362101338300619827688705410779_data);\n",
       "      });\n",
       "    });\n",
       "}else{\n",
       "    // require.js not available: dynamically load d3 & LDAvis\n",
       "    LDAvis_load_lib(\"https://d3js.org/d3.v5.js\", function(){\n",
       "         LDAvis_load_lib(\"https://cdn.jsdelivr.net/gh/bmabey/pyLDAvis@3.4.0/pyLDAvis/js/ldavis.v3.0.0.js\", function(){\n",
       "                 new LDAvis(\"#\" + \"ldavis_el362101338300619827688705410779\", ldavis_el362101338300619827688705410779_data);\n",
       "            })\n",
       "         });\n",
       "}\n",
       "</script>"
      ],
      "text/plain": [
       "PreparedData(topic_coordinates=              x         y  topics  cluster       Freq\n",
       "topic                                                \n",
       "6      0.239717 -0.008204       1        1  15.373344\n",
       "3     -0.130553  0.281185       2        1  13.776234\n",
       "5     -0.150216  0.061709       3        1  13.153886\n",
       "7      0.191897  0.108389       4        1  12.626896\n",
       "0     -0.106487 -0.227265       5        1  12.586478\n",
       "1      0.133382 -0.083733       6        1  11.601132\n",
       "4     -0.109810 -0.122770       7        1  10.461021\n",
       "2     -0.067929 -0.009312       8        1  10.421010, topic_info=            Term         Freq        Total Category  logprob  loglift\n",
       "76      software  4439.000000  4439.000000  Default  30.0000  30.0000\n",
       "47       product  4182.000000  4182.000000  Default  29.0000  29.0000\n",
       "16      computer  2622.000000  2622.000000  Default  28.0000  28.0000\n",
       "95       program  4096.000000  4096.000000  Default  27.0000  27.0000\n",
       "13       version  1942.000000  1942.000000  Default  26.0000  26.0000\n",
       "...          ...          ...          ...      ...      ...      ...\n",
       "297   experience   329.106341   384.418410   Topic8  -4.1516   2.1060\n",
       "104     anything   291.833160   383.315471   Topic8  -4.2718   1.9887\n",
       "1412        code   206.674599   273.215447   Topic8  -4.6168   1.9822\n",
       "179     customer   269.979415   415.808858   Topic8  -4.3496   1.8295\n",
       "238        thing   177.289777  1107.493885   Topic8  -4.7702   0.4293\n",
       "\n",
       "[367 rows x 6 columns], token_table=      Topic      Freq      Term\n",
       "term                           \n",
       "201       7  0.999156        ..\n",
       "488       8  0.995731  10_years\n",
       "2237      1  0.982386    32_bit\n",
       "2233      1  0.990604    64_bit\n",
       "2037      7  0.988609        _1\n",
       "...     ...       ...       ...\n",
       "31        2  0.000637      year\n",
       "31        3  0.001273      year\n",
       "31        4  0.000637      year\n",
       "31        5  0.008276      year\n",
       "31        8  0.018461      year\n",
       "\n",
       "[612 rows x 3 columns], R=30, lambda_step=0.01, plot_opts={'xlab': 'PC1', 'ylab': 'PC2'}, topic_order=[7, 4, 6, 8, 1, 2, 5, 3])"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Modelo 3: con n3 tópicos:\n",
    "\n",
    "pyLDAvis.gensim.prepare(ldamodel3, corpus, dictionary)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "J_8O14ttpxob",
   "metadata": {
    "id": "J_8O14ttpxob"
   },
   "source": [
    "<div style=\"background-color: #EDF7FF; border-color: #7C9DBF; border-left: 5px solid #7C9DBF; padding: 0.5em;\">\n",
    "\n",
    "<b>Análisis:</b> Analiza los resultados de los tres experimentos realizados (con diferente número de tópicos) y los resultados de la visualización de cada modelo LDA. En cada caso, ¿cuál resulta ser el mejor modelo? o ¿en ambos casos se confirma cuál es el mejor modelo?\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab-ZWYKWqnQ6",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 221
    },
    "id": "ab-ZWYKWqnQ6",
    "outputId": "121d8de6-7110-458f-b8f2-b0796fe007be"
   },
   "outputs": [],
   "source": [
    "#############################################\n",
    "# SOLUCIÓN                                 #\n",
    "#############################################\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "YF6i9Y4Lodhq",
   "metadata": {
    "id": "YF6i9Y4Lodhq"
   },
   "source": [
    "<div style=\"background-color: #EDF7FF; border-color: #7C9DBF; border-left: 5px solid #7C9DBF; padding: 0.5em;\">\n",
    "\n",
    "<strong>Ejercicio Opcional:</strong> Toma como base los resultados de cada modelo LDA y calcula las métricas de calidad denominadas perplejidad y coherencia, las cuales están definidas en el paquete gensim. Luego de los cálculos confirma o no tu decisión anterior de cuál es el mejor modelo.\n",
    "<br>\n",
    "Tanto la perplejidad como la coherencia son métricas complementarias. Una perplejidad baja indica que el modelo puede generalizar bien a nuevos datos, mientras que una alta coherencia indica que los temas generados son interpretables y distintos entre sí. Cuando evaluamos el rendimiento de un modelo LDA, se sugiere elegir modelos que evidencien un equilibrio entre ambas métricas.\n",
    "<br>\n",
    "Como indica el enunciado este ejercicio es opcional, pero ha sido incorporado en la práctica por sí alguien quiere aprender un poco más el tema. Las métricas mencionadas nos puede ayudar a tener un criterio adicional para elegir el modelo de temas máas apropiado. Para una introducción básica de este tema podrían revisar el siguiente post (https://medium.com/@iqra.bismi/topic-modelling-using-lda-fe81a2a806e0)\n",
    "<br>\n",
    "<b>Salida esperada:</b>\n",
    "<br>\n",
    "- Valores de coherencia y perplejidad (puedes usar el valor absoluto calculado para una mejor interpretación) de cada uno de los 3 modelos de LDA.\n",
    "<br>\n",
    "- Respuesta a la pregunta ¿según los valores de las métricas cuál es el mejor modelo?\n",
    "<br>\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ggDQcxhpoexZ",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ggDQcxhpoexZ",
    "outputId": "dec95007-4311-4a05-a578-ccc3590895ee"
   },
   "outputs": [],
   "source": [
    "#############################################\n",
    "# SOLUCIÓN                                  #\n",
    "#############################################\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "o4xwugFgH07f",
   "metadata": {
    "id": "o4xwugFgH07f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n  ¿Según los valores de las métricas calculadas cuál es el mejor modelo?\\n\\n'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "  ¿Según los valores de las métricas calculadas cuál es el mejor modelo?\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "#############################################\n",
    "# SOLUCIÓN                                  #\n",
    "#############################################\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f6ed8c2",
   "metadata": {
    "id": "1f6ed8c2"
   },
   "source": [
    "# 4. Clasificación (1,75 puntos)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32290b6e",
   "metadata": {
    "id": "32290b6e"
   },
   "source": [
    "\n",
    "<strong>Ejercicio:</strong> Crea un clasificador automático de opiniones positivas y negativas. (0.75 puntos)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a45ae89",
   "metadata": {
    "id": "3a45ae89"
   },
   "source": [
    "<i>Primer paso</i>: crea dos listas. Una con los textos y otra con las etiquetas de valoración (0 y 1)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec874492",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ec874492",
    "outputId": "af574a50-1e93-4c0a-e323-00c2f0e4c8b8"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['We run a top of the line system utilizing Windows 10 Pro. I personally tried to get this to work. When you click the application file as per the directions on the back of the case our entire system would bog down and have to be reset. I let it just sit once to see if it ever started and after about 20 minutes all these windows started popping up saying that the file required a version of Adobe that does not exist and that the wrong volume was inserted. Now we are taking all our computers off line to do a complete virus scan just in case. Avoid. At the least it is a headache and a waste of time and money.',\n",
       " 'I do not really know why there were so many complaints about Windows 8. I got this in 2013 and had no problem since them. All you have to do is add on a free start button utility and it works pretty much like windows has always worked. Of course now that Windows 10 is out maybe that is a moot point',\n",
       " 'I have used both WordPerfect Office and Microsoft Office for years. I love WordPerfect because it is easier to edit and manipulate graphics within the documents. I also like the Reveal Codes feature much easier than Word I highly recommend WordPerfect and most businesses tend to have both.']"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "opinions = df['text'].to_list()\n",
    "labels = df['sentiment'].to_list()\n",
    "opinions[:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9720bc32",
   "metadata": {
    "id": "9720bc32"
   },
   "source": [
    "<div style=\"background-color: #EDF7FF; border-color: #7C9DBF; border-left: 5px solid #7C9DBF; padding: 0.5em;\">\n",
    "\n",
    "<i>Segundo paso</i>: Vectorizamos las opiniones con un vectorizador tf.idf. Usad 'word' como analyzer.\n",
    "<br>\n",
    "<b>Salida esperada:</b> Imprime la matriz de los vectores correpsondientes a las primeras 5 opiniones.\n",
    "</br>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fbcfdd4",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9fbcfdd4",
    "outputId": "bea88594-50f2-4cf6-d252-9cf0af7cc9f9"
   },
   "outputs": [],
   "source": [
    "#############################################\n",
    "# SOLUCIÓN                                 #\n",
    "#############################################\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3122e026",
   "metadata": {
    "id": "3122e026"
   },
   "source": [
    "<div style=\"background-color: #EDF7FF; border-color: #7C9DBF; border-left: 5px solid #7C9DBF; padding: 0.5em;\">\n",
    "\n",
    "<i>Tercer paso</i>: Preparamos el corpus de entrenamiento y evaluación, y entrenamos al clasificador con Logistic Regression.\n",
    "<br>\n",
    "<b>Salida esperada:</b> Tiempo de ejecución que conlleva realizar el entrenamiento (fit()).\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b251acc",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0b251acc",
    "outputId": "7c039b39-af3f-4d68-e2dd-b4f92d8c2a68"
   },
   "outputs": [],
   "source": [
    "#############################################\n",
    "# SOLUCIÓN                                  #\n",
    "#############################################\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c78a34d",
   "metadata": {
    "id": "8c78a34d"
   },
   "source": [
    "\n",
    "<div style=\"background-color: #EDF7FF; border-color: #7C9DBF; border-left: 5px solid #7C9DBF; padding: 0.5em;\">\n",
    "\n",
    "<i>Cuarto paso</i>: Utilizar el modelo entrenado para predecir la categoría 1 (positivo) o 0 (negativo) de las opiniones del conjunto de test y mostrar las palabras más informativas para cada categoría.\n",
    "<br>\n",
    "<b>Salida esperada:</b> Imprime las 10 palabras más informativas de cada categoría.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "160fc014",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "160fc014",
    "outputId": "79a85e34-a6f4-4827-e4ce-0b628690df27"
   },
   "outputs": [],
   "source": [
    "#############################################\n",
    "# SOLUCIÓN                                  #\n",
    "#############################################\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4af23001",
   "metadata": {
    "id": "4af23001"
   },
   "source": [
    "\n",
    "<strong>Ejercicio:</strong> Muestra sobre qué aspectos se hacen valoraciones negativas. (1 punto)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8eb0943",
   "metadata": {
    "id": "d8eb0943"
   },
   "source": [
    "<div style=\"background-color: #EDF7FF; border-color: #7C9DBF; border-left: 5px solid #7C9DBF; padding: 0.5em;\">\n",
    "\n",
    "<i>Primer paso</i>: Elige dos palabras más informativas de la categoría 0 y toma un conjunto de opiniones en las que aparezcan estas palabras. Preprocesa las opiniones quitando los caracteres de salto de línea.\n",
    "<br>\n",
    "<b>Salida esperada:</b> Imprime las 3 primeras opiniones en las que aparezcan los términos seleccionados.\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7eb6ab69",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7eb6ab69",
    "outputId": "1f5b79ec-88e7-4c0f-e7e6-02d429bf9ba7"
   },
   "outputs": [],
   "source": [
    "#############################################\n",
    "# SOLUCIÓN                                  #\n",
    "#############################################\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5c24dbb",
   "metadata": {
    "id": "b5c24dbb"
   },
   "source": [
    "<div style=\"background-color: #EDF7FF; border-color: #7C9DBF; border-left: 5px solid #7C9DBF; padding: 0.5em;\">\n",
    "\n",
    "<i>Segundo paso</i>: Utiliza el diccionario de opiniones (archivo AFINN-111) para extraer la polaridad de cada opinión como la media de los valores de las opinion words del texto.\n",
    "<br>\n",
    "<b>Salida esperada:</b> Lista de las 3 primeras opioniones y el respectivo puntaje de polaridad.\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "895f6b09",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "895f6b09",
    "outputId": "fe58e7af-186d-4138-9195-694047655468"
   },
   "outputs": [],
   "source": [
    "#############################################\n",
    "# SOLUCIÓN                                  #\n",
    "#############################################\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3jukmO2e_nW2",
   "metadata": {
    "id": "3jukmO2e_nW2"
   },
   "source": [
    "<div style=\"background-color: #EDF7FF; border-color: #7C9DBF; border-left: 5px solid #7C9DBF; padding: 0.5em;\">\n",
    "\n",
    "<b>Análisis</b>: De los tres casos presentados en el ejercicio anterior ¿la polaridad que se calcula es coherente con el comentario emitido por los clientes? Discute si hay alguna diferencia y ¿por qué se generaría una diferencia?\n",
    "\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "RmWD6TGG_nqm",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 221
    },
    "id": "RmWD6TGG_nqm",
    "outputId": "2ff946ad-370f-4fa1-d045-2e69c0497b00"
   },
   "outputs": [],
   "source": [
    "#############################################\n",
    "# SOLUCIÓN                                  #\n",
    "#############################################\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1561cfe1",
   "metadata": {
    "id": "1561cfe1"
   },
   "source": [
    "<div style=\"background-color: #EDF7FF; border-color: #7C9DBF; border-left: 5px solid #7C9DBF; padding: 0.5em;\">\n",
    "\n",
    "<i>Tercer paso:</i> Selecciona opiniones con polaridad negativa que ejemplifiquen los aspectos peor valorados (puedes utilizar un umbral para seleccionar las peores reseñas). Comenta cuáles son estos aspectos.\n",
    "<br>\n",
    "<b>Salida esperada: </b>\n",
    "<br>\n",
    "- Lista de las tres primeras opiniones negativas.\n",
    "<br>\n",
    "- Respuesta a la pregunta ¿Cuáles son los aspectos peor valorados por los clientes?\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "412f2bf5",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "412f2bf5",
    "outputId": "fa23122b-717c-4467-fd8b-b9dd6716275d"
   },
   "outputs": [],
   "source": [
    "#############################################\n",
    "# SOLUCIÓN                                  #\n",
    "#############################################\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9142b7d3-4933-4bd3-b8f4-fe62622d027f",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 276
    },
    "id": "9142b7d3-4933-4bd3-b8f4-fe62622d027f",
    "outputId": "a627ea4c-4558-4c59-f5e6-7b39df93ac94"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Comenta cuáles son los aspectos peor valorados: \n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\\nComenta cuáles son los aspectos peor valorados: \") # PENEIDNETETEEEEEEEEE\n",
    "\n",
    "#############################################\n",
    "# SOLUCIÓN                                  #\n",
    "#############################################\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd22b5d6-b863-4ff6-92a6-a4e35325fa38",
   "metadata": {
    "id": "fd22b5d6-b863-4ff6-92a6-a4e35325fa38"
   },
   "source": [
    "# 5. Evaluación: comparación de modelos y discusión de resultados (1.5 puntos)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b69d8d2f",
   "metadata": {
    "id": "b69d8d2f"
   },
   "source": [
    "<div style=\"background-color: #EDF7FF; border-color: #7C9DBF; border-left: 5px solid #7C9DBF; padding: 0.5em;\">\n",
    "\n",
    "<strong>Ejercicio:</strong> Obtén los resultados de las métricas de evaluación del clasificador basado en regresión logística.\n",
    "\n",
    "<br>\n",
    "\n",
    "<b>Salida esperada: </b> Métricas de redimiento del modelo de regresión logística (por clase).\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afc6ad8f",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "afc6ad8f",
    "outputId": "68c4459c-7a0b-41ee-fd34-d110ed688fa8"
   },
   "outputs": [],
   "source": [
    "#############################################\n",
    "# SOLUCIÓN MODELO REGRESIÓN LOGÍSTICA              #\n",
    "#############################################\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82c5988e-ce7e-4b4c-afca-023941c34fa7",
   "metadata": {
    "id": "82c5988e-ce7e-4b4c-afca-023941c34fa7"
   },
   "source": [
    "<div style=\"background-color: #EDF7FF; border-color: #7C9DBF; border-left: 5px solid #7C9DBF; padding: 0.5em;\">\n",
    "\n",
    "<strong>Ejercicio:</strong> Obtén también los resultados de las métricas de evaluación para un clasificador diferente. Por ejemplo, utiliza SVM.\n",
    "<br>\n",
    "<b>Salida esperada: </b>\n",
    "<br>\n",
    "- Tiempo de ejecución que conlleva realizar el entrenamiento (fit()).\n",
    "<br>\n",
    "- Métricas de redimiento del modelo SVM (por clase).\n",
    "<br>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "210a7df8",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "210a7df8",
    "outputId": "41deecf3-910e-4885-c823-6af9ef82b0f9"
   },
   "outputs": [],
   "source": [
    "#############################################\n",
    "# SOLUCIÓN MODELO SVM                       #\n",
    "#############################################\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce2e4564",
   "metadata": {
    "id": "ce2e4564"
   },
   "source": [
    "<div style=\"background-color: #EDF7FF; border-color: #7C9DBF; border-left: 5px solid #7C9DBF; padding: 0.5em;\">\n",
    "\n",
    "<strong>Análisis:</strong> Compara los dos modelos en función de las métricas de evaluación y del tiempo de ejecución, para ello, contesta las siguientes interrogantes:\n",
    "\n",
    "- ¿Cuál de los dos modelos tiene mejores valores de precision, recall y f1?\n",
    "- ¿Las diferencias en el rendimiento son significativas?\n",
    "- ¿Cuál de los dos modelos elegirías para predecir nuevas reseñas sobre productos tech? Considera las métricas de rendimiento, pero, además, analiza las diferencias en el tiempo de ejecución de cada modelo.\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0466babb",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 221
    },
    "id": "0466babb",
    "outputId": "3c330b37-d3bf-4f99-bca3-2d85c16e6f17"
   },
   "outputs": [],
   "source": [
    "#############################################\n",
    "# SOLUCIÓN                                  #\n",
    "#############################################\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cc46d32-c604-4f08-891e-d62f9198fd16",
   "metadata": {
    "id": "3cc46d32-c604-4f08-891e-d62f9198fd16"
   },
   "source": [
    "\n",
    "<strong>Ejercicio:</strong> Como recordarás, durante la preparación del dataset, existen más reseñas de sentimiento positivo y menos de negativo, por tanto, en estos últimos pasos el clasificador fue entrenado con un dataset desbalanceado.\n",
    "\n",
    "De lo que habíamos visto antes, hay 4277 reseñas con etiqueta negativa y 8037 con etiqueta positiva. Para balancear el dataset vamos a adoptar la técnica undersampling, por tanto, tomaremos únicamente alrededor de 4276 reseñas con etiqueta positiva, lo cual equivale a aproximadamente al 50% del nuevo dataset.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "Q5yt-btYMwAw",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 437
    },
    "id": "Q5yt-btYMwAw",
    "outputId": "1f77a9e5-7d29-4740-ba68-f2817c5fa660"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4276, 4) (4277, 4)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    },
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "summary": "{\n  \"name\": \"dfb\",\n  \"rows\": 5,\n  \"fields\": [\n    {\n      \"column\": \"overall\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1.9493588689617927,\n        \"min\": 1.0,\n        \"max\": 5.0,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          1.0,\n          5.0,\n          2.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"reviewText\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"I have been using Quicken for over 10 years.  It is a great product.  I find it essential for managing my finances, planning retirement and preparing taxes. Online access to banks, financial institution makes it easy to download and reconcile banking, credit card and other transactions.  Reviewing your Quicken Accounts frequently and easily allows your to detect identity fraud or erroneous transactions.\\n\\nSetting up and maintaining categories with appropriate tax links allows the user to know where and how every penny is spent or earned.  Linkage to Turbo Tax, assuming you maintain good records in Quicken, permits Tax preparation to be done in minutes instead of hours.\\n\\nHowever expensive forced upgrades every year or two without commensurate functionality is disappointing.\\n\\nGJG\",\n          \"This year's edition offered no surprises.  The conversion process for the data file from the previous year completed without incident.  Quick Update with banks and credits went quickly and with no errors.\",\n          \"Best music app...actually shuffles my music in my playlists....so i don't listen to the music in the same exact order everyday\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"sentiment\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1,\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"text\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"I have been using Quicken for over 10 years. It is a great product. I find it essential for managing my finances planning retirement and preparing taxes. Online access to banks financial institution makes it easy to download and reconcile banking credit card and other transactions. Reviewing your Quicken Accounts frequently and easily allows your to detect identity fraud or erroneous transactions. Setting up and maintaining categories with appropriate tax links allows the user to know where and how every penny is spent or earned. Linkage to Turbo Tax assuming you maintain good records in Quicken permits Tax preparation to be done in minutes instead of hours. However expensive forced upgrades every year or two without commensurate functionality is disappointing. GJG\",\n          \"This year is edition offered no surprises. The conversion process for the data file from the previous year completed without incident. Quick Update with banks and credits went quickly and with no errors.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}",
       "type": "dataframe"
      },
      "text/html": [
       "\n",
       "  <div id=\"df-2ede2dff-9e68-4157-acf1-d42da7f84938\" class=\"colab-df-container\">\n",
       "    <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>overall</th>\n",
       "      <th>reviewText</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7038</th>\n",
       "      <td>1.0</td>\n",
       "      <td>Bought this software earlier in the year.  Took a little while to get it installed, but finally got it done.\\n\\nI wanted the software to allow me to have a portable B...</td>\n",
       "      <td>0</td>\n",
       "      <td>Bought this software earlier in the year. Took a little while to get it installed but finally got it done. I wanted the software to allow me to have a portable Blu Ra...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1197</th>\n",
       "      <td>5.0</td>\n",
       "      <td>I have been using Quicken for over 10 years.  It is a great product.  I find it essential for managing my finances, planning retirement and preparing taxes. Online ac...</td>\n",
       "      <td>1</td>\n",
       "      <td>I have been using Quicken for over 10 years. It is a great product. I find it essential for managing my finances planning retirement and preparing taxes. Online acces...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2862</th>\n",
       "      <td>5.0</td>\n",
       "      <td>Best music app...actually shuffles my music in my playlists....so i don't listen to the music in the same exact order everyday</td>\n",
       "      <td>1</td>\n",
       "      <td>Best music app...actually shuffles my music in my playlists....so i do not listen to the music in the same exact order everyday</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6713</th>\n",
       "      <td>2.0</td>\n",
       "      <td>I was very excited to order Snow Leopard (mainly due to the Grand Central Dispatch) technology.  After installing last night I found my Rev1 MBP overheats like crazy....</td>\n",
       "      <td>0</td>\n",
       "      <td>I was very excited to order Snow Leopard mainly due to the Grand Central Dispatch technology. After installing last night I found my Rev1 MBP overheats like crazy. Af...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2860</th>\n",
       "      <td>5.0</td>\n",
       "      <td>This year's edition offered no surprises.  The conversion process for the data file from the previous year completed without incident.  Quick Update with banks and cr...</td>\n",
       "      <td>1</td>\n",
       "      <td>This year is edition offered no surprises. The conversion process for the data file from the previous year completed without incident. Quick Update with banks and cre...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "    <div class=\"colab-df-buttons\">\n",
       "\n",
       "  <div class=\"colab-df-container\">\n",
       "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-2ede2dff-9e68-4157-acf1-d42da7f84938')\"\n",
       "            title=\"Convert this dataframe to an interactive table.\"\n",
       "            style=\"display:none;\">\n",
       "\n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
       "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
       "  </svg>\n",
       "    </button>\n",
       "\n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    .colab-df-buttons div {\n",
       "      margin-bottom: 4px;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "    <script>\n",
       "      const buttonEl =\n",
       "        document.querySelector('#df-2ede2dff-9e68-4157-acf1-d42da7f84938 button.colab-df-convert');\n",
       "      buttonEl.style.display =\n",
       "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "      async function convertToInteractive(key) {\n",
       "        const element = document.querySelector('#df-2ede2dff-9e68-4157-acf1-d42da7f84938');\n",
       "        const dataTable =\n",
       "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                    [key], {});\n",
       "        if (!dataTable) return;\n",
       "\n",
       "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "          + ' to learn more about interactive tables.';\n",
       "        element.innerHTML = '';\n",
       "        dataTable['output_type'] = 'display_data';\n",
       "        await google.colab.output.renderOutput(dataTable, element);\n",
       "        const docLink = document.createElement('div');\n",
       "        docLink.innerHTML = docLinkHtml;\n",
       "        element.appendChild(docLink);\n",
       "      }\n",
       "    </script>\n",
       "  </div>\n",
       "\n",
       "\n",
       "<div id=\"df-73a6add1-ca7f-401c-8ff4-44a04fc8f29d\">\n",
       "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-73a6add1-ca7f-401c-8ff4-44a04fc8f29d')\"\n",
       "            title=\"Suggest charts\"\n",
       "            style=\"display:none;\">\n",
       "\n",
       "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "     width=\"24px\">\n",
       "    <g>\n",
       "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
       "    </g>\n",
       "</svg>\n",
       "  </button>\n",
       "\n",
       "<style>\n",
       "  .colab-df-quickchart {\n",
       "      --bg-color: #E8F0FE;\n",
       "      --fill-color: #1967D2;\n",
       "      --hover-bg-color: #E2EBFA;\n",
       "      --hover-fill-color: #174EA6;\n",
       "      --disabled-fill-color: #AAA;\n",
       "      --disabled-bg-color: #DDD;\n",
       "  }\n",
       "\n",
       "  [theme=dark] .colab-df-quickchart {\n",
       "      --bg-color: #3B4455;\n",
       "      --fill-color: #D2E3FC;\n",
       "      --hover-bg-color: #434B5C;\n",
       "      --hover-fill-color: #FFFFFF;\n",
       "      --disabled-bg-color: #3B4455;\n",
       "      --disabled-fill-color: #666;\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart {\n",
       "    background-color: var(--bg-color);\n",
       "    border: none;\n",
       "    border-radius: 50%;\n",
       "    cursor: pointer;\n",
       "    display: none;\n",
       "    fill: var(--fill-color);\n",
       "    height: 32px;\n",
       "    padding: 0;\n",
       "    width: 32px;\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart:hover {\n",
       "    background-color: var(--hover-bg-color);\n",
       "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "    fill: var(--button-hover-fill-color);\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart-complete:disabled,\n",
       "  .colab-df-quickchart-complete:disabled:hover {\n",
       "    background-color: var(--disabled-bg-color);\n",
       "    fill: var(--disabled-fill-color);\n",
       "    box-shadow: none;\n",
       "  }\n",
       "\n",
       "  .colab-df-spinner {\n",
       "    border: 2px solid var(--fill-color);\n",
       "    border-color: transparent;\n",
       "    border-bottom-color: var(--fill-color);\n",
       "    animation:\n",
       "      spin 1s steps(1) infinite;\n",
       "  }\n",
       "\n",
       "  @keyframes spin {\n",
       "    0% {\n",
       "      border-color: transparent;\n",
       "      border-bottom-color: var(--fill-color);\n",
       "      border-left-color: var(--fill-color);\n",
       "    }\n",
       "    20% {\n",
       "      border-color: transparent;\n",
       "      border-left-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "    }\n",
       "    30% {\n",
       "      border-color: transparent;\n",
       "      border-left-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "      border-right-color: var(--fill-color);\n",
       "    }\n",
       "    40% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "    }\n",
       "    60% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "    }\n",
       "    80% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "      border-bottom-color: var(--fill-color);\n",
       "    }\n",
       "    90% {\n",
       "      border-color: transparent;\n",
       "      border-bottom-color: var(--fill-color);\n",
       "    }\n",
       "  }\n",
       "</style>\n",
       "\n",
       "  <script>\n",
       "    async function quickchart(key) {\n",
       "      const quickchartButtonEl =\n",
       "        document.querySelector('#' + key + ' button');\n",
       "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
       "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
       "      try {\n",
       "        const charts = await google.colab.kernel.invokeFunction(\n",
       "            'suggestCharts', [key], {});\n",
       "      } catch (error) {\n",
       "        console.error('Error during call to suggestCharts:', error);\n",
       "      }\n",
       "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
       "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
       "    }\n",
       "    (() => {\n",
       "      let quickchartButtonEl =\n",
       "        document.querySelector('#df-73a6add1-ca7f-401c-8ff4-44a04fc8f29d button');\n",
       "      quickchartButtonEl.style.display =\n",
       "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "    })();\n",
       "  </script>\n",
       "</div>\n",
       "    </div>\n",
       "  </div>\n"
      ],
      "text/plain": [
       "      overall  \\\n",
       "7038      1.0   \n",
       "1197      5.0   \n",
       "2862      5.0   \n",
       "6713      2.0   \n",
       "2860      5.0   \n",
       "\n",
       "                                                                                                                                                                     reviewText  \\\n",
       "7038  Bought this software earlier in the year.  Took a little while to get it installed, but finally got it done.\\n\\nI wanted the software to allow me to have a portable B...   \n",
       "1197  I have been using Quicken for over 10 years.  It is a great product.  I find it essential for managing my finances, planning retirement and preparing taxes. Online ac...   \n",
       "2862                                             Best music app...actually shuffles my music in my playlists....so i don't listen to the music in the same exact order everyday   \n",
       "6713  I was very excited to order Snow Leopard (mainly due to the Grand Central Dispatch) technology.  After installing last night I found my Rev1 MBP overheats like crazy....   \n",
       "2860  This year's edition offered no surprises.  The conversion process for the data file from the previous year completed without incident.  Quick Update with banks and cr...   \n",
       "\n",
       "      sentiment  \\\n",
       "7038          0   \n",
       "1197          1   \n",
       "2862          1   \n",
       "6713          0   \n",
       "2860          1   \n",
       "\n",
       "                                                                                                                                                                           text  \n",
       "7038  Bought this software earlier in the year. Took a little while to get it installed but finally got it done. I wanted the software to allow me to have a portable Blu Ra...  \n",
       "1197  I have been using Quicken for over 10 years. It is a great product. I find it essential for managing my finances planning retirement and preparing taxes. Online acces...  \n",
       "2862                                            Best music app...actually shuffles my music in my playlists....so i do not listen to the music in the same exact order everyday  \n",
       "6713  I was very excited to order Snow Leopard mainly due to the Grand Central Dispatch technology. After installing last night I found my Rev1 MBP overheats like crazy. Af...  \n",
       "2860  This year is edition offered no surprises. The conversion process for the data file from the previous year completed without incident. Quick Update with banks and cre...  "
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Separar las reseñas según su sentimiento para tomar igual cantidad para la clase 1 y 0.\n",
    "opinionsPos = df[df[\"sentiment\"] == 1] # opiniones positivas\n",
    "opinionsNeg = df[df[\"sentiment\"] == 0]  # opiniones negativas\n",
    "\n",
    "opinionsPos = opinionsPos.sample(frac=0.532, random_state = 42) # tomar una fracción de la opiones de clase mayoritaria.\n",
    "\n",
    "print(opinionsPos.shape, opinionsNeg.shape)\n",
    "\n",
    "# Integrar reseñas y separar en listas:\n",
    "\n",
    "dfb = pd.concat([opinionsPos, opinionsNeg], ignore_index=True)\n",
    "opinions = dfb[\"text\"].to_list()\n",
    "labels = dfb['sentiment'].to_list()\n",
    "dfb.sample(5, random_state = 42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "chDzxzFbWWed",
   "metadata": {
    "id": "chDzxzFbWWed"
   },
   "source": [
    "<div style=\"background-color: #EDF7FF; border-color: #7C9DBF; border-left: 5px solid #7C9DBF; padding: 0.5em;\">\n",
    "\n",
    "<i>Paso 1</i>: En este último ejercicio, repite los experimentos pero con el nuevo dataset, y repite los experimentos con los modelos de regresión logística y SVM.\n",
    "<br>\n",
    "<b>Salida esperada:</b>\n",
    "<br>\n",
    "- Métricas de cada modelo y tiempo de ejecución del fit().\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "PozWG7Hdw6pc",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PozWG7Hdw6pc",
    "outputId": "245354ff-a5ef-4fe2-87d9-f2c04b0b593a"
   },
   "outputs": [],
   "source": [
    "#############################################\n",
    "# SOLUCIÓN                                 #\n",
    "#############################################\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "FT0LKCCyxROl",
   "metadata": {
    "id": "FT0LKCCyxROl"
   },
   "source": [
    "<div style=\"background-color: #EDF7FF; border-color: #7C9DBF; border-left: 5px solid #7C9DBF; padding: 0.5em;\">\n",
    "\n",
    "<strong>Análisis:</strong> ¿Qué diferencias observas entre los clasificadores entrenados con el dataset desbalanceado, vs. los clasificadores y el dataset balanceado? Comenta las principales diferencias y similitudes.\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20e52d68-3d5e-4a76-b3c1-3363c5a0fc76",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 184
    },
    "id": "20e52d68-3d5e-4a76-b3c1-3363c5a0fc76",
    "outputId": "18f00e29-4209-43b4-877d-ae38ef7409fb"
   },
   "outputs": [],
   "source": [
    "#############################################\n",
    "# DISCUSIÓN: SEMEJANZAS Y DIFERENCIAS       #\n",
    "#############################################\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
